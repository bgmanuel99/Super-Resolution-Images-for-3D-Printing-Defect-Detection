{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b62c01c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../../\")))\n",
    "from SRModels.loading_methods import load_dataset_as_patches\n",
    "from SRModels.deep_learning_models.SRCNN_model import SRCNNModel\n",
    "from SRModels.constants import SRCNN_PATCH_SIZE, SRCNN_STRIDE, RANDOM_SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1ed6dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "HR_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"../../data/images/HR\"))\n",
    "LR_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"../../data/images/LR\"))\n",
    "INTERP_MAP_PATH = os.path.abspath(os.path.join(os.getcwd(), \"../../data/images/interpolation_map.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "495338f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X -> Low-resolution patches (model input) (Low-resolution images with same size as Y but noised)\n",
    "# Y -> High-resolution patches (target)\n",
    "X, Y, hr_h, hr_w = load_dataset_as_patches(HR_ROOT, LR_ROOT, mode=\"srcnn\", patch_size=SRCNN_PATCH_SIZE, stride=SRCNN_STRIDE, interpolation_map_path=INTERP_MAP_PATH)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, shuffle=True, random_state=RANDOM_SEED)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.1, shuffle=True, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e710ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (2560, 96, 96, 3), Y shape: (2560, 96, 96, 3)\n",
      "X_train shape: (1843, 96, 96, 3), Y_train shape: (1843, 96, 96, 3)\n",
      "X_val shape: (205, 96, 96, 3), Y_val shape: (205, 96, 96, 3)\n",
      "X_test shape: (512, 96, 96, 3), Y_test shape: (512, 96, 96, 3)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X shape: {X.shape}, Y shape: {Y.shape}\")\n",
    "print(f\"X_train shape: {X_train.shape}, Y_train shape: {Y_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}, Y_val shape: {Y_val.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}, Y_test shape: {Y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1aa44862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 96, 96, 64)        15616     \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 96, 96, 32)        2080      \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 96, 96, 3)         2403      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,099\n",
      "Trainable params: 20,099\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = SRCNNModel()\n",
    "\n",
    "model.setup_model(input_shape=X_train.shape[1:], learning_rate=1e-4, loss=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9352967c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on GPU: /physical_device:GPU:0\n",
      "116/116 [==============================] - 7s 27ms/step - loss: 0.0749 - psnr: 14.6088 - ssim: 0.3169 - val_loss: 0.0126 - val_psnr: 19.1892 - val_ssim: 0.5696 - lr: 1.0000e-04 - epoch_time_sec: 7.2724 - gpu_mean_current_mb: 21.7919 - gpu_peak_mb: 575.0620\n"
     ]
    }
   ],
   "source": [
    "# Train SRCNN and capture callbacks for metrics\n",
    "time_cb, mem_cb = model.fit(\n",
    "    X_train, Y_train, X_val, Y_val,\n",
    "    batch_size=16,\n",
    "    epochs=1,\n",
    "    use_augmentation=True,\n",
    "    use_mix=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a4e449b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0125 - psnr: 19.2357 - ssim: 0.5687\n",
      "Loss: 0.0125, PSNR: 19.24 dB, SSIM: 0.5687\n",
      "{'eval_loss': 0.012475560419261456, 'eval_psnr': 19.235689163208008, 'eval_ssim': 0.5686850547790527, 'epoch_time_sec': 7.27239000001282, 'memory': {'gpu_mean_current_mb': 21.7918701171875, 'gpu_peak_mb': 575.06201171875}}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate and prepare metrics dictionary\n",
    "results = model.evaluate(X_test, Y_test)\n",
    "metrics_dict = {\n",
    "    \"eval_loss\": float(results[0]),\n",
    "    \"eval_psnr\": float(results[1]),\n",
    "    \"eval_ssim\": float(results[2]),\n",
    "    \"epoch_time_sec\": time_cb.mean_time_value(),\n",
    "    \"memory\": mem_cb.as_dict()\n",
    "}\n",
    "print(metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4748ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to models/SRCNN/SRCNN_20250908_041140\\SRCNN_20250908_041140.h5\n"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Save the trained model\n",
    "model.save(directory=f\"models/SRCNN/SRCNN_{timestamp}\", timestamp=timestamp)\n",
    "\n",
    "# Save hr_h and hr_w for later use in the reconstruction of the images\n",
    "with open(os.path.abspath(os.path.join(os.getcwd(), f\"models/SRCNN/SRCNN_{timestamp}/SRCNN_{timestamp}_hrh_hrw.pkl\")), \"wb\") as f:\n",
    "    pickle.dump((hr_h, hr_w), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "637bfd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved metrics to c:\\Users\\bgmanuel\\InteligenciaArtificial\\MasterInteligenciaArtificial\\Periodo2\\TFM\\Super-Resolution-Images-for-3D-Printing-Defect-Detection\\SRModels\\deep_learning_models\\models\\SRCNN\\SRCNN_20250908_041140\\SRCNN_20250908_041140_metrics.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save evaluation/time/memory metrics next to the model\n",
    "metrics_path = os.path.abspath(os.path.join(os.getcwd(), f\"models/SRCNN/SRCNN_{timestamp}/SRCNN_{timestamp}_metrics.pkl\"))\n",
    "\n",
    "with open(metrics_path, \"wb\") as f:\n",
    "    pickle.dump(metrics_dict, f)\n",
    "    \n",
    "print(f\"Saved metrics to {metrics_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
