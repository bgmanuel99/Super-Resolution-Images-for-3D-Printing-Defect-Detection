{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b62c01c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import keras\n",
    "import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Conv2D, InputLayer\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential, load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2e4d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(folder_path, scale=2, patch_size=33, stride=14):\n",
    "    \"\"\"\n",
    "    Loads RGB high-resolution images and generates matching low-resolution patches.\n",
    "\n",
    "    Parameters:\n",
    "        folder_path (str): Path to folder containing HR images.\n",
    "        scale (int): Downscaling factor (e.g., 2, 3, 4).\n",
    "        patch_size (int): Size of output patch (default 33x33).\n",
    "        stride (int): Step size between patches.\n",
    "\n",
    "    Returns:\n",
    "        X (np.ndarray): Low-resolution RGB image patches (model input).\n",
    "        Y (np.ndarray): High-resolution RGB image patches (target).\n",
    "    \"\"\"\n",
    "    \n",
    "    X, Y = [], []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_COLOR)  # RGB\n",
    "            if img is None:\n",
    "                continue\n",
    "\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = img.astype(np.float32) / 255.0\n",
    "\n",
    "            h, w, _ = img.shape\n",
    "            h_scaled, w_scaled = h // scale, w // scale\n",
    "\n",
    "            # Simulate LR image by downscaling and then upscaling\n",
    "            img_lr = cv2.resize(img, (w_scaled, h_scaled), interpolation=cv2.INTER_CUBIC)\n",
    "            img_lr_up = cv2.resize(img_lr, (w, h), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "            # Extract patches\n",
    "            for i in range(0, h - patch_size + 1, stride):\n",
    "                for j in range(0, w - patch_size + 1, stride):\n",
    "                    hr_patch = img[i:i+patch_size, j:j+patch_size, :]\n",
    "                    lr_patch = img_lr_up[i:i+patch_size, j:j+patch_size, :]\n",
    "\n",
    "                    X.append(lr_patch)\n",
    "                    Y.append(hr_patch)\n",
    "\n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22385192",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRCNNModel:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self._trained = False\n",
    "        \n",
    "    def _psnr(y_true, y_pred):\n",
    "        max_pixel = 1.0\n",
    "        \n",
    "        return keras.metrics.PSNR(max_val=max_pixel)(y_true, y_pred)\n",
    "\n",
    "    def setup_model(self, input_shape=(33, 33, 1), learning_rate=1e-4, loss=\"mean_squared_error\", from_pretrained=False, pretrained_path=None):\n",
    "        \"\"\"Sets up the model: either loads pretrained or builds + compiles a new model.\"\"\"\n",
    "        \n",
    "        if from_pretrained:\n",
    "            if pretrained_path is None or not os.path.isfile(pretrained_path):\n",
    "                raise FileNotFoundError(f\"Pretrained model file not found at {pretrained_path}\")\n",
    "            \n",
    "            self.model = load_model(pretrained_path, custom_objects={\"psnr\": self._psnr})\n",
    "            print(f\"Loaded pretrained model from {pretrained_path}\")\n",
    "            self._trained = True\n",
    "        else:\n",
    "            self._build_model(input_shape)\n",
    "            self._compile_model(learning_rate, loss)\n",
    "\n",
    "    def _build_model(self, input_shape):\n",
    "        \"\"\"Builds the SRCNN model using Sequential API.\"\"\"\n",
    "        \n",
    "        self.model = Sequential([\n",
    "            InputLayer(input_shape=input_shape), \n",
    "            Conv2D(64, (9, 9), activation=\"relu\", padding=\"same\"),\n",
    "            Conv2D(32, (1, 1), activation=\"relu\", padding=\"same\"),\n",
    "            Conv2D(1, (5, 5), activation=\"linear\", padding=\"same\")\n",
    "        ])\n",
    "\n",
    "    def _compile_model(self, learning_rate, loss):\n",
    "        \"\"\"Compiles the model.\"\"\"\n",
    "        \n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "        self.model.compile(optimizer=optimizer, loss=loss, metrics=[self._psnr])\n",
    "\n",
    "    def fit(self, X, Y, batch_size=16, epochs=10, validation_split=0.1, use_augmentation=False):\n",
    "        \"\"\"Trains the model with optional data augmentation and callbacks.\"\"\"\n",
    "        \n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model has not been set up.\")\n",
    "        \n",
    "        devices = tf.config.list_physical_devices(\"GPU\")\n",
    "        if devices:\n",
    "            print(\"Training on GPU:\", devices[0].name)\n",
    "        else:\n",
    "            print(\"Training on CPU\")\n",
    "\n",
    "        # Callbacks\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
    "        ]\n",
    "\n",
    "        if use_augmentation:\n",
    "            datagen = ImageDataGenerator(\n",
    "                rotation_range=15,\n",
    "                width_shift_range=0.1,\n",
    "                height_shift_range=0.1,\n",
    "                zoom_range=0.1,\n",
    "                horizontal_flip=True\n",
    "            )\n",
    "            self.model.fit(\n",
    "                datagen.flow(X, Y, batch_size=batch_size),\n",
    "                steps_per_epoch=len(X) // batch_size,\n",
    "                epochs=epochs,\n",
    "                validation_split=validation_split,\n",
    "                callbacks=callbacks\n",
    "            )\n",
    "        else:\n",
    "            self.model.fit(\n",
    "                X, Y,\n",
    "                batch_size=batch_size,\n",
    "                epochs=epochs,\n",
    "                validation_split=validation_split,\n",
    "                callbacks=callbacks\n",
    "            )\n",
    "\n",
    "        self._trained = True\n",
    "\n",
    "    def evaluate(self, X_test, Y_test):\n",
    "        \"\"\"Evaluates the model.\"\"\"\n",
    "        \n",
    "        if not self._trained:\n",
    "            raise RuntimeError(\"Model has not been trained.\")\n",
    "        \n",
    "        results = self.model.evaluate(X_test, Y_test)\n",
    "        print(f\"Loss: {results[0]:.4f}, PSNR: {results[1]:.2f} dB\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def super_resolve_image(self, image_path, scale=2, patch_size=33, stride=14):\n",
    "        \"\"\"Performs super-resolution on a single image.\"\"\"\n",
    "        \n",
    "        if not self._trained:\n",
    "            raise RuntimeError(\"Model has not been trained.\")\n",
    "        if not os.path.isfile(image_path):\n",
    "            raise FileNotFoundError(f\"Image file not found at {image_path}\")\n",
    "        \n",
    "        def extract_patches_from_image(image, patch_size=33, stride=14):\n",
    "            \"\"\"Extracts patches from an image.\"\"\"\n",
    "            \n",
    "            h, w, _ = image.shape\n",
    "            patches = []\n",
    "            positions = []\n",
    "\n",
    "            for i in range(0, h - patch_size + 1, stride):\n",
    "                for j in range(0, w - patch_size + 1, stride):\n",
    "                    patch = image[i:i+patch_size, j:j+patch_size, :]\n",
    "                    patches.append(patch)\n",
    "                    positions.append((i, j))\n",
    "\n",
    "            return np.array(patches), positions, h, w\n",
    "\n",
    "        def reconstruct_from_patches(patches, positions, image_shape, patch_size=33):\n",
    "            \"\"\"Reconstructs an image from patches.\"\"\"\n",
    "            \n",
    "            h, w = image_shape[:2]\n",
    "            reconstructed = np.zeros((h, w, 3), dtype=np.float32)\n",
    "            weight = np.zeros((h, w, 3), dtype=np.float32)\n",
    "\n",
    "            for patch, (i, j) in zip(patches, positions):\n",
    "                reconstructed[i:i+patch_size, j:j+patch_size, :] += patch\n",
    "                weight[i:i+patch_size, j:j+patch_size, :] += 1.0\n",
    "\n",
    "            reconstructed /= np.maximum(weight, 1e-8)  # avoid division by zero\n",
    "            return np.clip(reconstructed, 0, 1)\n",
    "\n",
    "        # Load and normalize original image\n",
    "        img = cv2.imread(image_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "\n",
    "        # TODO: dont downscale, already LR, just upscale\n",
    "        # Downscale and upscale to simulate LR input\n",
    "        h, w = img.shape[:2]\n",
    "        img_lr = cv2.resize(img, (w // scale, h // scale), interpolation=cv2.INTER_CUBIC)\n",
    "        img_lr_up = cv2.resize(img_lr, (w, h), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        # Patchify\n",
    "        patches, positions, _, _ = extract_patches_from_image(img_lr_up, patch_size, stride)\n",
    "        patches = np.array(patches)\n",
    "\n",
    "        # Predict\n",
    "        preds = self.model.predict(patches, batch_size=16)\n",
    "\n",
    "        # Reconstruct\n",
    "        sr_img = reconstruct_from_patches(preds, positions, img.shape, patch_size)\n",
    "\n",
    "        return sr_img\n",
    "\n",
    "    def save(self, directory=\"models\"):\n",
    "        \"\"\"Saves the model to a .h5 file with a timestamp.\"\"\"\n",
    "        \n",
    "        if not self._trained:\n",
    "            raise RuntimeError(\"Cannot save an untrained model.\")\n",
    "        \n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        filepath = os.path.join(directory, f\"SRCNN_{timestamp}.h5\")\n",
    "        self.model.save(filepath)\n",
    "        print(f\"Model saved to {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa44862",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SRCNNModel()\n",
    "\n",
    "model.setup_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e523584b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = load_images(\"path_to_dataset\")\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6b05d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, epochs=50, use_augmentation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4e449b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4748ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4050d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SRCNNModel()\n",
    "\n",
    "model.setup_model(from_pretrained=True, pretrained_path=\"path_to_pretrained_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0be04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr_image = model.super_resolve_image(\"path/to/new_image.jpg\")\n",
    "sr_image_uint8 = (sr_image * 255).astype(np.uint8)\n",
    "\n",
    "plt.imshow(sr_image_uint8)\n",
    "plt.axis('off')\n",
    "plt.title(\"Super-Resolved Image\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
