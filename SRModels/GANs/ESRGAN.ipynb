{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa147a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import layers, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from keras.applications import VGG19, vgg19\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.losses import BinaryCrossentropy, MeanAbsoluteError, MeanSquaredError\n",
    "from keras.layers import Input, Conv2D, LeakyReLU, Add, Concatenate, GlobalAveragePooling2D, Dense, BatchNormalization, Lambda, Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54eac4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_as_patches(hr_root, lr_root, patch_size_lr=48, stride=24, scale_factor=2, max_patches_per_image=None):\n",
    "    \"\"\"\n",
    "    Loads HR and LR image patches from separate folders for EDSR training.\n",
    "    Extracts patches from both LR and HR images maintaining the scale factor relationship.\n",
    "\n",
    "    Parameters:\n",
    "        hr_root (str): Root path to HR images.\n",
    "        lr_root (str): Root path to LR images.\n",
    "        patch_size_lr (int): Size of LR patches (HR patches will be patch_size_lr * scale_factor).\n",
    "        scale_factor (int): The scale factor (2, 3, or 4).\n",
    "        stride (int): Stride for patch extraction.\n",
    "        max_patches_per_image (int): Maximum patches to extract per image (None for all).\n",
    "\n",
    "    Returns:\n",
    "        X (np.ndarray): Low-resolution patches (model input).\n",
    "        Y (np.ndarray): High-resolution patches (target).\n",
    "    \"\"\"\n",
    "    \n",
    "    def add_padding(image, patch_size, stride):\n",
    "        \"\"\"Add padding to ensure full coverage.\"\"\"\n",
    "        \n",
    "        h, w, c = image.shape\n",
    "        \n",
    "        # Calcular cu√°nto padding se necesita\n",
    "        pad_h = (patch_size - (h % stride)) % stride if h % stride != 0 else 0\n",
    "        pad_w = (patch_size - (w % stride)) % stride if w % stride != 0 else 0\n",
    "        \n",
    "        # Agregar padding extra para asegurar cobertura completa\n",
    "        pad_h = max(pad_h, patch_size - stride)\n",
    "        pad_w = max(pad_w, patch_size - stride)\n",
    "        \n",
    "        # Padding reflejado (mirror) para mantener continuidad\n",
    "        padded_img = np.pad(\n",
    "            image, \n",
    "            ((0, pad_h), (0, pad_w), (0, 0)), \n",
    "            mode='reflect'\n",
    "        )\n",
    "        \n",
    "        return padded_img\n",
    "    \n",
    "    if not os.path.exists(hr_root) or not os.path.exists(lr_root):\n",
    "        raise ValueError(\"Both HR and LR root directories must exist.\")\n",
    "    \n",
    "    patch_size_hr = patch_size_lr * scale_factor\n",
    "    X, Y = [], []\n",
    "\n",
    "    def get_all_image_paths(root):\n",
    "        image_paths = []\n",
    "        for dirpath, _, filenames in os.walk(root):\n",
    "            for filename in filenames:\n",
    "                if filename.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\")):\n",
    "                    image_paths.append(os.path.join(dirpath, filename))\n",
    "        return sorted(image_paths)\n",
    "\n",
    "    hr_paths = get_all_image_paths(hr_root)\n",
    "    lr_paths = get_all_image_paths(lr_root)\n",
    "\n",
    "    # Match HR and LR images by filename\n",
    "    hr_dict = {os.path.basename(p): p for p in hr_paths}\n",
    "    lr_dict = {os.path.basename(p): p for p in lr_paths}\n",
    "    common_filenames = sorted(set(hr_dict.keys()) & set(lr_dict.keys()))\n",
    "\n",
    "    if not common_filenames:\n",
    "        raise ValueError(\"No matching filenames found between HR and LR directories.\")\n",
    "\n",
    "    total_patches = 0\n",
    "    \n",
    "    for fname in common_filenames:\n",
    "        hr_img = cv2.imread(hr_dict[fname], cv2.IMREAD_COLOR)\n",
    "        lr_img = cv2.imread(lr_dict[fname], cv2.IMREAD_COLOR)\n",
    "\n",
    "        if hr_img is None or lr_img is None:\n",
    "            continue\n",
    "\n",
    "        # Convert to RGB and normalize\n",
    "        hr_img = cv2.cvtColor(hr_img, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
    "        lr_img = cv2.cvtColor(lr_img, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
    "\n",
    "        lr_h, lr_w, _ = lr_img.shape\n",
    "        hr_h, hr_w, _ = hr_img.shape\n",
    "        \n",
    "        # Add padding to ensure full coverage\n",
    "        hr_img = add_padding(hr_img, patch_size_hr, stride)\n",
    "        lr_img = add_padding(lr_img, patch_size_lr, stride)\n",
    "\n",
    "        # Generate patches\n",
    "        patches_this_image = 0\n",
    "        \n",
    "        for i in range(0, lr_h - patch_size_lr + 1, stride):\n",
    "            for j in range(0, lr_w - patch_size_lr + 1, stride):\n",
    "                # Extract LR patch\n",
    "                lr_patch = lr_img[i:i+patch_size_lr, j:j+patch_size_lr]\n",
    "                \n",
    "                # Extract corresponding HR patch\n",
    "                hr_i = i * scale_factor\n",
    "                hr_j = j * scale_factor\n",
    "                \n",
    "                if hr_i + patch_size_hr <= hr_h and hr_j + patch_size_hr <= hr_w:\n",
    "                    hr_patch = hr_img[hr_i:hr_i+patch_size_hr, hr_j:hr_j+patch_size_hr]\n",
    "                    \n",
    "                    X.append(lr_patch)\n",
    "                    Y.append(hr_patch)\n",
    "                    \n",
    "                    patches_this_image += 1\n",
    "                    total_patches += 1\n",
    "                    \n",
    "                    if max_patches_per_image and patches_this_image >= max_patches_per_image:\n",
    "                        break\n",
    "            \n",
    "            if max_patches_per_image and patches_this_image >= max_patches_per_image:\n",
    "                break\n",
    "\n",
    "    if not X:\n",
    "        raise ValueError(\"No patches could be extracted. Check your patch size and image dimensions.\")\n",
    "\n",
    "    X_array = np.array(X)\n",
    "    Y_array = np.array(Y)\n",
    "    \n",
    "    print(f\"Extracted {total_patches} patch pairs from {len(common_filenames)} images\")\n",
    "    print(f\"LR patches shape: {X_array.shape}\")\n",
    "    print(f\"HR patches shape: {Y_array.shape}\")\n",
    "\n",
    "    return X_array, Y_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1878495c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectralNormalization(Layer):\n",
    "    \"\"\"\n",
    "    Spectral Normalization layer for stabilizing GAN training by constraining \n",
    "    the Lipschitz constant of the discriminator.\n",
    "    \n",
    "    Parameters:\n",
    "    - layer: The layer to apply spectral normalization to\n",
    "    - power_iterations: Number of power iterations for spectral norm computation\n",
    "    \n",
    "    Returns:\n",
    "    - Normalized layer output\n",
    "    \"\"\"\n",
    "    def __init__(self, layer, power_iterations=1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.layer = layer\n",
    "        self.power_iterations = power_iterations\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.layer.build(input_shape)\n",
    "        \n",
    "        # Get the weight matrix\n",
    "        if hasattr(self.layer, 'kernel'):\n",
    "            self.kernel = self.layer.kernel\n",
    "        else:\n",
    "            raise ValueError(\"Layer must have a kernel attribute\")\n",
    "            \n",
    "        # Initialize u and v vectors for power iteration\n",
    "        kernel_shape = self.kernel.shape\n",
    "        self.u = self.add_weight(\n",
    "            shape=(1, kernel_shape[-1]),\n",
    "            initializer='random_normal',\n",
    "            trainable=False,\n",
    "            name='u'\n",
    "        )\n",
    "        \n",
    "        super().build(input_shape)\n",
    "    \n",
    "    def call(self, inputs, training=None):\n",
    "        # Power iteration method\n",
    "        u = self.u\n",
    "        \n",
    "        for _ in range(self.power_iterations):\n",
    "            # Reshape kernel for matrix multiplication\n",
    "            kernel_reshaped = tf.reshape(self.kernel, [-1, self.kernel.shape[-1]])\n",
    "            \n",
    "            # v = u @ W^T / ||u @ W^T||\n",
    "            v = tf.nn.l2_normalize(tf.matmul(u, kernel_reshaped, transpose_b=True))\n",
    "            \n",
    "            # u = v @ W / ||v @ W||\n",
    "            u = tf.nn.l2_normalize(tf.matmul(v, kernel_reshaped))\n",
    "        \n",
    "        if training:\n",
    "            self.u.assign(u)\n",
    "        \n",
    "        # Compute spectral norm\n",
    "        sigma = tf.matmul(tf.matmul(u, kernel_reshaped, transpose_b=True), \n",
    "                         tf.transpose(v))\n",
    "        \n",
    "        # Normalize the kernel\n",
    "        self.layer.kernel.assign(self.kernel / sigma)\n",
    "        \n",
    "        return self.layer(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66870c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESRGAN:\n",
    "    \"\"\"\n",
    "    Enhanced Super-Resolution Generative Adversarial Network (ESRGAN) implementation.\n",
    "    \n",
    "    This implementation includes all advanced features: spectral normalization,\n",
    "    learning rate scheduling, network interpolation, and data augmentation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, lr_size=(64, 64, 3), scale=2, vgg_layer='block5_conv4'):\n",
    "        \"\"\"\n",
    "        Initialize ESRGAN model.\n",
    "        \n",
    "        Parameters:\n",
    "        - lr_size: Tuple, shape of low-resolution input images (height, width, channels)\n",
    "        - scale: Int, upscaling factor (2, 4, or 8)\n",
    "        - vgg_layer: String, VGG layer name for perceptual loss computation\n",
    "        \n",
    "        Returns:\n",
    "        - None (initializes class attributes)\n",
    "        \"\"\"\n",
    "        self.lr_size = lr_size\n",
    "        self.hr_size = (lr_size[0]*scale, lr_size[1]*scale, 3)\n",
    "        self.scale = scale\n",
    "        self.vgg_layer = vgg_layer\n",
    "        \n",
    "        # Calculate number of upsampling blocks based on scale\n",
    "        self.num_upsample_blocks = int(np.log2(scale))\n",
    "        if 2**self.num_upsample_blocks != scale:\n",
    "            raise ValueError(f\"Scale must be a power of 2 (2, 4, 8). Got {scale}\")\n",
    "        \n",
    "        # Models will be initialized in setup_model\n",
    "        self.generator = None\n",
    "        self.discriminator = None\n",
    "        self.vgg = None\n",
    "        self.psnr_generator = None\n",
    "        \n",
    "        # Loss functions\n",
    "        self.bce = BinaryCrossentropy(from_logits=False)\n",
    "        self.l1 = MeanAbsoluteError()\n",
    "        self.mse = MeanSquaredError()\n",
    "        \n",
    "        # Learning rate configuration\n",
    "        self.initial_lr = 1e-4\n",
    "        self.g_optimizer = None\n",
    "        self.d_optimizer = None\n",
    "        self.g_lr_schedule = None\n",
    "        self.d_lr_schedule = None\n",
    "        self._trained = False\n",
    "\n",
    "    def setup_model(\n",
    "            self, \n",
    "            num_blocks=23, \n",
    "            filters=64, \n",
    "            growth_channels=32, \n",
    "            beta=0.2, \n",
    "            use_spectral_norm=True, \n",
    "            from_pretrained=False, \n",
    "            pretrained_path=None):\n",
    "        \"\"\"\n",
    "        Setup the ESRGAN model either from scratch or from pretrained weights.\n",
    "        \n",
    "        Parameters:\n",
    "        - from_pretrained: Bool, whether to load from pretrained weights\n",
    "        - pretrained_path: String, path to pretrained model files (without extension)\n",
    "        \n",
    "        Returns:\n",
    "        - None (initializes model components)\n",
    "        \"\"\"\n",
    "        generator_file = f\"{pretrained_path}_generator.h5\" if pretrained_path else None\n",
    "        discriminator_file = f\"{pretrained_path}_discriminator.h5\" if pretrained_path else None\n",
    "        psnr_generator_file = f\"{pretrained_path}_psnr_generator.h5\" if pretrained_path else None\n",
    "\n",
    "        if from_pretrained and pretrained_path and os.path.isfile(generator_file) and os.path.isfile(discriminator_file):\n",
    "            print(\"Loading pretrained models...\")\n",
    "            self.generator = load_model(generator_file, compile=False)\n",
    "            self.discriminator = load_model(discriminator_file, compile=False)\n",
    "            if os.path.isfile(psnr_generator_file):\n",
    "                self.psnr_generator = load_model(psnr_generator_file, compile=False)\n",
    "            else:\n",
    "                print(\"PSNR generator not found, will be created if needed...\")\n",
    "            print(\"Pretrained models loaded successfully!\")\n",
    "            self._trained = True\n",
    "        else:\n",
    "            print(\"Building new models...\")\n",
    "            self._build_new_models(num_blocks, filters, growth_channels, beta, use_spectral_norm)\n",
    "            self._trained = True\n",
    "\n",
    "        # Always build VGG for perceptual loss\n",
    "        self.vgg = self._build_vgg()\n",
    "        # Setup optimizers and learning rate schedules\n",
    "        self._setup_optimizers()\n",
    "\n",
    "    def _build_new_models(self, num_blocks, filters, growth_channels, beta, use_spectral_norm):\n",
    "        \"\"\"\n",
    "        Build new generator and discriminator models from scratch.\n",
    "        \n",
    "        Parameters:\n",
    "        - None\n",
    "        \n",
    "        Returns:\n",
    "        - None (sets self.generator and self.discriminator)\n",
    "        \"\"\"\n",
    "        self.generator = self._build_generator(num_blocks, filters, growth_channels, beta)\n",
    "        self.discriminator = self._build_discriminator(use_spectral_norm)\n",
    "\n",
    "    def _setup_optimizers(self):\n",
    "        \"\"\"\n",
    "        Setup optimizers and learning rate schedules.\n",
    "        \n",
    "        Parameters:\n",
    "        - None\n",
    "        \n",
    "        Returns:\n",
    "        - None (initializes optimizers and schedules)\n",
    "        \"\"\"\n",
    "        # Learning rate schedules\n",
    "        self.g_lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "            initial_learning_rate=self.initial_lr,\n",
    "            decay_steps=50000,\n",
    "            decay_rate=0.5,\n",
    "            staircase=True\n",
    "        )\n",
    "        self.d_lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "            initial_learning_rate=self.initial_lr,\n",
    "            decay_steps=50000,\n",
    "            decay_rate=0.5,\n",
    "            staircase=True\n",
    "        )\n",
    "        \n",
    "        # Optimizers\n",
    "        self.g_optimizer = Adam(self.initial_lr, beta_1=0.9)\n",
    "        self.d_optimizer = Adam(self.initial_lr, beta_1=0.9)\n",
    "\n",
    "    def _dense_block(self, x, filters, growth_channels, beta):\n",
    "        \"\"\"\n",
    "        Dense block with growth connections for feature reuse.\n",
    "        \n",
    "        Parameters:\n",
    "        - x: Tensor, input feature maps\n",
    "        - filters: Int, number of output filters\n",
    "        - growth_channels: Int, number of channels added by each layer\n",
    "        - beta: Float, residual scaling factor\n",
    "        \n",
    "        Returns:\n",
    "        - Tensor, output feature maps with residual connection\n",
    "        \"\"\"\n",
    "        inputs = x\n",
    "        concat_layers = [x]\n",
    "        \n",
    "        for i in range(5):\n",
    "            if i > 0:\n",
    "                x = Concatenate()(concat_layers)\n",
    "            \n",
    "            out = Conv2D(growth_channels, 3, padding='same')(x)\n",
    "            out = LeakyReLU(0.2)(out)\n",
    "            concat_layers.append(out)\n",
    "        \n",
    "        x = Concatenate()(concat_layers)\n",
    "        out = Conv2D(filters, 1, padding='same')(x)\n",
    "        out = Lambda(lambda x: x * beta)(out)\n",
    "        return Add()([out, inputs])\n",
    "\n",
    "    def _rrdb_block(self, x, filters, growth_channels, beta):\n",
    "        \"\"\"\n",
    "        Residual-in-Residual Dense Block - core building block of ESRGAN generator.\n",
    "        \n",
    "        Parameters:\n",
    "        - x: Tensor, input feature maps\n",
    "        - filters: Int, number of filters\n",
    "        - beta: Float, residual scaling factor for stability\n",
    "        \n",
    "        Returns:\n",
    "        - Tensor, output feature maps with nested residual connections\n",
    "        \"\"\"\n",
    "        inputs = x\n",
    "        \n",
    "        for _ in range(3):\n",
    "            x = self._dense_block(x, filters, growth_channels, beta)\n",
    "        \n",
    "        x = Lambda(lambda x: x * beta)(x)\n",
    "        return Add()([inputs, x])\n",
    "\n",
    "    def _build_generator(self, num_blocks, filters, growth_channels, beta):\n",
    "        \"\"\"\n",
    "        Build the ESRGAN generator network with RRDB blocks.\n",
    "        \n",
    "        Parameters:\n",
    "        - num_blocks: Int, number of RRDB blocks\n",
    "        - filters: Int, number of base filters\n",
    "        \n",
    "        Returns:\n",
    "        - Model, Keras model for the generator\n",
    "        \"\"\"\n",
    "        inputs = Input(shape=self.lr_size)\n",
    "        \n",
    "        x = Conv2D(filters, 3, padding='same')(inputs)\n",
    "        conv1 = x\n",
    "\n",
    "        for _ in range(num_blocks):\n",
    "            x = self._rrdb_block(x, filters, growth_channels, beta)\n",
    "\n",
    "        x = Conv2D(filters, 3, padding='same')(x)\n",
    "        x = Add()([x, conv1])\n",
    "\n",
    "        # Upsampling blocks (adaptive based on scale)\n",
    "        for _ in range(self.num_upsample_blocks):\n",
    "            x = Conv2D(filters * 4, 3, padding='same')(x)\n",
    "            x = Lambda(lambda x: tf.nn.depth_to_space(x, 2))(x)\n",
    "            x = LeakyReLU(0.2)(x)\n",
    "\n",
    "        out = Conv2D(3, 3, padding='same', activation='tanh')(x)\n",
    "        return Model(inputs, out, name=\"Generator\")\n",
    "\n",
    "    def _build_discriminator(self, use_spectral_norm):\n",
    "        \"\"\"\n",
    "        Build the discriminator network with optional spectral normalization.\n",
    "        \n",
    "        Parameters:\n",
    "        - use_spectral_norm: Bool, whether to apply spectral normalization\n",
    "        \n",
    "        Returns:\n",
    "        - Model, Keras model for the discriminator\n",
    "        \"\"\"\n",
    "        def d_block(x, filters, strides=1, bn=True, sn=True):\n",
    "            \"\"\"\n",
    "            Discriminator convolutional block.\n",
    "            \n",
    "            Parameters:\n",
    "            - x: Tensor, input\n",
    "            - filters: Int, number of filters\n",
    "            - strides: Int, convolution stride\n",
    "            - bn: Bool, whether to use batch normalization\n",
    "            - sn: Bool, whether to use spectral normalization\n",
    "            \n",
    "            Returns:\n",
    "            - Tensor, processed feature maps\n",
    "            \"\"\"\n",
    "            if sn and use_spectral_norm:\n",
    "                conv_layer = Conv2D(filters, 3, strides=strides, padding='same')\n",
    "                x = SpectralNormalization(conv_layer)(x)\n",
    "            else:\n",
    "                x = Conv2D(filters, 3, strides=strides, padding='same')(x)\n",
    "            \n",
    "            if bn:\n",
    "                x = BatchNormalization()(x)\n",
    "            return LeakyReLU(0.2)(x)\n",
    "\n",
    "        inputs = layers.Input(shape=self.hr_size)\n",
    "        x = d_block(inputs, 64, bn=False)\n",
    "        x = d_block(x, 64, strides=2)\n",
    "        x = d_block(x, 128)\n",
    "        x = d_block(x, 128, strides=2)\n",
    "        x = d_block(x, 256)\n",
    "        x = d_block(x, 256, strides=2)\n",
    "        x = d_block(x, 512)\n",
    "        x = d_block(x, 512, strides=2)\n",
    "        \n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dense(1024)(x)\n",
    "        x = LeakyReLU(0.2)(x)\n",
    "        out = Dense(1)(x)\n",
    "        \n",
    "        return Model(inputs, out, name=\"Discriminator\")\n",
    "\n",
    "    def _build_vgg(self):\n",
    "        \"\"\"\n",
    "        Build VGG19 network for perceptual loss computation.\n",
    "        \n",
    "        Parameters:\n",
    "        - None\n",
    "        \n",
    "        Returns:\n",
    "        - Model, VGG19 model for feature extraction\n",
    "        \"\"\"\n",
    "        vgg = VGG19(weights='imagenet', include_top=False, input_shape=self.hr_size)\n",
    "        vgg.trainable = False\n",
    "        \n",
    "        def preprocess_vgg(x):\n",
    "            \"\"\"\n",
    "            Preprocess images for VGG19 input.\n",
    "            \n",
    "            Parameters:\n",
    "            - x: Tensor, input images in [-1, 1] range\n",
    "            \n",
    "            Returns:\n",
    "            - Tensor, preprocessed images for VGG19\n",
    "            \"\"\"\n",
    "            x = (x + 1.0) * 127.5\n",
    "            return vgg19.preprocess_input(x)\n",
    "        \n",
    "        inputs = Input(shape=self.hr_size)\n",
    "        x = Lambda(preprocess_vgg)(inputs)\n",
    "        x = vgg(x)\n",
    "        features = vgg.get_layer(self.vgg_layer)(x)\n",
    "        \n",
    "        return Model(inputs, features)\n",
    "\n",
    "    def _data_augmentation(self, lr_batch, hr_batch):\n",
    "        \"\"\"\n",
    "        Apply data augmentation to training batches.\n",
    "        \n",
    "        Parameters:\n",
    "        - lr_batch: Tensor, batch of low-resolution images\n",
    "        - hr_batch: Tensor, batch of high-resolution images\n",
    "        \n",
    "        Returns:\n",
    "        - Tuple of Tensors, augmented (lr_batch, hr_batch)\n",
    "        \"\"\"\n",
    "        batch_size = tf.shape(lr_batch)[0]\n",
    "        \n",
    "        # Random horizontal flip\n",
    "        flip_prob = tf.random.uniform([batch_size, 1, 1, 1])\n",
    "        lr_batch = tf.where(flip_prob < 0.5, \n",
    "                           tf.image.flip_left_right(lr_batch), lr_batch)\n",
    "        hr_batch = tf.where(flip_prob < 0.5, \n",
    "                           tf.image.flip_left_right(hr_batch), hr_batch)\n",
    "        \n",
    "        # Random vertical flip\n",
    "        flip_prob = tf.random.uniform([batch_size, 1, 1, 1])\n",
    "        lr_batch = tf.where(flip_prob < 0.5, \n",
    "                           tf.image.flip_up_down(lr_batch), lr_batch)\n",
    "        hr_batch = tf.where(flip_prob < 0.5, \n",
    "                           tf.image.flip_up_down(hr_batch), hr_batch)\n",
    "        \n",
    "        # Random 90-degree rotations\n",
    "        k = tf.random.uniform([batch_size], maxval=4, dtype=tf.int32)\n",
    "        lr_batch = tf.image.rot90(lr_batch, k=k[0])  # Simplified for batch\n",
    "        hr_batch = tf.image.rot90(hr_batch, k=k[0])\n",
    "        \n",
    "        return lr_batch, hr_batch\n",
    "\n",
    "    def _build_psnr_generator(self, num_blocks, filters, growth_channels, beta):\n",
    "        \"\"\"\n",
    "        Build and setup PSNR-oriented generator for network interpolation.\n",
    "        \n",
    "        Parameters:\n",
    "        - num_blocks: Int, number of RRDB blocks in PSNR generator\n",
    "        - filters: Int, number of filters in PSNR generator\n",
    "        - growth_channels: Int, number of growth channels in PSNR generator\n",
    "        - beta: Float, residual scaling factor for PSNR generator\n",
    "        \n",
    "        Returns:\n",
    "        - Function, PSNR training step function\n",
    "        \"\"\"\n",
    "        self.psnr_generator = self._build_generator(num_blocks, filters, growth_channels, beta)\n",
    "        \n",
    "        # PSNR training uses only MSE loss\n",
    "        psnr_optimizer = Adam(1e-4)\n",
    "        \n",
    "        @tf.function\n",
    "        def psnr_train_step(lr, hr):\n",
    "            \"\"\"\n",
    "            Single PSNR training step.\n",
    "            \n",
    "            Parameters:\n",
    "            - lr: Tensor, low-resolution images\n",
    "            - hr: Tensor, high-resolution images\n",
    "            \n",
    "            Returns:\n",
    "            - Tensor, MSE loss value\n",
    "            \"\"\"\n",
    "            with tf.GradientTape() as tape:\n",
    "                sr = self.psnr_generator(lr, training=True)\n",
    "                loss = self.mse(hr, sr)\n",
    "            \n",
    "            grads = tape.gradient(loss, self.psnr_generator.trainable_variables)\n",
    "            psnr_optimizer.apply_gradients(zip(grads, self.psnr_generator.trainable_variables))\n",
    "            return loss\n",
    "        \n",
    "        return psnr_train_step\n",
    "\n",
    "    def _interpolate_networks(self, alpha=0.2):\n",
    "        \"\"\"\n",
    "        Perform network interpolation between PSNR and GAN models.\n",
    "        \n",
    "        Parameters:\n",
    "        - alpha: Float, interpolation factor (0=full GAN, 1=full PSNR)\n",
    "        \n",
    "        Returns:\n",
    "        - None (modifies generator weights in-place)\n",
    "        \"\"\"\n",
    "        if self.psnr_generator is None:\n",
    "            raise ValueError(\"PSNR generator not built. Call build_psnr_generator first.\")\n",
    "        \n",
    "        # Interpolate weights\n",
    "        for psnr_var, gan_var in zip(self.psnr_generator.trainable_variables, \n",
    "                                    self.generator.trainable_variables):\n",
    "            interpolated = alpha * psnr_var + (1 - alpha) * gan_var\n",
    "            gan_var.assign(interpolated)\n",
    "\n",
    "    def _perceptual_loss(self, hr, sr):\n",
    "        \"\"\"\n",
    "        Compute perceptual loss using VGG19 features.\n",
    "        \n",
    "        Parameters:\n",
    "        - hr: Tensor, high-resolution ground truth images\n",
    "        - sr: Tensor, super-resolved images\n",
    "        \n",
    "        Returns:\n",
    "        - Tensor, perceptual loss value\n",
    "        \"\"\"\n",
    "        sr_features = self.vgg(sr)\n",
    "        hr_features = self.vgg(hr)\n",
    "        return self.l1(hr_features, sr_features)\n",
    "\n",
    "    def _relativistic_discriminator_loss(self, real_logits, fake_logits):\n",
    "        \"\"\"\n",
    "        Compute relativistic discriminator loss.\n",
    "        \n",
    "        Parameters:\n",
    "        - real_logits: Tensor, discriminator output for real images\n",
    "        - fake_logits: Tensor, discriminator output for fake images\n",
    "        \n",
    "        Returns:\n",
    "        - Tensor, relativistic discriminator loss\n",
    "        \"\"\"\n",
    "        real_loss = tf.reduce_mean(\n",
    "            tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                labels=tf.ones_like(real_logits),\n",
    "                logits=real_logits - tf.reduce_mean(fake_logits)\n",
    "            )\n",
    "        )\n",
    "        fake_loss = tf.reduce_mean(\n",
    "            tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                labels=tf.zeros_like(fake_logits),\n",
    "                logits=fake_logits - tf.reduce_mean(real_logits)\n",
    "            )\n",
    "        )\n",
    "        return real_loss + fake_loss\n",
    "\n",
    "    def _relativistic_generator_loss(self, real_logits, fake_logits):\n",
    "        \"\"\"\n",
    "        Compute relativistic generator loss.\n",
    "        \n",
    "        Parameters:\n",
    "        - real_logits: Tensor, discriminator output for real images\n",
    "        - fake_logits: Tensor, discriminator output for fake images\n",
    "        \n",
    "        Returns:\n",
    "        - Tensor, relativistic generator loss\n",
    "        \"\"\"\n",
    "        fake_loss = tf.reduce_mean(\n",
    "            tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                labels=tf.ones_like(fake_logits),\n",
    "                logits=fake_logits - tf.reduce_mean(real_logits)\n",
    "            )\n",
    "        )\n",
    "        real_loss = tf.reduce_mean(\n",
    "            tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                labels=tf.zeros_like(real_logits),\n",
    "                logits=real_logits - tf.reduce_mean(fake_logits)\n",
    "            )\n",
    "        )\n",
    "        return fake_loss + real_loss\n",
    "\n",
    "    def _update_learning_rates(self, step):\n",
    "        \"\"\"\n",
    "        Update learning rates according to schedules.\n",
    "        \n",
    "        Parameters:\n",
    "        - step: Int, current training step\n",
    "        \n",
    "        Returns:\n",
    "        - None (updates optimizer learning rates)\n",
    "        \"\"\"\n",
    "        new_g_lr = self.g_lr_schedule(step)\n",
    "        new_d_lr = self.d_lr_schedule(step)\n",
    "        \n",
    "        self.g_optimizer.learning_rate.assign(new_g_lr)\n",
    "        self.d_optimizer.learning_rate.assign(new_d_lr)\n",
    "\n",
    "    @tf.function(reduce_retracing=True)\n",
    "    def _train_step(self, lr, hr, step, use_augmentation):\n",
    "        \"\"\"\n",
    "        Single training step for ESRGAN.\n",
    "        \n",
    "        Parameters:\n",
    "        - lr: Tensor, batch of low-resolution images\n",
    "        - hr: Tensor, batch of high-resolution images\n",
    "        - step: Tensor, current training step\n",
    "        - use_augmentation: Bool, whether to apply data augmentation\n",
    "        \n",
    "        Returns:\n",
    "        - Dict, training metrics and losses\n",
    "        \"\"\"\n",
    "        if use_augmentation:\n",
    "            lr, hr = self._data_augmentation(lr, hr)\n",
    "        \n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            sr = self.generator(lr, training=True)\n",
    "\n",
    "            real_logits = self.discriminator(hr, training=True)\n",
    "            fake_logits = self.discriminator(sr, training=True)\n",
    "\n",
    "            # Discriminator loss\n",
    "            d_loss = self._relativistic_discriminator_loss(real_logits, fake_logits)\n",
    "\n",
    "            # Generator losses\n",
    "            perceptual = self._perceptual_loss(hr, sr)\n",
    "            adv_loss = self._relativistic_generator_loss(real_logits, fake_logits)\n",
    "            pixel_loss = self.l1(hr, sr)\n",
    "\n",
    "            # Combined generator loss\n",
    "            g_loss = 5e-3 * adv_loss + 1.0 * perceptual + 1e-2 * pixel_loss\n",
    "\n",
    "        # Apply gradients\n",
    "        grads_g = tape.gradient(g_loss, self.generator.trainable_variables)\n",
    "        grads_d = tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
    "\n",
    "        self.g_optimizer.apply_gradients(zip(grads_g, self.generator.trainable_variables))\n",
    "        self.d_optimizer.apply_gradients(zip(grads_d, self.discriminator.trainable_variables))\n",
    "\n",
    "        # Update learning rates\n",
    "        self._update_learning_rates(step)\n",
    "\n",
    "        return {\n",
    "            \"psnr\": tf.image.psnr(hr, sr, max_val=2.0),  # Assuming tanh output [-1, 1]\n",
    "            \"ssim\": tf.image.ssim(hr, sr, max_val=2.0),  # Assuming tanh output [-1, 1]\n",
    "            'g_loss': g_loss,\n",
    "            'd_loss': d_loss,\n",
    "            'perceptual_loss': perceptual,\n",
    "            'pixel_loss': pixel_loss,\n",
    "            'adv_loss': adv_loss,\n",
    "            'g_lr': self.g_optimizer.learning_rate,\n",
    "            'd_lr': self.d_optimizer.learning_rate\n",
    "        }\n",
    "\n",
    "    def _train_psnr_phase(self, dataset, epochs, num_blocks, filters, growth_channels, beta):\n",
    "        \"\"\"\n",
    "        Pre-train generator with PSNR (MSE) loss only.\n",
    "        \n",
    "        Parameters:\n",
    "        - dataset: tf.data.Dataset, training dataset\n",
    "        - epochs: Int, number of PSNR training epochs\n",
    "        - num_blocks: Int, number of RRDB blocks in PSNR generator\n",
    "        - filters: Int, number of filters in PSNR generator\n",
    "        - growth_channels: Int, number of growth channels in PSNR generator\n",
    "        - beta: Float, residual scaling factor for PSNR generator\n",
    "        \n",
    "        Returns:\n",
    "        - None (trains self.psnr_generator)\n",
    "        \"\"\"\n",
    "        print(\"Starting PSNR pre-training...\")\n",
    "        psnr_train_step = self._build_psnr_generator(num_blocks, filters, growth_channels, beta)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            print(f\"PSNR Epoch {epoch+1}/{epochs}\")\n",
    "            for step, (lr, hr) in enumerate(dataset):\n",
    "                loss = psnr_train_step(lr, hr)\n",
    "                if step % 100 == 0:\n",
    "                    print(f\"Step {step}: PSNR Loss: {float(loss):.4f}\")\n",
    "\n",
    "    def fit(\n",
    "            self, \n",
    "            dataset, \n",
    "            epochs=100, \n",
    "            psnr_epochs=0, \n",
    "            interpolation_alpha=0.2, \n",
    "            use_agmentation=True, \n",
    "            val_dataset=None, \n",
    "            val_metrics=None,\n",
    "            val_max_batches=None, \n",
    "            num_blocks=23, \n",
    "            filters=64, \n",
    "            growth_channels=32, \n",
    "            beta=0.2):\n",
    "        \"\"\"\n",
    "        Full training pipeline with optional PSNR pre-training and network interpolation.\n",
    "        \n",
    "        Parameters:\n",
    "        - dataset: tf.data.Dataset, training dataset with (lr, hr) pairs\n",
    "        - epochs: Int, number of GAN training epochs\n",
    "        - psnr_epochs: Int, number of PSNR pre-training epochs (0 to skip)\n",
    "        - interpolation_alpha: Float, network interpolation factor\n",
    "        - use_agmentation: Bool, whether to apply data augmentation\n",
    "        - val_dataset: tf.data.Dataset, validation dataset for evaluation\n",
    "        - val_metrics: List of metric functions for validation\n",
    "        - val_max_batches: Int or None, maximum number of validation batches to evaluate\n",
    "        - num_blocks: Int, number of RRDB blocks in generator\n",
    "        - filters: Int, number of filters in generator\n",
    "        - growth_channels: Int, number of growth channels in generator\n",
    "        - beta: Float, residual scaling factor for generator\n",
    "        \n",
    "        Returns:\n",
    "        - None (trains the model)\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.generator is None:\n",
    "            raise ValueError(\"Model not setup. Call setup_model() first.\")\n",
    "            \n",
    "        global_step = 0\n",
    "        \n",
    "        # PSNR pre-training\n",
    "        if psnr_epochs > 0:\n",
    "            self._train_psnr_phase(dataset, psnr_epochs, num_blocks, filters, growth_channels, beta)\n",
    "            # Copy PSNR weights to main generator\n",
    "            for psnr_var, gan_var in zip(self.psnr_generator.trainable_variables, self.generator.trainable_variables):\n",
    "                gan_var.assign(psnr_var)\n",
    "        \n",
    "        # GAN training\n",
    "        print(\"Starting GAN training...\")\n",
    "        for epoch in range(epochs):\n",
    "            print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "            for step, (lr, hr) in enumerate(dataset):\n",
    "                logs = self._train_step(lr, hr, global_step, use_agmentation)\n",
    "                global_step += 1\n",
    "                \n",
    "                if step % 10 == 0:\n",
    "                    print({k: f\"{tf.reduce_mean(v).numpy():.4f}\" for k, v in logs.items()})\n",
    "                \n",
    "                # Network interpolation every 1000 steps\n",
    "                if global_step % 1000 == 0 and self.psnr_generator is not None:\n",
    "                    self._interpolate_networks(interpolation_alpha)\n",
    "                    print(f\"Applied network interpolation with alpha={interpolation_alpha}\")\n",
    "            \n",
    "            # Validation step\n",
    "            if val_dataset is not None:\n",
    "                self._evaluate(val_dataset, metrics=val_metrics, max_batches=val_max_batches)\n",
    "                    \n",
    "        self._trained = True\n",
    "        \n",
    "    def _evaluate(self, dataset, metrics=None, max_batches=None):\n",
    "        \"\"\"\n",
    "        Evaluate the trained model on a dataset.\n",
    "\n",
    "        Parameters:\n",
    "        - dataset: tf.data.Dataset, dataset of (lr, hr) pairs\n",
    "        - metrics: list of metric functions, each should accept (y_true, y_pred)\n",
    "        - max_batches: int or None, maximum number of batches to evaluate\n",
    "\n",
    "        Returns:\n",
    "        - results: dict of metric names and their average values\n",
    "        \"\"\"\n",
    "        if not self._trained:\n",
    "            raise ValueError(\"Model is not trained or loaded. Please train or load a pretrained model first.\")\n",
    "\n",
    "        if metrics is None:\n",
    "            # Default metrics: PSNR and L1 loss\n",
    "            def psnr(y_true, y_pred):\n",
    "                return tf.image.psnr(y_true, y_pred, max_val=2.0)  # assuming tanh output [-1,1]\n",
    "            def ssim(y_true, y_pred):\n",
    "                return tf.image.ssim(y_true, y_pred, max_val=2.0)  # assuming tanh output [-1,1]\n",
    "            def l1(y_true, y_pred):\n",
    "                return tf.reduce_mean(tf.abs(y_true - y_pred))\n",
    "            metrics = [(\"PSNR\", psnr), (\"SSIM\", ssim), (\"L1\", l1)]\n",
    "\n",
    "        results = {name: [] for name, _ in metrics}\n",
    "        for i, (lr, hr) in enumerate(dataset):\n",
    "            if max_batches is not None and i >= max_batches:\n",
    "                break\n",
    "            sr = self.generator(lr, training=False)\n",
    "            for name, func in metrics:\n",
    "                results[name].append(func(hr, sr).numpy())\n",
    "\n",
    "        # Average results\n",
    "        avg_results = {name: float(np.mean(vals)) for name, vals in results.items()}\n",
    "        print(\"Evaluation results:\", avg_results)\n",
    "        return avg_results\n",
    "\n",
    "    def super_resolve(self, lr_image):\n",
    "        \"\"\"\n",
    "        Super-resolve a single image or batch of images.\n",
    "        \n",
    "        Parameters:\n",
    "        - lr_image: Tensor, low-resolution image(s) to super-resolve\n",
    "        \n",
    "        Returns:\n",
    "        - Tensor, super-resolved image(s)\n",
    "        \"\"\"\n",
    "        if not self._trained:\n",
    "            raise ValueError(\"Model is not trained or loaded. Please train or load a pretrained model first.\")\n",
    "            \n",
    "        if len(lr_image.shape) == 3:\n",
    "            lr_image = tf.expand_dims(lr_image, axis=0)\n",
    "        sr = self.generator(lr_image, training=False)\n",
    "        if lr_image.shape[0] == 1:\n",
    "            sr = tf.squeeze(sr, axis=0)\n",
    "        return sr\n",
    "\n",
    "    def save(self, directory=\"models/ESRGAN\"):\n",
    "        \"\"\"\n",
    "        Save all model components to disk.\n",
    "        \n",
    "        Parameters:\n",
    "        - path: String, base path for saving models (without extension)\n",
    "        \n",
    "        Returns:\n",
    "        - None (saves models to disk)\n",
    "        \"\"\"\n",
    "        if not self._trained:\n",
    "            raise ValueError(\"Model is not trained or loaded. Please train or load a pretrained model first.\")\n",
    "        \n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        generator_path = os.path.join(directory, f\"ESRGAN_x{self.scale}_{timestamp}_generator.h5\")\n",
    "        discriminator_path = os.path.join(directory, f\"ESRGAN_x{self.scale}_{timestamp}_discriminator.h5\")\n",
    "        psnr_generator_path = os.path.join(directory, f\"ESRGAN_x{self.scale}_{timestamp}_psnr_generator.h5\")\n",
    "        self.generator.save(generator_path)\n",
    "        self.discriminator.save(discriminator_path)\n",
    "        if self.psnr_generator is not None:\n",
    "            self.psnr_generator.save(psnr_generator_path)\n",
    "        print(f\"Generator model saved to {generator_path}\")\n",
    "        print(f\"Discriminator model saved to {discriminator_path}\")\n",
    "        print(f\"PSNR generator model saved to {psnr_generator_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9954ea28",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATCH_SIZE_LR = 24\n",
    "STRIDE = 12\n",
    "SCALE_FACTOR = 2\n",
    "NUM_BLOCKS = 23\n",
    "FILTERS = 64\n",
    "GROWTH_CHANNELS = 32\n",
    "BETA = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "594f3fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 274104 patch pairs from 846 images\n",
      "LR patches shape: (274104, 24, 24, 3)\n",
      "HR patches shape: (274104, 48, 48, 3)\n",
      "X_train shape: (222023, 24, 24, 3), Y_train shape: (222023, 48, 48, 3)\n",
      "X_val shape: (24670, 24, 24, 3), Y_val shape: (24670, 48, 48, 3)\n",
      "X_test shape: (27411, 24, 24, 3), Y_test shape: (27411, 48, 48, 3)\n"
     ]
    }
   ],
   "source": [
    "X, Y = load_dataset_as_patches(\"../../data/images/HR\", \"../../data/images/LR\", patch_size_lr=PATCH_SIZE_LR, stride=STRIDE, scale_factor=SCALE_FACTOR)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, shuffle=True, random_state=42)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.1, shuffle=True, random_state=42)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}, Y_train shape: {Y_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}, Y_val shape: {Y_val.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}, Y_test shape: {Y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f2f2452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a generator to avoid memory issues\n",
    "def data_generator(X, Y):\n",
    "    for x, y in zip(X, Y):\n",
    "        yield x, y\n",
    "\n",
    "output_signature = (\n",
    "    tf.TensorSpec(shape=X_train.shape[1:], dtype=tf.float32),\n",
    "    tf.TensorSpec(shape=Y_train.shape[1:], dtype=tf.float32)\n",
    ")\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: data_generator(X_train, Y_train),\n",
    "    output_signature=output_signature\n",
    ").batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: data_generator(X_val, Y_val),\n",
    "    output_signature=output_signature\n",
    ").batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: data_generator(X_test, Y_test),\n",
    "    output_signature=output_signature\n",
    ").batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e7f25ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building new models...\n"
     ]
    }
   ],
   "source": [
    "model = ESRGAN(lr_size=(PATCH_SIZE_LR, PATCH_SIZE_LR, 3), scale=SCALE_FACTOR)\n",
    "\n",
    "model.setup_model(\n",
    "    num_blocks=NUM_BLOCKS, \n",
    "    filters=FILTERS, \n",
    "    growth_channels=GROWTH_CHANNELS, \n",
    "    beta=BETA, \n",
    "    use_spectral_norm=True, \n",
    "    from_pretrained=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a434389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting PSNR pre-training...\n",
      "PSNR Epoch 1/5\n",
      "Step 0: PSNR Loss: 1.9934\n",
      "Step 100: PSNR Loss: 0.1170\n",
      "Step 200: PSNR Loss: 0.1068\n",
      "Step 300: PSNR Loss: 0.1157\n",
      "Step 400: PSNR Loss: 0.1204\n",
      "Step 500: PSNR Loss: 0.1498\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterpolation_alpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpsnr_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_agmentation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_blocks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_BLOCKS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFILTERS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrowth_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mGROWTH_CHANNELS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBETA\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 595\u001b[0m, in \u001b[0;36mESRGAN.fit\u001b[1;34m(self, dataset, epochs, psnr_epochs, interpolation_alpha, use_agmentation, val_dataset, val_metrics, val_max_batches, num_blocks, filters, growth_channels, beta)\u001b[0m\n\u001b[0;32m    593\u001b[0m \u001b[38;5;66;03m# PSNR pre-training\u001b[39;00m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m psnr_epochs \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 595\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_psnr_phase\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpsnr_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_blocks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrowth_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# Copy PSNR weights to main generator\u001b[39;00m\n\u001b[0;32m    597\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m psnr_var, gan_var \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpsnr_generator\u001b[38;5;241m.\u001b[39mtrainable_variables, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerator\u001b[38;5;241m.\u001b[39mtrainable_variables):\n",
      "Cell \u001b[1;32mIn[11], line 549\u001b[0m, in \u001b[0;36mESRGAN._train_psnr_phase\u001b[1;34m(self, dataset, epochs, num_blocks, filters, growth_channels, beta)\u001b[0m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPSNR Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    548\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, (lr, hr) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataset):\n\u001b[1;32m--> 549\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mpsnr_train_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    550\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    551\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: PSNR Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mfloat\u001b[39m(loss)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\bgmanuel\\anaconda3\\envs\\py310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\bgmanuel\\anaconda3\\envs\\py310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\bgmanuel\\anaconda3\\envs\\py310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\bgmanuel\\anaconda3\\envs\\py310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bgmanuel\\anaconda3\\envs\\py310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\bgmanuel\\anaconda3\\envs\\py310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\bgmanuel\\anaconda3\\envs\\py310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_dataset,\n",
    "    epochs=10,\n",
    "    interpolation_alpha=0.2,\n",
    "    psnr_epochs=5, \n",
    "    use_agmentation=True,\n",
    "    val_dataset=val_dataset, \n",
    "    num_blocks=NUM_BLOCKS,\n",
    "    filters=FILTERS,\n",
    "    growth_channels=GROWTH_CHANNELS,\n",
    "    beta=BETA\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
