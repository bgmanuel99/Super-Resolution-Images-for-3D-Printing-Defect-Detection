{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f26f0a5",
   "metadata": {},
   "source": [
    "# VGG16 fine-tuning for defect detection\n",
    "\n",
    "This section builds a VGG16 model with ImageNet weights, lets you choose any valid input shape (HxWx3), and fine-tune only the last layers you specify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82c2da04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../../\")))\n",
    "from SRModels.defect_detection_models.VGG16_model import FineTunedVGG16\n",
    "from SRModels.loading_methods import load_defects_dataset_as_patches\n",
    "from SRModels.constants import VGG_PATCH_SIZE, VGG_STRIDE, RANDOM_SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "999f12f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "HR_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"../../data/images/HR\"))\n",
    "CLASS_LABELS_PATH = os.path.abspath(os.path.join(os.getcwd(), \"../../data/images/class_labels_map.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee59aaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X ->  High-resolution patches (model input)\n",
    "# y -> Class labels (target)\n",
    "X, y = load_defects_dataset_as_patches(HR_ROOT, patch_size=VGG_PATCH_SIZE, stride=VGG_STRIDE, class_map_path=CLASS_LABELS_PATH)\n",
    "\n",
    "X = X[:int(len(X) * 0.7)]\n",
    "y = y[:int(len(y) * 0.7)]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=RANDOM_SEED)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, shuffle=True, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3a4bf84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (14022, 96, 96, 3), Y shape: (14022,)\n",
      "X_train shape: (10095, 96, 96, 3), y_train shape: (10095,)\n",
      "X_val shape: (1122, 96, 96, 3), y_val shape: (1122,)\n",
      "X_test shape: (2805, 96, 96, 3), y_test shape: (2805,)\n",
      "Class distribution: {0: 5446, 1: 8576}\n"
     ]
    }
   ],
   "source": [
    "print(f\"X shape: {X.shape}, Y shape: {y.shape}\")\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
    "\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "print(f\"Class distribution: {dict(zip(unique, counts))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b1936f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16_finetune\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 96, 96, 3)]       0         \n",
      "                                                                 \n",
      " vgg16 (Functional)          (None, 3, 3, 512)         14714688  \n",
      "                                                                 \n",
      " gap (GlobalAveragePooling2D  (None, 512)              0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,846,530\n",
      "Trainable params: 131,842\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = FineTunedVGG16()\n",
    "\n",
    "model.setup_model(\n",
    "    input_shape=X.shape[1:],\n",
    "    num_classes=np.unique(y).shape[0],\n",
    "    train_last_n_layers=6,\n",
    "    base_trainable=True,\n",
    "    dropout_rate=0.3,\n",
    "    l2_reg=1e-4,\n",
    "    learning_rate=1e-3,\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    from_pretrained=False,\n",
    "    pretrained_path=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "844034ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "316/316 [==============================] - 18s 41ms/step - loss: 0.3994 - accuracy: 0.8268 - val_loss: 0.2869 - val_accuracy: 0.8806 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "316/316 [==============================] - 11s 36ms/step - loss: 0.3491 - accuracy: 0.8527 - val_loss: 0.2679 - val_accuracy: 0.8913 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "316/316 [==============================] - 11s 35ms/step - loss: 0.3295 - accuracy: 0.8635 - val_loss: 0.2876 - val_accuracy: 0.8779 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "316/316 [==============================] - 11s 36ms/step - loss: 0.3194 - accuracy: 0.8690 - val_loss: 0.2568 - val_accuracy: 0.8886 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "316/316 [==============================] - 12s 37ms/step - loss: 0.3096 - accuracy: 0.8726 - val_loss: 0.2529 - val_accuracy: 0.8939 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "316/316 [==============================] - 12s 37ms/step - loss: 0.3092 - accuracy: 0.8724 - val_loss: 0.2726 - val_accuracy: 0.8850 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "316/316 [==============================] - 11s 35ms/step - loss: 0.2992 - accuracy: 0.8787 - val_loss: 0.2410 - val_accuracy: 0.9011 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "316/316 [==============================] - 11s 36ms/step - loss: 0.3045 - accuracy: 0.8761 - val_loss: 0.2797 - val_accuracy: 0.8806 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "316/316 [==============================] - 11s 36ms/step - loss: 0.3021 - accuracy: 0.8800 - val_loss: 0.2393 - val_accuracy: 0.8930 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "316/316 [==============================] - 12s 38ms/step - loss: 0.2912 - accuracy: 0.8812 - val_loss: 0.2475 - val_accuracy: 0.9011 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "316/316 [==============================] - 13s 41ms/step - loss: 0.2906 - accuracy: 0.8807 - val_loss: 0.2334 - val_accuracy: 0.8975 - lr: 0.0010\n",
      "Epoch 12/150\n",
      "316/316 [==============================] - 13s 41ms/step - loss: 0.2966 - accuracy: 0.8775 - val_loss: 0.2475 - val_accuracy: 0.8904 - lr: 0.0010\n",
      "Epoch 13/150\n",
      "316/316 [==============================] - ETA: 0s - loss: 0.2875 - accuracy: 0.8817\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "316/316 [==============================] - 13s 42ms/step - loss: 0.2875 - accuracy: 0.8817 - val_loss: 0.2599 - val_accuracy: 0.8948 - lr: 0.0010\n",
      "Epoch 14/150\n",
      "316/316 [==============================] - 13s 40ms/step - loss: 0.2817 - accuracy: 0.8882 - val_loss: 0.2230 - val_accuracy: 0.9055 - lr: 5.0000e-04\n",
      "Epoch 15/150\n",
      "316/316 [==============================] - 13s 41ms/step - loss: 0.2808 - accuracy: 0.8873 - val_loss: 0.2252 - val_accuracy: 0.9037 - lr: 5.0000e-04\n",
      "Epoch 16/150\n",
      "316/316 [==============================] - 13s 42ms/step - loss: 0.2784 - accuracy: 0.8863 - val_loss: 0.2099 - val_accuracy: 0.9198 - lr: 5.0000e-04\n",
      "Epoch 17/150\n",
      "316/316 [==============================] - 12s 39ms/step - loss: 0.2730 - accuracy: 0.8919 - val_loss: 0.2116 - val_accuracy: 0.9073 - lr: 5.0000e-04\n",
      "Epoch 18/150\n",
      "316/316 [==============================] - ETA: 0s - loss: 0.2696 - accuracy: 0.8908\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "316/316 [==============================] - 13s 40ms/step - loss: 0.2696 - accuracy: 0.8908 - val_loss: 0.2191 - val_accuracy: 0.9046 - lr: 5.0000e-04\n",
      "Epoch 19/150\n",
      "316/316 [==============================] - 13s 40ms/step - loss: 0.2715 - accuracy: 0.8898 - val_loss: 0.2066 - val_accuracy: 0.9153 - lr: 2.5000e-04\n",
      "Epoch 20/150\n",
      "316/316 [==============================] - 13s 42ms/step - loss: 0.2624 - accuracy: 0.8943 - val_loss: 0.2102 - val_accuracy: 0.9100 - lr: 2.5000e-04\n",
      "Epoch 21/150\n",
      "315/316 [============================>.] - ETA: 0s - loss: 0.2705 - accuracy: 0.8908\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "316/316 [==============================] - 13s 40ms/step - loss: 0.2703 - accuracy: 0.8910 - val_loss: 0.2133 - val_accuracy: 0.9073 - lr: 2.5000e-04\n",
      "Epoch 22/150\n",
      "316/316 [==============================] - 13s 40ms/step - loss: 0.2587 - accuracy: 0.8964 - val_loss: 0.2141 - val_accuracy: 0.9109 - lr: 1.2500e-04\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    X_val, y_val,\n",
    "    batch_size=32,\n",
    "    epochs=150,\n",
    "    use_augmentation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3777a434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 2s 22ms/step - loss: 0.2029 - accuracy: 0.9205\n",
      "Loss: 0.2029, Accuracy: 0.9205\n",
      "88/88 [==============================] - 2s 20ms/step - loss: 0.2029 - accuracy: 0.9205\n",
      "Loss: 0.2029, Accuracy: 0.9205\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)\n",
    "\n",
    "# Evaluate and prepare metrics dictionary\n",
    "results = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Extract last epoch train/val metrics from history\n",
    "train_loss = history.history['loss'] if 'loss' in history.history else None\n",
    "val_loss = history.history['val_loss'] if 'val_loss' in history.history else None\n",
    "train_accuracy = history.history['accuracy'] if 'accuracy' in history.history else None\n",
    "val_accuracy = history.history['val_accuracy'] if 'val_accuracy' in history.history else None\n",
    "\n",
    "metrics_dict = {\n",
    "    \"eval_loss\": float(results[0]),\n",
    "    \"eval_accuracy\": float(results[1]),\n",
    "    \"final_train_loss\": train_loss,\n",
    "    \"final_val_loss\": val_loss,\n",
    "    \"final_train_accuracy\": train_accuracy,\n",
    "    \"final_val_accuracy\": val_accuracy,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "680f0307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to models/VGG16/VGG16_20250910_015040\\VGG16_20250910_015040.h5\n"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "model.save(directory=f\"models/VGG16/VGG16_{timestamp}\", timestamp=timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f42349e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved metrics to c:\\Users\\bgmanuel\\InteligenciaArtificial\\MasterInteligenciaArtificial\\Periodo2\\TFM\\Super-Resolution-Images-for-3D-Printing-Defect-Detection\\SRModels\\defect_detection_models\\models\\VGG16\\VGG16_20250910_015040\\VGG16_20250910_015040_metrics.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save evaluation/time/memory metrics next to the model\n",
    "metrics_path = os.path.abspath(os.path.join(os.getcwd(), f\"models/VGG16/VGG16_{timestamp}/VGG16_{timestamp}_metrics.pkl\"))\n",
    "\n",
    "with open(metrics_path, \"wb\") as f:\n",
    "    pickle.dump(metrics_dict, f)\n",
    "    \n",
    "print(f\"Saved metrics to {metrics_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
