{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f26f0a5",
   "metadata": {},
   "source": [
    "# VGG16 fine-tuning for defect detection\n",
    "\n",
    "This section builds a VGG16 model with ImageNet weights, lets you choose any valid input shape (HxWx3), and fine-tune only the last layers you specify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82c2da04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../../\")))\n",
    "from SRModels.defect_detection_models.VGG16_model import FineTunedVGG16\n",
    "from SRModels.loading_methods import load_defects_dataset_as_patches\n",
    "from SRModels.constants import VGG_PATCH_SIZE, VGG_STRIDE, RANDOM_SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "999f12f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "HR_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"../../data/images/HR\"))\n",
    "CLASS_LABELS_PATH = os.path.abspath(os.path.join(os.getcwd(), \"../../data/images/class_labels_map.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee59aaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X ->  High-resolution patches (model input)\n",
    "# y -> Class labels (target)\n",
    "X, y = load_defects_dataset_as_patches(HR_ROOT, patch_size=VGG_PATCH_SIZE, stride=VGG_STRIDE, class_map_path=CLASS_LABELS_PATH)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=RANDOM_SEED)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, shuffle=True, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50127e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 18112, 1: 14144}\n"
     ]
    }
   ],
   "source": [
    "# how many samples per class\n",
    "(unique, counts) = np.unique(y, return_counts=True)\n",
    "print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3a4bf84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (2560, 96, 96, 3), Y shape: (2560,)\n",
      "X_train shape: (1843, 96, 96, 3), y_train shape: (1843,)\n",
      "X_val shape: (205, 96, 96, 3), y_val shape: (205,)\n",
      "X_test shape: (512, 96, 96, 3), y_test shape: (512,)\n",
      "Class distribution: {0: 1920, 1: 640}\n"
     ]
    }
   ],
   "source": [
    "print(f\"X shape: {X.shape}, Y shape: {y.shape}\")\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
    "\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "print(f\"Class distribution: {dict(zip(unique, counts))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b1936f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16_finetune\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 96, 96, 3)]       0         \n",
      "                                                                 \n",
      " vgg16 (Functional)          (None, 3, 3, 512)         14714688  \n",
      "                                                                 \n",
      " gap (GlobalAveragePooling2D  (None, 512)              0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,846,530\n",
      "Trainable params: 131,842\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = FineTunedVGG16()\n",
    "\n",
    "model.setup_model(\n",
    "    input_shape=X.shape[1:],\n",
    "    num_classes=np.unique(y).shape[0],\n",
    "    train_last_n_layers=6,\n",
    "    base_trainable=True,\n",
    "    dropout_rate=0.3,\n",
    "    l2_reg=1e-4,\n",
    "    learning_rate=1e-3,\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    from_pretrained=False,\n",
    "    pretrained_path=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "844034ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 4s 64ms/step - loss: 0.2724 - accuracy: 0.9056 - val_loss: 0.1518 - val_accuracy: 0.9512 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    X_val, y_val,\n",
    "    batch_size=32,\n",
    "    epochs=1,\n",
    "    use_augmentation=True,\n",
    "    augment_validation=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3777a434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 30ms/step - loss: 0.1412 - accuracy: 0.9512\n",
      "Loss: 0.1412, Accuracy: 0.9512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.14118382334709167, 0.951171875]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "680f0307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to models/VGG16\\VGG16_20250908_115146.h5\n"
     ]
    }
   ],
   "source": [
    "model.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
