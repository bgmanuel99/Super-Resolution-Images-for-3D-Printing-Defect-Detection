{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f26f0a5",
   "metadata": {},
   "source": [
    "# VGG16 fine-tuning for defect detection\n",
    "\n",
    "This section builds a VGG16 model with ImageNet weights, lets you choose any valid input shape (HxWx3), and fine-tune only the last layers you specify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c2da04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Model\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications import VGG16\n",
    "from keras.layers import BatchNormalization, Dense, Dropout, GlobalAveragePooling2D, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7279558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vgg16_finetune(\n",
    "    input_shape=(128, 128, 3),\n",
    "    num_classes=2,\n",
    "    train_last_n_layers=4,\n",
    "    base_trainable=False,\n",
    "    dropout_rate=0.2,\n",
    "    l2_reg=0.0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Build a VGG16-based model with ImageNet weights and a custom classification head.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_shape : (H, W, 3)\n",
    "        Model input shape. Must have 3 channels.\n",
    "    num_classes : int\n",
    "        Number of output classes.\n",
    "    train_last_n_layers : int\n",
    "        Number of layers (from the end of the base model) to unfreeze for fine-tuning.\n",
    "    base_trainable : bool\n",
    "        If True, allow training on selected last N layers of VGG16.\n",
    "    dropout_rate : float\n",
    "        Dropout after the pooled features (0 disables).\n",
    "    l2_reg : float\n",
    "        L2 weight decay for the dense head (0 disables).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    keras.Model\n",
    "        Compiled model ready to train.\n",
    "    \"\"\"\n",
    "    \n",
    "    assert input_shape[-1] == 3, \"Input must have 3 channels (RGB).\"\n",
    "\n",
    "    # Load VGG16 base with ImageNet weights and no top\n",
    "    base = VGG16(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_shape=input_shape,\n",
    "    )\n",
    "\n",
    "    # Freeze all layers by default\n",
    "    base.trainable = False\n",
    "\n",
    "    # Optionally unfreeze last N layers\n",
    "    if base_trainable and train_last_n_layers > 0:\n",
    "        # Unfreeze only the last N layers of the base\n",
    "        for layer in base.layers[-train_last_n_layers:]:\n",
    "            if not isinstance(layer, BatchNormalization):\n",
    "                layer.trainable = True\n",
    "\n",
    "    # Build head\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = base(inputs, training=False)  # important for BN layers in eval mode\n",
    "    x = GlobalAveragePooling2D(name=\"gap\")(x)\n",
    "    if dropout_rate > 0:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "    kernel_reg = l2(l2_reg) if l2_reg > 0 else None\n",
    "    x = Dense(256, activation=\"relu\", kernel_regularizer=kernel_reg)(x)\n",
    "    x = Dropout(dropout_rate)(x) if dropout_rate > 0 else x\n",
    "\n",
    "    outputs = Dense(num_classes, activation=\"softmax\", name=\"predictions\")(x)\n",
    "    model = Model(inputs, outputs, name=\"vgg16_finetune\")\n",
    "\n",
    "    optimizer = Adam(learning_rate=1e-3)\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999f12f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1936f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_vgg16_finetune(\n",
    "    input_shape=(128, 128, 3),\n",
    "    num_classes=2,\n",
    "    train_last_n_layers=6,\n",
    "    base_trainable=True,\n",
    "    dropout_rate=0.3,\n",
    "    l2_reg=1e-4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844034ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
