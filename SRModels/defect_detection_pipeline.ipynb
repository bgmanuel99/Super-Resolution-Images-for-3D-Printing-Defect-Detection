{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10cf6b22",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9759e077",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bgmanuel\\anaconda3\\envs\\py310\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\bgmanuel\\anaconda3\\envs\\py310\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.12.0 and strictly below 2.15.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.10.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../\")))\n",
    "\n",
    "from SRModels.constants import *\n",
    "from SRModels.loading_methods import load_predictions_dataset\n",
    "from SRModels.deep_learning_models.SRCNN_model import SRCNNModel\n",
    "from SRModels.deep_learning_models.EDSR_model import EDSR\n",
    "from SRModels.deep_learning_models.ESRGAN_model import ESRGAN\n",
    "from SRModels.defect_detection_models.VGG16_model import FineTunedVGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe56b895",
   "metadata": {},
   "source": [
    "# CONSTANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0f454b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SRCNN_PRETRAINED_PATH = os.path.abspath(os.path.join(os.getcwd(), \"deep_learning_models/models/SRCNN/xxx/xxx.h5\"))\n",
    "SRCNN_HR_DIMENSIONS_PATH = os.path.abspath(os.path.join(os.getcwd(), \"deep_learning_models/models/SRCNN/xxx/xxx.pkl\"))\n",
    "EDSR_PRETRAINED_PATH = os.path.abspath(os.path.join(os.getcwd(), \"deep_learning_models/models/EDSR/xxxxxxxxxxxx.h5\"))\n",
    "ESRGAN_GENERATOR_PRETRAINED_PATH = os.path.abspath(os.path.join(os.getcwd(), \"deep_learning_models/models/ESRGAN/xxxxxxxxxxxx.h5\"))\n",
    "ESRGAN_DISCRIMINATOR_PRETRAINED_PATH = os.path.abspath(os.path.join(os.getcwd(), \"deep_learning_models/models/ESRGAN/xxxxxxxxxxxx.h5\"))\n",
    "VGG16_PRETRAINED_PATH = os.path.abspath(os.path.join(os.getcwd(), \"defect_detection_models/models/VGG16/xxxxxxxxxxxx.h5\"))\n",
    "\n",
    "# Training metrics pickle paths\n",
    "SRCNN_TRAIN_METRICS_PATH = os.path.abspath(os.path.join(os.getcwd(), \"deep_learning_models/models/SRCNN/train_metrics.pkl\"))\n",
    "EDSR_TRAIN_METRICS_PATH = os.path.abspath(os.path.join(os.getcwd(), \"deep_learning_models/models/EDSR/train_metrics.pkl\"))\n",
    "ESRGAN_TRAIN_METRICS_PATH = os.path.abspath(os.path.join(os.getcwd(), \"deep_learning_models/models/ESRGAN/train_metrics.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8062bc",
   "metadata": {},
   "source": [
    "# LR Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f707d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to LR images and labels map generated by preprocessing_functions\n",
    "LR_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"../data/images_for_predictions/LR\"))\n",
    "CLASS_LABELS_PATH = os.path.abspath(os.path.join(os.getcwd(), \"../data/images_for_predictions/class_labels_map.pkl\"))\n",
    "\n",
    "# Load arrays\n",
    "X, y = load_predictions_dataset(LR_ROOT, CLASS_LABELS_PATH)\n",
    "print(f\"Loaded LR images: {X.shape} | Labels: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514b5269",
   "metadata": {},
   "source": [
    "# SRCNN model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90f5696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load HR dimensions\n",
    "with open(SRCNN_HR_DIMENSIONS_PATH, \"rb\") as f:\n",
    "    hr_h, hr_w = pickle.load(f)\n",
    "\n",
    "# Load pretrained SRCNN model\n",
    "pretrained_srcnn_model = SRCNNModel()\n",
    "\n",
    "pretrained_srcnn_model.setup_model(from_pretrained=True, pretrained_path=SRCNN_PRETRAINED_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba24d0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Super-resolve all LR images with SRCNN (using X)\n",
    "srcnn_sr_images = []\n",
    "srcnn_times = []\n",
    "srcnn_mean_gpus = []\n",
    "srcnn_peak_gpus = []\n",
    "\n",
    "for idx in range(X.shape[0]):\n",
    "    sr_img, metrics = pretrained_srcnn_model.super_resolve_image(X[idx], hr_h=hr_h, hr_w=hr_w, patch_size=33, stride=14)\n",
    "    srcnn_sr_images.append(sr_img)\n",
    "    srcnn_times.append(metrics[\"time_sec\"])\n",
    "    srcnn_mean_gpus.append(metrics[\"gpu_mean_current_mb\"])\n",
    "    srcnn_peak_gpus.append(metrics[\"gpu_peak_mb\"])\n",
    "    \n",
    "srcnn_sr_images = np.stack(srcnn_sr_images, axis=0)\n",
    "srcnn_time_mean = np.mean(srcnn_times)\n",
    "srcnn_gpu_mean_mean = np.mean(srcnn_mean_gpus)\n",
    "srcnn_gpu_peak_max = np.max(srcnn_peak_gpus)\n",
    "\n",
    "print(f\"SRCNN: mean_time={srcnn_time_mean:.4f}s, mean_gpu={srcnn_gpu_mean_mean:.2f}MB, peak_gpu={srcnn_gpu_peak_max:.2f}MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8091fdd",
   "metadata": {},
   "source": [
    "# EDSR model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ade4cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained EDSR model\n",
    "pretrained_edsr_model = EDSR()\n",
    "\n",
    "pretrained_edsr_model.setup_model(scale_factor=EDSR_SCALE_FACTOR, from_pretrained=True, pretrained_path=EDSR_PRETRAINED_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47c230a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Super-resolve all LR images with EDSR (using X)\n",
    "edsr_sr_list = []\n",
    "edsr_times = []\n",
    "edsr_mean_gpus = []\n",
    "edsr_peak_gpus = []\n",
    "\n",
    "for idx, lr_img in enumerate(X):\n",
    "    sr_img, metrics = pretrained_edsr_model.super_resolve_image(lr_img, patch_size_lr=48, stride=24)\n",
    "    edsr_sr_list.append(sr_img)\n",
    "    edsr_times.append(metrics[\"time_sec\"])\n",
    "    edsr_mean_gpus.append(metrics[\"gpu_mean_current_mb\"])\n",
    "    edsr_peak_gpus.append(metrics[\"gpu_peak_mb\"])\n",
    "    \n",
    "edsr_sr_images = np.stack(edsr_sr_list, axis=0)\n",
    "edsr_time_mean = np.mean(edsr_times)\n",
    "edsr_gpu_mean_mean = np.mean(edsr_mean_gpus)\n",
    "edsr_gpu_peak_max = np.max(edsr_peak_gpus)\n",
    "\n",
    "print(f\"EDSR: mean_time={edsr_time_mean:.4f}s, mean_gpu={edsr_gpu_mean_mean:.2f}MB, peak_gpu={edsr_gpu_peak_max:.2f}MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f5f0dc",
   "metadata": {},
   "source": [
    "# ESRGAN model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfa3990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained ESRGAN model\n",
    "pretrained_esrgan_model = ESRGAN()\n",
    "\n",
    "pretrained_esrgan_model.setup_model(\n",
    "    from_trained=True, \n",
    "    generator_pretrained_path=ESRGAN_GENERATOR_PRETRAINED_PATH, \n",
    "    discriminator_pretrained_path=ESRGAN_DISCRIMINATOR_PRETRAINED_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9e1e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Super-resolve all LR images with ESRGAN (using X)\n",
    "esrgan_sr_list = []\n",
    "esrgan_times = []\n",
    "esrgan_mean_gpus = []\n",
    "esrgan_peak_gpus = []\n",
    "\n",
    "for idx, lr_img in enumerate(X):\n",
    "    sr_img, metrics = pretrained_esrgan_model.super_resolve_image(lr_img, patch_size_lr=48, stride=24, batch_size=8)\n",
    "    esrgan_sr_list.append(sr_img)\n",
    "    esrgan_times.append(metrics[\"time_sec\"])\n",
    "    esrgan_mean_gpus.append(metrics[\"gpu_mean_current_mb\"])\n",
    "    esrgan_peak_gpus.append(metrics[\"gpu_peak_mb\"])\n",
    "    \n",
    "esrgan_sr_images = np.stack(esrgan_sr_list, axis=0)\n",
    "esrgan_time_mean = np.mean(esrgan_times)\n",
    "esrgan_gpu_mean_mean = np.mean(esrgan_mean_gpus)\n",
    "esrgan_gpu_peak_max = np.max(esrgan_peak_gpus)\n",
    "\n",
    "print(f\"ESRGAN: mean_time={esrgan_time_mean:.4f}s, mean_gpu={esrgan_gpu_mean_mean:.2f}MB, peak_gpu={esrgan_gpu_peak_max:.2f}MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f311fe69",
   "metadata": {},
   "source": [
    "# VGG16 model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af77c885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained VGG16 model for feature extraction\n",
    "pretrained_vgg16_model = FineTunedVGG16()\n",
    "\n",
    "pretrained_vgg16_model.setup_model(from_pretrained=True, pretrained_path=VGG16_PRETRAINED_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db80b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify LR images with VGG16 majority voting\n",
    "lr_labels = []\n",
    "lr_confidences = []\n",
    "\n",
    "for idx, img in enumerate(X):\n",
    "    label, conf = pretrained_vgg16_model.classify_defects_method(\n",
    "        image=img, patch_size=VGG_PATCH_SIZE, stride=VGG_STRIDE, batch_size=64\n",
    "    )\n",
    "    lr_labels.append(int(label))\n",
    "    lr_confidences.append(float(conf))\n",
    "\n",
    "print(f\"LR classified: {len(lr_labels)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2a9ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify SRCNN SR images with VGG16 majority voting\n",
    "srcnn_labels = []\n",
    "srcnn_confidences = []\n",
    "\n",
    "for idx, img in enumerate(srcnn_sr_images):\n",
    "    label, conf = pretrained_vgg16_model.classify_defects_method(\n",
    "        image=img, patch_size=VGG_PATCH_SIZE, stride=VGG_STRIDE, batch_size=64\n",
    "    )\n",
    "    srcnn_labels.append(int(label))\n",
    "    srcnn_confidences.append(float(conf))\n",
    "\n",
    "print(f\"SRCNN classified: {len(srcnn_labels)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b88be94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify EDSR SR images with VGG16 majority voting\n",
    "edsr_labels = []\n",
    "edsr_confidences = []\n",
    "\n",
    "for idx, img in enumerate(edsr_sr_images):\n",
    "    label, conf = pretrained_vgg16_model.classify_defects_method(\n",
    "        image=img, patch_size=VGG_PATCH_SIZE, stride=VGG_STRIDE, batch_size=64\n",
    "    )\n",
    "    edsr_labels.append(int(label))\n",
    "    edsr_confidences.append(float(conf))\n",
    "\n",
    "print(f\"EDSR classified: {len(edsr_labels)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0aaacb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify ESRGAN SR images with VGG16 majority voting\n",
    "esrgan_labels = []\n",
    "esrgan_confidences = []\n",
    "\n",
    "for idx, img in enumerate(esrgan_sr_images):\n",
    "    label, conf = pretrained_vgg16_model.classify_defects_method(\n",
    "        image=img, patch_size=VGG_PATCH_SIZE, stride=VGG_STRIDE, batch_size=64\n",
    "    )\n",
    "    esrgan_labels.append(int(label))\n",
    "    esrgan_confidences.append(float(conf))\n",
    "\n",
    "print(f\"ESRGAN classified: {len(esrgan_labels)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8819cbf6",
   "metadata": {},
   "source": [
    "# Deep learning metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c048ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a549f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 1: Training and Inference Metrics Panel\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load training metrics from pickle files if available\n",
    "def load_train_metrics(path):\n",
    "    try:\n",
    "        with open(path, \"rb\") as f:\n",
    "            return pickle.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: couldn't load {path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Expected structure (flexible):\n",
    "# { 'loss': float or list, 'psnr': float or list, 'ssim': float or list,\n",
    "#   'time': {'mean_epoch_time_sec': float},\n",
    "#   'memory': {'gpu_mean_current_mb': float, 'gpu_peak_mb': float} }\n",
    "\n",
    "srcnn_train = load_train_metrics(SRCNN_TRAIN_METRICS_PATH)\n",
    "edsr_train = load_train_metrics(EDSR_TRAIN_METRICS_PATH)\n",
    "esrgan_train = load_train_metrics(ESRGAN_TRAIN_METRICS_PATH)\n",
    "\n",
    "models = [\"SRCNN\", \"EDSR\", \"ESRGAN\"]\n",
    "\n",
    "# Aggregate training metrics\n",
    "def as_scalar(x):\n",
    "    if x is None:\n",
    "        return None\n",
    "    if isinstance(x, (list, tuple, np.ndarray)) and len(x) > 0:\n",
    "        return float(np.mean(x))\n",
    "    if isinstance(x, (int, float)):\n",
    "        return float(x)\n",
    "    return None\n",
    "\n",
    "train_loss = []\n",
    "train_psnr = []\n",
    "train_ssim = []\n",
    "train_time = []\n",
    "train_mean_mem = []\n",
    "train_peak_mem = []\n",
    "\n",
    "for m in [srcnn_train, edsr_train, esrgan_train]:\n",
    "    if m is None:\n",
    "        train_loss.append(None)\n",
    "        train_psnr.append(None)\n",
    "        train_ssim.append(None)\n",
    "        train_time.append(None)\n",
    "        train_mean_mem.append(None)\n",
    "        train_peak_mem.append(None)\n",
    "        continue\n",
    "    train_loss.append(as_scalar(m.get('loss')))\n",
    "    train_psnr.append(as_scalar(m.get('psnr')))\n",
    "    train_ssim.append(as_scalar(m.get('ssim')))\n",
    "    t = m.get('time') or {}\n",
    "    train_time.append(as_scalar(t.get('mean_epoch_time_sec')))\n",
    "    mem = m.get('memory') or {}\n",
    "    train_mean_mem.append(as_scalar(mem.get('gpu_mean_current_mb')))\n",
    "    train_peak_mem.append(as_scalar(mem.get('gpu_peak_mb')))\n",
    "\n",
    "# Inference aggregates computed earlier in the notebook\n",
    "inf_time = [srcnn_time_mean, edsr_time_mean, esrgan_time_mean]\n",
    "inf_mean_mem = [srcnn_gpu_mean_mean, edsr_gpu_mean_mean, esrgan_gpu_mean_mean]\n",
    "inf_peak_mem = [srcnn_gpu_peak_max, edsr_gpu_peak_max, esrgan_gpu_peak_max]\n",
    "\n",
    "x = np.arange(len(models))\n",
    "width = 0.25\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Subplot 1: Training loss, PSNR, SSIM\n",
    "ax = axes[0]\n",
    "ax.set_title(\"Training: Loss / PSNR / SSIM\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(models)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "ax.plot(x, [v if v is not None else np.nan for v in train_loss], marker='o', label='Loss')\n",
    "ax.plot(x, [v if v is not None else np.nan for v in train_psnr], marker='o', label='PSNR')\n",
    "ax.plot(x, [v if v is not None else np.nan for v in train_ssim], marker='o', label='SSIM')\n",
    "ax.legend(loc='best')\n",
    "\n",
    "# Subplot 2: Training mean time, mean mem, peak mem\n",
    "ax = axes[1]\n",
    "ax.set_title(\"Training: Time / GPU Mem\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(models)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "ax.plot(x, [v if v is not None else np.nan for v in train_time], marker='o', label='Mean Time (s)')\n",
    "ax.plot(x, [v if v is not None else np.nan for v in train_mean_mem], marker='o', label='Mean GPU (MB)')\n",
    "ax.plot(x, [v if v is not None else np.nan for v in train_peak_mem], marker='o', label='Peak GPU (MB)')\n",
    "ax.legend(loc='best')\n",
    "\n",
    "# Subplot 3: Inference mean time, mean mem, peak mem\n",
    "ax = axes[2]\n",
    "ax.set_title(\"Inference: Time / GPU Mem\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(models)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "ax.plot(x, inf_time, marker='o', label='Mean Time (s)')\n",
    "ax.plot(x, inf_mean_mem, marker='o', label='Mean GPU (MB)')\n",
    "ax.plot(x, inf_peak_mem, marker='o', label='Peak GPU (MB)')\n",
    "ax.legend(loc='best')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44c99f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 2: Confusion Matrices for VGG16 predictions\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "# Make sure true labels y exist (loaded earlier) and predictions lists exist\n",
    "def plot_confusion(ax, cm, classes, title):\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    ax.set_title(title)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    ax.set_xticks(tick_marks)\n",
    "    ax.set_yticks(tick_marks)\n",
    "    ax.set_xticklabels(classes)\n",
    "    ax.set_yticklabels(classes)\n",
    "    ax.set_ylabel('True label')\n",
    "    ax.set_xlabel('Predicted label')\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        ax.text(j, i, format(cm[i, j], 'd'),\n",
    "                horizontalalignment=\"center\",\n",
    "                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    return im\n",
    "\n",
    "class_names = [str(c) for c in sorted(np.unique(y))] if 'y' in globals() else ['0','1']\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Choose three sets to visualize; here: LR, SRCNN, EDSR\n",
    "cm_lr = confusion_matrix(y, lr_labels) if 'lr_labels' in globals() else np.zeros((len(class_names), len(class_names)), dtype=int)\n",
    "cm_srcnn = confusion_matrix(y, srcnn_labels) if 'srcnn_labels' in globals() else np.zeros_like(cm_lr)\n",
    "cm_edsr = confusion_matrix(y, edsr_labels) if 'edsr_labels' in globals() else np.zeros_like(cm_lr)\n",
    "\n",
    "plot_confusion(axes[0], cm_lr, class_names, title='LR Confusion Matrix')\n",
    "plot_confusion(axes[1], cm_srcnn, class_names, title='SRCNN Confusion Matrix')\n",
    "plot_confusion(axes[2], cm_edsr, class_names, title='EDSR Confusion Matrix')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
