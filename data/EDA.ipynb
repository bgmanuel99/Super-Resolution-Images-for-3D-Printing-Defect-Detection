{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92856d4d",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ac93309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import cv2\n",
    "import lpips\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import torch\n",
    "from skimage import filters\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from skimage.metrics import (\n",
    "    peak_signal_noise_ratio as psnr,\n",
    "    structural_similarity as ssim,\n",
    " )\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe885f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagePairLoader:\n",
    "    \"\"\"Separated I/O utilities for iterating and aligning LR/HR pairs.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def iter_pairs(lr_base, hr_base):\n",
    "        \"\"\"Yield matching (lr_relpath, hr_relpath) pairs by scanning subfolders.\n",
    "\n",
    "        Pairs are matched by their relative path from the base dirs. Only files\n",
    "        present in both LR and HR trees are returned. Order is lexicographic.\n",
    "        \"\"\"\n",
    "        \n",
    "        exts = (\".png\", \".jpg\", \".jpeg\")\n",
    "\n",
    "        def walk_relnames(base):\n",
    "            rels = set()\n",
    "            for root, _, files in os.walk(base):\n",
    "                for f in files:\n",
    "                    if f.lower().endswith(exts):\n",
    "                        full = os.path.join(root, f)\n",
    "                        rel = os.path.relpath(full, base)\n",
    "                        rels.add(rel)\n",
    "            return rels\n",
    "        \n",
    "        lr_set = walk_relnames(lr_base)\n",
    "        hr_set = walk_relnames(hr_base)\n",
    "        \n",
    "        common = sorted(lr_set & hr_set)\n",
    "        if not common:\n",
    "            raise ValueError(\"No matching LR/HR image pairs were found under the provided directories.\")\n",
    "        \n",
    "        for rel in common:\n",
    "            # Use the same relative path for LR and HR; callers will join with bases\n",
    "            yield rel, rel\n",
    "\n",
    "    @staticmethod\n",
    "    def load_and_align(lr_path, hr_path, interp_map=None):\n",
    "        \"\"\"Load two images and resize LR to HR size if required.\n",
    "\n",
    "        If interp_map provided, it should map LR filename to the\n",
    "        interpolation method string used originally (e.g., 'INTER_CUBIC').\n",
    "        That method is used for upscaling to match EDA fairness.\n",
    "        \"\"\"\n",
    "        \n",
    "        lr = cv2.imread(lr_path)\n",
    "        hr = cv2.imread(hr_path)\n",
    "\n",
    "        if lr is None or hr is None:\n",
    "            raise ValueError(f\"Failed reading {lr_path} or {hr_path}\")\n",
    "\n",
    "        if lr.shape[:2] != hr.shape[:2]:\n",
    "            interp_code = cv2.INTER_LINEAR\n",
    "            if interp_map is not None:\n",
    "                fname = os.path.basename(lr_path)\n",
    "                name = interp_map.get(fname)\n",
    "                name_to_code = {\n",
    "                    'INTER_LINEAR': cv2.INTER_LINEAR,\n",
    "                    'INTER_CUBIC': cv2.INTER_CUBIC,\n",
    "                    'INTER_AREA': cv2.INTER_AREA,\n",
    "                    'INTER_LANCZOS4': cv2.INTER_LANCZOS4,\n",
    "                }\n",
    "                if name in name_to_code:\n",
    "                    interp_code = name_to_code[name]\n",
    "            lr = cv2.resize(\n",
    "                lr,\n",
    "                (hr.shape[1], hr.shape[0]),\n",
    "                interpolation=interp_code\n",
    "            )\n",
    "\n",
    "        return lr, hr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6c8345",
   "metadata": {},
   "source": [
    "## Methods for exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87582ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDatasetAnalyzer:\n",
    "    \"\"\"Utility collection to analyze LR/HR image pairs.\n",
    "\n",
    "    All methods are static so they can be called without\n",
    "    instantiation.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def loss_fn():\n",
    "        \"\"\"Return (singleton) the loaded LPIPS model.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        lpips.LPIPS\n",
    "            Initialized LPIPS model instance.\n",
    "        \"\"\"\n",
    "        \n",
    "        if not hasattr(ImageDatasetAnalyzer, '_loss_fn'):\n",
    "            ImageDatasetAnalyzer._loss_fn = lpips.LPIPS(net=\"alex\")\n",
    "\n",
    "        return ImageDatasetAnalyzer._loss_fn\n",
    "\n",
    "    @staticmethod\n",
    "    def lpips_score(lr_img, hr_img):\n",
    "        \"\"\"Compute LPIPS between two aligned BGR images.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        lr_img : np.ndarray\n",
    "            Aligned LR image (BGR).\n",
    "        hr_img : np.ndarray\n",
    "            HR image (BGR).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            LPIPS value.\n",
    "        \"\"\"\n",
    "        \n",
    "        def to_tensor(img):\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) / 255.0\n",
    "            img = 2 * img - 1\n",
    "            img = np.transpose(img, (2, 0, 1))\n",
    "            return torch.from_numpy(img).unsqueeze(0).float()\n",
    "        \n",
    "        return ImageDatasetAnalyzer.loss_fn()(\n",
    "            to_tensor(lr_img),\n",
    "            to_tensor(hr_img)\n",
    "        ).item()\n",
    "\n",
    "    @staticmethod\n",
    "    def rms_noise(gray):\n",
    "        \"\"\"Estimate RMS noise using difference from a Gaussian blur.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        img : np.ndarray\n",
    "            Input BGR image.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            RMS noise estimate.\n",
    "        \"\"\"\n",
    "        \n",
    "        blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "        diff = gray.astype(np.float32) - blurred.astype(np.float32)\n",
    "\n",
    "        return float(np.sqrt(np.mean(diff ** 2)))\n",
    "\n",
    "    @staticmethod\n",
    "    def laplacian_variance(gray):\n",
    "        \"\"\"Variance of Laplacian (sharpness proxy).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        img : np.ndarray\n",
    "            BGR image.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            Variance value.\n",
    "        \"\"\"\n",
    "        \n",
    "        return float(cv2.Laplacian(gray, cv2.CV_64F).var())\n",
    "\n",
    "    @staticmethod\n",
    "    def psnr_metric(lr_img, hr_img):\n",
    "        \"\"\"Compute PSNR between HR and LR images.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        lr_img : np.ndarray\n",
    "            Aligned LR image.\n",
    "        hr_img : np.ndarray\n",
    "            HR image.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            PSNR value.\n",
    "        \"\"\"\n",
    "        \n",
    "        return psnr(hr_img, lr_img, data_range=255)\n",
    "\n",
    "    @staticmethod\n",
    "    def ssim_metric(lr_img, hr_img):\n",
    "        \"\"\"Compute SSIM between HR and LR images.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        lr_img : np.ndarray\n",
    "            Aligned LR image.\n",
    "        hr_img : np.ndarray\n",
    "            HR image.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            SSIM value.\n",
    "        \"\"\"\n",
    "        \n",
    "        return ssim(hr_img, lr_img, channel_axis=2, data_range=255)\n",
    "\n",
    "    @staticmethod\n",
    "    def glcm_features(gray, angles=None, levels=64, multi_angle=False):\n",
    "        \"\"\"Extract GLCM contrast, homogeneity, correlation.\n",
    "\n",
    "        Defaults trimmed to 64 levels and one angle (0 rad) to\n",
    "        reduce memory and time. Set multi_angle=True to use\n",
    "        the 4 standard angles (0, 45, 90, 135 deg) or pass a\n",
    "        custom iterable via angles.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        gray : np.ndarray\n",
    "            Grayscale image.\n",
    "        angles : iterable | None\n",
    "            Angles in radians. If None uses [0] unless\n",
    "            multi_angle True (then 4 angles).\n",
    "        levels : int\n",
    "            Quantization levels (default 64).\n",
    "        multi_angle : bool\n",
    "            Average metrics across four angles when True.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            glcm_contrast, glcm_homogeneity, glcm_correlation.\n",
    "        \"\"\"\n",
    "        \n",
    "        if angles is None:\n",
    "            if multi_angle:\n",
    "                angles = (0, np.pi / 4, np.pi / 2, 3 * np.pi / 4)\n",
    "            else:\n",
    "                angles = (0,)\n",
    "        # Quantize to requested levels\n",
    "        if gray.max() == 0:\n",
    "            norm = np.zeros_like(gray, dtype=np.uint8)\n",
    "        else:\n",
    "            norm = (\n",
    "                (gray.astype(np.float32) / 255.0) * (levels - 1)\n",
    "            ).astype(np.uint8)\n",
    "        glcm = graycomatrix(\n",
    "            norm,\n",
    "            [1],\n",
    "            list(angles),\n",
    "            levels,\n",
    "            symmetric=True,\n",
    "            normed=True\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"glcm_contrast\": float(\n",
    "                graycoprops(glcm, \"contrast\").mean()\n",
    "            ),\n",
    "            \"glcm_homogeneity\": float(\n",
    "                graycoprops(glcm, \"homogeneity\").mean()\n",
    "            ),\n",
    "            \"glcm_correlation\": float(\n",
    "                graycoprops(glcm, \"correlation\").mean()\n",
    "            )\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def feature_distribution(img, hsv):\n",
    "        \"\"\"Basic stats per BGR channel plus HSV saturation/brightness.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        img : np.ndarray\n",
    "            BGR image.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            Channel stats plus saturation_mean, brightness_mean.\n",
    "        \"\"\"\n",
    "        \n",
    "        results = {}\n",
    "\n",
    "        for idx, channel in enumerate(cv2.split(img)):\n",
    "            flat = channel.ravel()\n",
    "            results[f\"ch{idx}_mean\"] = float(np.mean(flat))\n",
    "            results[f\"ch{idx}_std\"] = float(np.std(flat))\n",
    "            results[f\"ch{idx}_skew\"] = float(scipy.stats.skew(flat))\n",
    "            results[f\"ch{idx}_kurt\"] = float(scipy.stats.kurtosis(flat))\n",
    "        \n",
    "        results[\"saturation_mean\"] = float(np.mean(hsv[:, :, 1]))\n",
    "        results[\"brightness_mean\"] = float(np.mean(hsv[:, :, 2]))\n",
    "\n",
    "        return results\n",
    "\n",
    "    @staticmethod\n",
    "    def detect_artifacts(img, gray):\n",
    "        \"\"\"Detect artifacts: blocking, color noise, ringing.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        img : np.ndarray\n",
    "            BGR image.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            blocking_score, color_noise, ringing_artifact.\n",
    "        \"\"\"\n",
    "        \n",
    "        dct = cv2.dct(np.float32(gray))\n",
    "        horizontal_blocking = np.mean(np.abs(dct[7::8, :]))\n",
    "        vertical_blocking = np.mean(np.abs(dct[:, 7::8]))\n",
    "        blocking_score = float(\n",
    "            (horizontal_blocking + vertical_blocking) / 2\n",
    "        )\n",
    "        blur = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "        color_noise = float(\n",
    "            np.mean(np.abs(img.astype(float) - blur.astype(float)))\n",
    "        )\n",
    "        edges = cv2.Canny(gray, 100, 200)\n",
    "        kernel = np.ones((5, 5), np.uint8)\n",
    "        dilated = cv2.dilate(edges, kernel)\n",
    "        edge_region = dilated & ~edges\n",
    "        \n",
    "        if np.any(edge_region):\n",
    "            ringing = float(np.std(gray[edge_region]))\n",
    "        else:\n",
    "            ringing = 0.0\n",
    "\n",
    "        return {\n",
    "            \"blocking_score\": blocking_score,\n",
    "            \"color_noise\": color_noise,\n",
    "            \"ringing_artifact\": ringing\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb5cc926",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagePairMetrics:\n",
    "    \"\"\"Container of metrics computed for an LR/HR pair.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        filename,\n",
    "        lpips,\n",
    "        psnr,\n",
    "        ssim,\n",
    "        glcm_contrast,\n",
    "        glcm_homogeneity,\n",
    "        glcm_correlation,\n",
    "        rms_noise_lr,\n",
    "        rms_noise_hr,\n",
    "        lap_var_lr,\n",
    "        lap_var_hr,\n",
    "        blocking_lr,\n",
    "        blocking_hr,\n",
    "        color_noise_lr,\n",
    "        color_noise_hr,\n",
    "        ringing_lr,\n",
    "        ringing_hr,\n",
    "        saturation_mean_lr,\n",
    "        saturation_mean_hr,\n",
    "        brightness_mean_lr,\n",
    "        brightness_mean_hr,\n",
    "        edge_diff,\n",
    "        ch0_skew_lr=None, \n",
    "        ch0_skew_hr=None,\n",
    "        ch1_skew_lr=None, \n",
    "        ch1_skew_hr=None,\n",
    "        ch2_skew_lr=None, \n",
    "        ch2_skew_hr=None,\n",
    "        ch0_kurt_lr=None, \n",
    "        ch0_kurt_hr=None,\n",
    "        ch1_kurt_lr=None, \n",
    "        ch1_kurt_hr=None,\n",
    "        ch2_kurt_lr=None, \n",
    "        ch2_kurt_hr=None,\n",
    "    ):\n",
    "        self.filename = filename\n",
    "        self.lpips = lpips\n",
    "        self.psnr = psnr\n",
    "        self.ssim = ssim\n",
    "        self.glcm_contrast = glcm_contrast\n",
    "        self.glcm_homogeneity = glcm_homogeneity\n",
    "        self.glcm_correlation = glcm_correlation\n",
    "        self.rms_noise_lr = rms_noise_lr\n",
    "        self.rms_noise_hr = rms_noise_hr\n",
    "        self.lap_var_lr = lap_var_lr\n",
    "        self.lap_var_hr = lap_var_hr\n",
    "        self.blocking_lr = blocking_lr\n",
    "        self.blocking_hr = blocking_hr\n",
    "        self.color_noise_lr = color_noise_lr\n",
    "        self.color_noise_hr = color_noise_hr\n",
    "        self.ringing_lr = ringing_lr\n",
    "        self.ringing_hr = ringing_hr\n",
    "        self.saturation_mean_lr = saturation_mean_lr\n",
    "        self.saturation_mean_hr = saturation_mean_hr\n",
    "        self.brightness_mean_lr = brightness_mean_lr\n",
    "        self.brightness_mean_hr = brightness_mean_hr\n",
    "        self.edge_diff = edge_diff\n",
    "        self.ch0_skew_lr = ch0_skew_lr\n",
    "        self.ch0_skew_hr = ch0_skew_hr\n",
    "        self.ch1_skew_lr = ch1_skew_lr\n",
    "        self.ch1_skew_hr = ch1_skew_hr\n",
    "        self.ch2_skew_lr = ch2_skew_lr\n",
    "        self.ch2_skew_hr = ch2_skew_hr\n",
    "        self.ch0_kurt_lr = ch0_kurt_lr\n",
    "        self.ch0_kurt_hr = ch0_kurt_hr\n",
    "        self.ch1_kurt_lr = ch1_kurt_lr\n",
    "        self.ch1_kurt_hr = ch1_kurt_hr\n",
    "        self.ch2_kurt_lr = ch2_kurt_lr\n",
    "        self.ch2_kurt_hr = ch2_kurt_hr\n",
    "\n",
    "    def as_dict(self):\n",
    "        \"\"\"Return metrics as a dict for DataFrame conversion.\"\"\"\n",
    "        return self.__dict__.copy()\n",
    "\n",
    "class MetricsAggregator:\n",
    "    \"\"\"Orchestrates metric extraction for all image pairs.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def collect(\n",
    "        lr_dir,\n",
    "        hr_dir,\n",
    "        glcm_multi_angle=False,\n",
    "        glcm_levels=64,\n",
    "        interp_map=None,\n",
    "    ):\n",
    "        \"\"\"Compute metrics for each pair and accumulate global visual data.\n",
    "        Always returns a tuple (rows, global_data) where global_data contains\n",
    "        the accumulators required to build the global advanced visualization panel.\n",
    "        Now uses tqdm for progress display. Added complementary skew/kurt capture.\n",
    "        \"\"\"\n",
    "        \n",
    "        rows = []\n",
    "        sat_bins = np.linspace(0, 256, 51)  # 50 bins 0-255\n",
    "        global_data = {\n",
    "            'count': 0,\n",
    "            'lr_fft_sum': None,\n",
    "            'hr_fft_sum': None,\n",
    "            'grad_hr_sum': None,\n",
    "            'glcm_sum': None,  # shape (256, 256, 1, 1)\n",
    "            'sat_lr_counts': np.zeros(len(sat_bins) - 1, dtype=np.float64),\n",
    "            'sat_hr_counts': np.zeros(len(sat_bins) - 1, dtype=np.float64),\n",
    "            'sat_bins': sat_bins,\n",
    "            'noise_means_lr': [],\n",
    "        }\n",
    "        \n",
    "        pairs = list(ImagePairLoader.iter_pairs(lr_dir, hr_dir))\n",
    "        for lf, hf in tqdm(pairs, desc=\"Computing metrics\", unit=\"img\"):\n",
    "            lr_img, hr_img = ImagePairLoader.load_and_align(\n",
    "                os.path.join(lr_dir, lf),\n",
    "                os.path.join(hr_dir, hf),\n",
    "                interp_map=interp_map\n",
    "            )\n",
    "            \n",
    "            gray_lr = cv2.cvtColor(lr_img, cv2.COLOR_BGR2GRAY)\n",
    "            gray_hr = cv2.cvtColor(hr_img, cv2.COLOR_BGR2GRAY)\n",
    "            hsv_lr = cv2.cvtColor(lr_img, cv2.COLOR_BGR2HSV)\n",
    "            hsv_hr = cv2.cvtColor(hr_img, cv2.COLOR_BGR2HSV)\n",
    "            lpips_val = ImageDatasetAnalyzer.lpips_score(lr_img, hr_img)\n",
    "            psnr_val = ImageDatasetAnalyzer.psnr_metric(lr_img, hr_img)\n",
    "            ssim_val = ImageDatasetAnalyzer.ssim_metric(lr_img, hr_img)\n",
    "            glcm = ImageDatasetAnalyzer.glcm_features(\n",
    "                gray_lr,\n",
    "                levels=glcm_levels,\n",
    "                multi_angle=glcm_multi_angle\n",
    "            )\n",
    "            fd_lr = ImageDatasetAnalyzer.feature_distribution(lr_img, hsv_lr)\n",
    "            fd_hr = ImageDatasetAnalyzer.feature_distribution(hr_img, hsv_hr)\n",
    "            art_lr = ImageDatasetAnalyzer.detect_artifacts(lr_img, gray_lr)\n",
    "            art_hr = ImageDatasetAnalyzer.detect_artifacts(hr_img, gray_hr)\n",
    "            rms_lr = ImageDatasetAnalyzer.rms_noise(gray_lr)\n",
    "            rms_hr = ImageDatasetAnalyzer.rms_noise(gray_hr)\n",
    "            lap_var_lr = ImageDatasetAnalyzer.laplacian_variance(gray_lr)\n",
    "            lap_var_hr = ImageDatasetAnalyzer.laplacian_variance(gray_hr)\n",
    "            lr_edges = filters.sobel(gray_lr)\n",
    "            hr_edges = filters.sobel(gray_hr)\n",
    "            edge_diff = float(np.mean(hr_edges) - np.mean(lr_edges))\n",
    "            ch0_skew_lr = fd_lr.get('ch0_skew')\n",
    "            ch0_skew_hr = fd_hr.get('ch0_skew')\n",
    "            ch1_skew_lr = fd_lr.get('ch1_skew')\n",
    "            ch1_skew_hr = fd_hr.get('ch1_skew')\n",
    "            ch2_skew_lr = fd_lr.get('ch2_skew')\n",
    "            ch2_skew_hr = fd_hr.get('ch2_skew')\n",
    "            ch0_kurt_lr = fd_lr.get('ch0_kurt')\n",
    "            ch0_kurt_hr = fd_hr.get('ch0_kurt')\n",
    "            ch1_kurt_lr = fd_lr.get('ch1_kurt')\n",
    "            ch1_kurt_hr = fd_hr.get('ch1_kurt')\n",
    "            ch2_kurt_lr = fd_lr.get('ch2_kurt')\n",
    "            ch2_kurt_hr = fd_hr.get('ch2_kurt')\n",
    "\n",
    "            rows.append(\n",
    "                ImagePairMetrics(\n",
    "                    filename=lf.replace('\\\\', '/'),\n",
    "                    lpips=lpips_val,\n",
    "                    psnr=psnr_val,\n",
    "                    ssim=ssim_val,\n",
    "                    glcm_contrast=glcm['glcm_contrast'],\n",
    "                    glcm_homogeneity=glcm['glcm_homogeneity'],\n",
    "                    glcm_correlation=glcm['glcm_correlation'],\n",
    "                    rms_noise_lr=rms_lr,\n",
    "                    rms_noise_hr=rms_hr,\n",
    "                    lap_var_lr=lap_var_lr,\n",
    "                    lap_var_hr=lap_var_hr,\n",
    "                    blocking_lr=art_lr['blocking_score'],\n",
    "                    blocking_hr=art_hr['blocking_score'],\n",
    "                    color_noise_lr=art_lr['color_noise'],\n",
    "                    color_noise_hr=art_hr['color_noise'],\n",
    "                    ringing_lr=art_lr['ringing_artifact'],\n",
    "                    ringing_hr=art_hr['ringing_artifact'],\n",
    "                    saturation_mean_lr=fd_lr['saturation_mean'],\n",
    "                    saturation_mean_hr=fd_hr['saturation_mean'],\n",
    "                    brightness_mean_lr=fd_lr['brightness_mean'],\n",
    "                    brightness_mean_hr=fd_hr['brightness_mean'],\n",
    "                    edge_diff=edge_diff,\n",
    "                    ch0_skew_lr=ch0_skew_lr, \n",
    "                    ch0_skew_hr=ch0_skew_hr,\n",
    "                    ch1_skew_lr=ch1_skew_lr, \n",
    "                    ch1_skew_hr=ch1_skew_hr,\n",
    "                    ch2_skew_lr=ch2_skew_lr, \n",
    "                    ch2_skew_hr=ch2_skew_hr,\n",
    "                    ch0_kurt_lr=ch0_kurt_lr, \n",
    "                    ch0_kurt_hr=ch0_kurt_hr,\n",
    "                    ch1_kurt_lr=ch1_kurt_lr, \n",
    "                    ch1_kurt_hr=ch1_kurt_hr,\n",
    "                    ch2_kurt_lr=ch2_kurt_lr, \n",
    "                    ch2_kurt_hr=ch2_kurt_hr,\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            if global_data['lr_fft_sum'] is None:\n",
    "                lr_fft_mag = np.abs(np.fft.fftshift(np.fft.fft2(gray_lr)))\n",
    "                hr_fft_mag = np.abs(np.fft.fftshift(np.fft.fft2(gray_hr)))\n",
    "                global_data['lr_fft_sum'] = lr_fft_mag.astype(np.float64)\n",
    "                global_data['hr_fft_sum'] = hr_fft_mag.astype(np.float64)\n",
    "                \n",
    "                sobelx = cv2.Sobel(gray_hr, cv2.CV_64F, 1, 0, ksize=5)\n",
    "                sobely = cv2.Sobel(gray_hr, cv2.CV_64F, 0, 1, ksize=5)\n",
    "                grad_mag = np.sqrt(sobelx ** 2 + sobely ** 2)\n",
    "                global_data['grad_hr_sum'] = grad_mag\n",
    "                \n",
    "                lr_glcm_full = graycomatrix(\n",
    "                    gray_lr,\n",
    "                    [1],\n",
    "                    [0],\n",
    "                    256,\n",
    "                    symmetric=True,\n",
    "                    normed=True\n",
    "                )\n",
    "                \n",
    "                global_data['glcm_sum'] = lr_glcm_full.astype(np.float64)\n",
    "            else:\n",
    "                global_data['lr_fft_sum'] += np.abs(\n",
    "                    np.fft.fftshift(np.fft.fft2(gray_lr))\n",
    "                )\n",
    "                \n",
    "                global_data['hr_fft_sum'] += np.abs(\n",
    "                    np.fft.fftshift(np.fft.fft2(gray_hr))\n",
    "                )\n",
    "                \n",
    "                sobelx = cv2.Sobel(gray_hr, cv2.CV_64F, 1, 0, ksize=5)\n",
    "                sobely = cv2.Sobel(gray_hr, cv2.CV_64F, 0, 1, ksize=5)\n",
    "                grad_mag = np.sqrt(sobelx ** 2 + sobely ** 2)\n",
    "                global_data['grad_hr_sum'] += grad_mag\n",
    "                \n",
    "                lr_glcm_full = graycomatrix(\n",
    "                    gray_lr,\n",
    "                    [1],\n",
    "                    [0],\n",
    "                    256,\n",
    "                    symmetric=True,\n",
    "                    normed=True\n",
    "                )\n",
    "                \n",
    "                global_data['glcm_sum'] += lr_glcm_full\n",
    "            \n",
    "            sat_lr = hsv_lr[:, :, 1]\n",
    "            sat_hr = hsv_hr[:, :, 1]\n",
    "            lr_counts, _ = np.histogram(sat_lr, bins=global_data['sat_bins'])\n",
    "            hr_counts, _ = np.histogram(sat_hr, bins=global_data['sat_bins'])\n",
    "            global_data['sat_lr_counts'] += lr_counts\n",
    "            global_data['sat_hr_counts'] += hr_counts\n",
    "            global_data['noise_means_lr'].append(art_lr['color_noise'])\n",
    "            global_data['count'] += 1\n",
    "            \n",
    "        return rows, global_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1763473",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StatsReporter:\n",
    "    \"\"\"Utilities to convert and summarize metrics to a DataFrame.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def dataframe(rows):\n",
    "        \"\"\"Convert list of ImagePairMetrics into a DataFrame.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        rows : list[ImagePairMetrics]\n",
    "            List of metric objects.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pandas.DataFrame\n",
    "            One row per image pair.\n",
    "        \"\"\"\n",
    "        \n",
    "        return pd.DataFrame([r.as_dict() for r in rows])\n",
    "\n",
    "    @staticmethod\n",
    "    def summary(df):\n",
    "        \"\"\"Return basic descriptive statistics.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pandas.DataFrame\n",
    "            Metrics data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pandas.DataFrame\n",
    "            mean, std and quartiles.\n",
    "        \"\"\"\n",
    "        \n",
    "        return df.describe().T[['mean', 'std', '25%', '50%', '75%']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d57ae2",
   "metadata": {},
   "source": [
    "## Visualization methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "769cc582",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataVisualization:\n",
    "    \"\"\"Visualization utilities for exploratory analysis.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def save_visual_example(lr_img, hr_img, output_path, lpips_val):\n",
    "        \"\"\"Save comparison figure and a difference heatmap.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        lr_img : np.ndarray\n",
    "            LR image.\n",
    "        hr_img : np.ndarray\n",
    "            HR image.\n",
    "        output_path : str\n",
    "            Output PNG path.\n",
    "        lpips_val : float\n",
    "            LPIPS value for title.\n",
    "        \"\"\"\n",
    "        \n",
    "        lr_resized = cv2.resize(\n",
    "            lr_img,\n",
    "            (hr_img.shape[1], hr_img.shape[0]),\n",
    "            interpolation=cv2.INTER_CUBIC\n",
    "        )\n",
    "\n",
    "        diff_map = cv2.absdiff(lr_resized, hr_img)\n",
    "        diff_map_color = cv2.applyColorMap(\n",
    "            cv2.convertScaleAbs(cv2.cvtColor(diff_map, cv2.COLOR_BGR2GRAY)),\n",
    "            cv2.COLORMAP_JET\n",
    "        )\n",
    "\n",
    "        _, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "        axes[0].imshow(cv2.cvtColor(lr_resized, cv2.COLOR_BGR2RGB))\n",
    "        axes[0].set_title(\"Rescaled LR\")\n",
    "        axes[0].axis(\"off\")\n",
    "\n",
    "        axes[1].imshow(cv2.cvtColor(hr_img, cv2.COLOR_BGR2RGB))\n",
    "        axes[1].set_title(\"HR\")\n",
    "        axes[1].axis(\"off\")\n",
    "\n",
    "        axes[2].imshow(diff_map_color)\n",
    "        axes[2].set_title(f\"Difference map\\nLPIPS: {lpips_val:.4f}\")\n",
    "        axes[2].axis(\"off\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()\n",
    "\n",
    "    @staticmethod\n",
    "    def create_advanced_visualizations(lr_img, hr_img, output_path):\n",
    "        \"\"\"Create per-pair advanced panel: spectra, gradients, GLCM, noise\n",
    "        map, saturation distribution.\"\"\"\n",
    "        plt.figure(figsize=(20, 10))\n",
    "\n",
    "        # 1. LR Spectrum\n",
    "        plt.subplot(231)\n",
    "        lr_fft = np.fft.fft2(cv2.cvtColor(lr_img, cv2.COLOR_BGR2GRAY))\n",
    "        plt.imshow(np.log(np.abs(np.fft.fftshift(lr_fft)) + 1e-8),\n",
    "                   cmap=\"viridis\")\n",
    "        plt.title(\"LR Frequency Spectrum\")\n",
    "        plt.colorbar()\n",
    "\n",
    "        # 2. HR Spectrum\n",
    "        plt.subplot(232)\n",
    "        hr_fft = np.fft.fft2(cv2.cvtColor(hr_img, cv2.COLOR_BGR2GRAY))\n",
    "        plt.imshow(np.log(np.abs(np.fft.fftshift(hr_fft)) + 1e-8),\n",
    "                   cmap=\"viridis\")\n",
    "        plt.title(\"HR Frequency Spectrum\")\n",
    "        plt.colorbar()\n",
    "\n",
    "        # 3. HR Gradient Magnitude\n",
    "        plt.subplot(233)\n",
    "        gray_hr = cv2.cvtColor(hr_img, cv2.COLOR_BGR2GRAY)\n",
    "        sobelx = cv2.Sobel(gray_hr, cv2.CV_64F, 1, 0, ksize=5)\n",
    "        sobely = cv2.Sobel(gray_hr, cv2.CV_64F, 0, 1, ksize=5)\n",
    "        gradient_magnitude = np.sqrt(sobelx ** 2 + sobely ** 2)\n",
    "        plt.imshow(gradient_magnitude, cmap=\"magma\")\n",
    "        plt.title(\"Gradient Magnitude\")\n",
    "        plt.colorbar()\n",
    "        \n",
    "        # 4. LR GLCM\n",
    "        plt.subplot(234)\n",
    "        lr_gray = cv2.cvtColor(lr_img, cv2.COLOR_BGR2GRAY)\n",
    "        lr_glcm = graycomatrix(\n",
    "            lr_gray, [1], [0], 256, symmetric=True, normed=True\n",
    "        )\n",
    "        lr_contrast = graycoprops(lr_glcm, \"contrast\")[0, 0]\n",
    "        plt.imshow(lr_glcm[:, :, 0, 0], cmap=\"plasma\")\n",
    "        plt.title(f\"LR GLCM (Contrast: {lr_contrast:.2f})\")\n",
    "        plt.colorbar()\n",
    "\n",
    "        # 5. LR Color Noise Map\n",
    "        plt.subplot(235)\n",
    "        blur = cv2.GaussianBlur(lr_img, (5, 5), 0)\n",
    "        noise_map = np.mean(\n",
    "            np.abs(lr_img.astype(float) - blur.astype(float)), axis=2\n",
    "        )\n",
    "        color_noise_mean = float(\n",
    "            np.mean(np.abs(lr_img.astype(float) - blur.astype(float)))\n",
    "        )\n",
    "        plt.imshow(noise_map, cmap=\"hot\")\n",
    "        plt.title(f\"Noise Map (Mean: {color_noise_mean:.2f})\")\n",
    "        plt.colorbar()\n",
    "\n",
    "        # 6. Saturation Distribution LR vs HR\n",
    "        plt.subplot(236)\n",
    "        lr_hsv = cv2.cvtColor(lr_img, cv2.COLOR_BGR2HSV)[:, :, 1]\n",
    "        hr_hsv = cv2.cvtColor(hr_img, cv2.COLOR_BGR2HSV)[:, :, 1]\n",
    "        plt.hist(lr_hsv.ravel(), bins=50, alpha=0.5, density=True,\n",
    "                 label=\"LR\", color=\"steelblue\")\n",
    "        plt.hist(hr_hsv.ravel(), bins=50, alpha=0.5, density=True,\n",
    "                 label=\"HR\", color=\"orange\")\n",
    "        plt.title(\"Saturation Distribution\")\n",
    "        plt.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        plt.savefig(output_path, dpi=300, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "    @staticmethod\n",
    "    def create_global_advanced_visualizations(global_data, output_path):\n",
    "        \"\"\"Create a global panel with averaged spectra, gradient, averaged\n",
    "        GLCM, noise mean distribution, saturation densities.\"\"\"\n",
    "        \n",
    "        if global_data is None or global_data.get('count', 0) == 0:\n",
    "            print(\"No global data available to create advanced visualization.\")\n",
    "            return\n",
    "\n",
    "        n = global_data['count']\n",
    "        eps = 1e-8\n",
    "        # Average spectra (compute log after averaging magnitudes)\n",
    "        lr_fft_avg = global_data['lr_fft_sum'] / n\n",
    "        hr_fft_avg = global_data['hr_fft_sum'] / n\n",
    "        # Average gradient magnitude\n",
    "        grad_hr_avg = global_data['grad_hr_sum'] / n\n",
    "        # Average (unnormalized-sum) GLCM then renormalize\n",
    "        glcm_sum = global_data['glcm_sum']\n",
    "        glcm_avg = glcm_sum / glcm_sum.sum()\n",
    "        glcm_contrast = graycoprops(glcm_avg, \"contrast\")[0, 0]\n",
    "\n",
    "        # Saturation histograms (normalize to density)\n",
    "        sat_bins = global_data['sat_bins']\n",
    "        bin_width = sat_bins[1] - sat_bins[0]\n",
    "        sat_lr_density = (\n",
    "            global_data['sat_lr_counts'] /\n",
    "            (global_data['sat_lr_counts'].sum() * bin_width + eps)\n",
    "        )\n",
    "        sat_hr_density = (\n",
    "            global_data['sat_hr_counts'] /\n",
    "            (global_data['sat_hr_counts'].sum() * bin_width + eps)\n",
    "        )\n",
    "        sat_centers = 0.5 * (sat_bins[:-1] + sat_bins[1:])\n",
    "\n",
    "        noise_means = np.array(global_data['noise_means_lr'], dtype=np.float64)\n",
    "\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        \n",
    "        # 1 LR Spectrum\n",
    "        plt.subplot(231)\n",
    "        plt.imshow(np.log(lr_fft_avg + eps), cmap=\"viridis\")\n",
    "        plt.title(\"LR Avg Frequency Spectrum\")\n",
    "        plt.colorbar()\n",
    "        \n",
    "        # 2 HR Spectrum\n",
    "        plt.subplot(232)\n",
    "        plt.imshow(np.log(hr_fft_avg + eps), cmap=\"viridis\")\n",
    "        plt.title(\"HR Avg Frequency Spectrum\")\n",
    "        plt.colorbar()\n",
    "        \n",
    "        # 3 Gradient Magnitude\n",
    "        plt.subplot(233)\n",
    "        plt.imshow(grad_hr_avg, cmap=\"magma\")\n",
    "        plt.title(\"HR Avg Gradient Magnitude\")\n",
    "        plt.colorbar()\n",
    "        \n",
    "        # 4 GLCM\n",
    "        plt.subplot(234)\n",
    "        plt.imshow(glcm_avg[:, :, 0, 0], cmap=\"plasma\")\n",
    "        plt.title(f\"LR Avg GLCM (Contrast: {glcm_contrast:.2f})\")\n",
    "        plt.colorbar()\n",
    "        \n",
    "        # 5 Noise mean distribution\n",
    "        plt.subplot(235)\n",
    "        plt.hist(\n",
    "            noise_means, bins=30, color='tomato', edgecolor='black', alpha=0.8\n",
    "        )\n",
    "        plt.title(\n",
    "            f\"LR Color Noise Mean Dist\\nMean={noise_means.mean():.2f} \"\n",
    "            f\"Std={noise_means.std():.2f}\"\n",
    "        )\n",
    "        plt.xlabel(\"Per-image color noise mean\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        \n",
    "        # 6 Saturation density\n",
    "        plt.subplot(236)\n",
    "        plt.plot(sat_centers, sat_lr_density, label='LR', color='steelblue')\n",
    "        plt.plot(sat_centers, sat_hr_density, label='HR', color='orange')\n",
    "        plt.title(\"Global Saturation Density\")\n",
    "        plt.xlabel(\"Saturation value\")\n",
    "        plt.ylabel(\"Density\")\n",
    "        \n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        plt.savefig(output_path, dpi=300, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "    @staticmethod\n",
    "    def basic_distributions(df, output_dir):\n",
    "        \"\"\"\n",
    "            Save distributions.png: \n",
    "                original basic histograms + integrated GLCM histograms.\n",
    "            Metrics: \n",
    "                lpips, psnr, ssim, lap_var_hr, rms_noise_hr, blocking_hr, \n",
    "                glcm_contrast, glcm_homogeneity, glcm_correlation.\n",
    "        \"\"\"\n",
    "        \n",
    "        metrics = [\n",
    "            'lpips', 'psnr', 'ssim', 'lap_var_hr', 'rms_noise_hr', \n",
    "            'blocking_hr', 'glcm_contrast', 'glcm_homogeneity', \n",
    "            'glcm_correlation'\n",
    "        ]\n",
    "        colors = [\n",
    "            \"#1f77b4\",\"#ff7f0e\",\"#2ca02c\",\"#d62728\",\"#9467bd\",\n",
    "            \"#8c564b\",\"#6baed6\",\"#9edae5\",\"#17becf\"\n",
    "        ]\n",
    "        plt.figure(figsize=(18, 14))\n",
    "        rows = 3; cols = 3\n",
    "        for i, (m, c) in enumerate(zip(metrics, colors), 1):\n",
    "            plt.subplot(rows, cols, i)\n",
    "            plt.hist(df[m], bins=30, color=c, edgecolor='black', alpha=0.85)\n",
    "            plt.title(m)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\n",
    "            os.path.join(output_dir, 'distributions.png'),\n",
    "            dpi=300, bbox_inches='tight'\n",
    "        )\n",
    "        plt.close()\n",
    "\n",
    "    @staticmethod\n",
    "    def artifact_color_histograms(df, output_dir):\n",
    "        \"\"\"Overlay LR vs HR histograms + edge diff.\"\"\"\n",
    "        overlay_pairs = [\n",
    "            ('blocking_lr', 'blocking_hr', 'Blocking Score'),\n",
    "            ('ringing_lr', 'ringing_hr', 'Ringing Artifact'),\n",
    "            ('saturation_mean_lr', 'saturation_mean_hr', 'Saturation Mean'),\n",
    "            ('brightness_mean_lr', 'brightness_mean_hr', 'Brightness Mean'),\n",
    "            ('color_noise_lr', 'color_noise_hr', 'Color Noise'),\n",
    "        ]\n",
    "        rows = 3; cols = 3\n",
    "        plt.figure(figsize=(16, 12))\n",
    "        for i, (lr_col, hr_col, title) in enumerate(overlay_pairs, 1):\n",
    "            plt.subplot(rows, cols, i)\n",
    "            plt.hist(\n",
    "                df[lr_col], bins=30, alpha=0.55, label='LR', color='#1f77b4',\n",
    "                edgecolor='black', linewidth=0.4\n",
    "            )\n",
    "            plt.hist(\n",
    "                df[hr_col], bins=30, alpha=0.55, label='HR', color='#ff7f0e',\n",
    "                edgecolor='black', linewidth=0.4\n",
    "            )\n",
    "            plt.title(title)\n",
    "            plt.legend(fontsize=8)\n",
    "        # edge_diff\n",
    "        plt.subplot(rows, cols, 7)\n",
    "        plt.hist(df['edge_diff'], bins=30, color='#2ca02c', alpha=0.8, edgecolor='black')\n",
    "        plt.title('Edge Mean Diff (HR-LR)')\n",
    "        plt.subplot(rows, cols, 8)\n",
    "        sns.kdeplot(df['edge_diff'], fill=True, color='#2ca02c')\n",
    "        plt.title('Edge Diff Density')\n",
    "        plt.subplot(rows, cols, 9)\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, 'artifact_color_histograms.png'), dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    @staticmethod\n",
    "    def artifact_boxplots(df, output_dir):\n",
    "        \"\"\"Save artifact_boxplots.png with LR vs HR boxplots.\"\"\"\n",
    "        \n",
    "        plt.figure(figsize=(11, 6))\n",
    "        groups = [\n",
    "            ('blocking_lr', 'blocking_hr', 'Blocking'),\n",
    "            ('ringing_lr', 'ringing_hr', 'Ringing'),\n",
    "            ('saturation_mean_lr', 'saturation_mean_hr', 'Saturation'),\n",
    "            ('brightness_mean_lr', 'brightness_mean_hr', 'Brightness'),\n",
    "            ('color_noise_lr', 'color_noise_hr', 'ColorNoise'),\n",
    "        ]\n",
    "        data = []\n",
    "        labels = []\n",
    "        for lr_col, hr_col, name in groups:\n",
    "            data.append(df[lr_col]); labels.append(f'{name} LR')\n",
    "            data.append(df[hr_col]); labels.append(f'{name} HR')\n",
    "        box = plt.boxplot(data, labels=labels, patch_artist=True)\n",
    "        palette = ['#1f77b4', '#ff7f0e'] * len(groups)\n",
    "        for patch, col in zip(box['boxes'], palette):\n",
    "            patch.set_facecolor(col); patch.set_alpha(0.55)\n",
    "        plt.xticks(rotation=25, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, 'artifact_boxplots.png'), dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    @staticmethod\n",
    "    def channel_shape_bars(df, output_dir):\n",
    "        \"\"\"Complementary: multi-bar chart of per-channel skew & kurt (LR vs HR).\"\"\"\n",
    "        \n",
    "        required = [\n",
    "            'ch0_skew_lr','ch0_skew_hr','ch1_skew_lr','ch1_skew_hr','ch2_skew_lr','ch2_skew_hr',\n",
    "            'ch0_kurt_lr','ch0_kurt_hr','ch1_kurt_lr','ch1_kurt_hr','ch2_kurt_lr','ch2_kurt_hr'\n",
    "        ]\n",
    "        if not all(r in df.columns for r in required):\n",
    "            print('Channel shape stats missing; skipping channel_shape_bars.')\n",
    "            return\n",
    "        \n",
    "        skew_means_lr = [df['ch0_skew_lr'].mean(), df['ch1_skew_lr'].mean(), df['ch2_skew_lr'].mean()]\n",
    "        skew_means_hr = [df['ch0_skew_hr'].mean(), df['ch1_skew_hr'].mean(), df['ch2_skew_hr'].mean()]\n",
    "        kurt_means_lr = [df['ch0_kurt_lr'].mean(), df['ch1_kurt_lr'].mean(), df['ch2_kurt_lr'].mean()]\n",
    "        kurt_means_hr = [df['ch0_kurt_hr'].mean(), df['ch1_kurt_hr'].mean(), df['ch2_kurt_hr'].mean()]\n",
    "        channels = ['B','G','R']; x = np.arange(len(channels)); width = 0.18\n",
    "        \n",
    "        plt.figure(figsize=(12,6))\n",
    "        plt.bar(x - 1.5*width, skew_means_lr, width, label='Skew LR', color='#3182bd')\n",
    "        plt.bar(x - 0.5*width, skew_means_hr, width, label='Skew HR', color='#6baed6')\n",
    "        plt.bar(x + 0.5*width, kurt_means_lr, width, label='Kurt LR', color='#fd8d3c')\n",
    "        plt.bar(x + 1.5*width, kurt_means_hr, width, label='Kurt HR', color='#fdd0a2')\n",
    "        plt.axhline(0, color='black', linewidth=0.8)\n",
    "        plt.xticks(x, channels)\n",
    "        plt.ylabel('Value (mean)')\n",
    "        plt.title('Per-Channel Skew & Kurtosis (LR vs HR)')\n",
    "        plt.legend(ncol=2)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, 'channel_shape_bars.png'), dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    @staticmethod\n",
    "    def correlation_matrix(df, output_dir):\n",
    "        \"\"\"Generate a correlation heatmap.\n",
    "        Saves: correlation_matrix.png. Includes extended metrics if present.\"\"\"\n",
    "        \n",
    "        metrics = [\n",
    "            'lpips', 'psnr', 'ssim', 'lap_var_hr', 'rms_noise_hr', \n",
    "            'blocking_hr','ringing_hr', 'saturation_mean_hr', \n",
    "            'brightness_mean_hr', 'edge_diff'\n",
    "        ]\n",
    "        \n",
    "        available = [m for m in metrics if m in df.columns]\n",
    "        if len(available) < 3:\n",
    "            print('Not enough columns for correlation matrix.')\n",
    "            return\n",
    "        \n",
    "        corr = df[available].corr()\n",
    "        plt.figure(figsize=(1.2 * len(available), 0.9 * len(available)))\n",
    "        sns.heatmap(\n",
    "            corr, cmap='flare', annot=True, fmt='.2f', center=0, square=True,\n",
    "            cbar_kws={'shrink': 0.75}\n",
    "        )\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\n",
    "            os.path.join(output_dir, 'correlation_matrix.png'),\n",
    "            dpi=300, bbox_inches='tight'\n",
    "        )\n",
    "        plt.close()\n",
    "\n",
    "    @staticmethod\n",
    "    def scatter_relations(df, output_dir):\n",
    "        \"\"\"Scatter plots for metrics relations.\n",
    "        Saves: scatter_relations.png\n",
    "        Pairs:\n",
    "          (lpips, psnr), (lpips, ssim), (lap_var_hr, psnr),\n",
    "          (rms_noise_hr, psnr), (blocking_hr, ringing_hr),\n",
    "          (saturation_mean_hr, brightness_mean_hr),\n",
    "          (edge_diff, psnr), (edge_diff, ssim)\n",
    "        \"\"\"\n",
    "        \n",
    "        pairs = [\n",
    "            ('lpips', 'psnr', 'LPIPS vs PSNR', '#1f77b4'),\n",
    "            ('lpips', 'ssim', 'LPIPS vs SSIM', '#ff7f0e'),\n",
    "            ('lap_var_hr', 'psnr', 'LaplacianVar HR vs PSNR', '#2ca02c'),\n",
    "            ('rms_noise_hr', 'psnr', 'Noise HR vs PSNR', '#d62728'),\n",
    "            ('blocking_hr', 'ringing_hr', 'Blocking vs Ringing', '#9467bd'),\n",
    "            ('saturation_mean_hr', 'brightness_mean_hr',\n",
    "             'Saturation vs Brightness', '#8c564b'),\n",
    "            ('edge_diff', 'psnr', 'Edge Diff vs PSNR', '#e377c2'),\n",
    "            ('edge_diff', 'ssim', 'Edge Diff vs SSIM', '#7f7f7f')\n",
    "        ]\n",
    "        rows, cols = 4, 2\n",
    "        plt.figure(figsize=(cols * 5, rows * 3.2))\n",
    "        for i, (x, y, title, color) in enumerate(pairs, 1):\n",
    "            if x not in df.columns or y not in df.columns:\n",
    "                continue\n",
    "            plt.subplot(rows, cols, i)\n",
    "            plt.scatter(\n",
    "                df[x], df[y], s=14, alpha=0.75, color=color,\n",
    "                edgecolors='white', linewidths=0.4\n",
    "            )\n",
    "            plt.xlabel(x)\n",
    "            plt.ylabel(y)\n",
    "            plt.title(title, fontsize=9)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\n",
    "            os.path.join(output_dir, 'scatter_relations.png'),\n",
    "            dpi=300, bbox_inches='tight'\n",
    "        )\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16c7f06",
   "metadata": {},
   "source": [
    "## Dataset processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24e9b686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_eda_pipeline(\n",
    "    lr_dir,\n",
    "    hr_dir,\n",
    "    output_dir=\"eda_results\",\n",
    "    top_k_examples=1,\n",
    "    glcm_multi_angle=False,\n",
    "    glcm_levels=64,\n",
    "    interp_map_path=\"\",\n",
    "):\n",
    "    \"\"\"Execute full EDA pipeline and return metrics DataFrame.\n",
    "\n",
    "    Generates:\n",
    "      - advanced_global_panel.png\n",
    "      - distributions.png\n",
    "      - artifact_color_histograms.png\n",
    "      - artifact_boxplots.png\n",
    "      - channel_shape_bars.png\n",
    "      - correlation_matrix.png\n",
    "      - scatter_relations.png\n",
    "      - LPIPS_Scenarios\n",
    "    \"\"\"\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Load interpolation mapping\n",
    "    interp_map = None\n",
    "    if interp_map_path and os.path.exists(interp_map_path):\n",
    "        try:\n",
    "            with open(interp_map_path, 'rb') as f:\n",
    "                interp_map = pickle.load(f)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: could not load interpolation map: {e}\")\n",
    "    else:\n",
    "        print(\"Interpolation map not found; default interpolation will be used.\")\n",
    "    \n",
    "    examples_dir = os.path.join(output_dir, \"LPIPS_Scenarios\")\n",
    "    best_dir = os.path.join(examples_dir, \"best_scenarios\")\n",
    "    worst_dir = os.path.join(examples_dir, \"worst_scenarios\")\n",
    "\n",
    "    for d in (best_dir, worst_dir):\n",
    "        os.makedirs(d, exist_ok=True)\n",
    "    \n",
    "    # Collect metrics + global visualization data\n",
    "    rows, global_data = MetricsAggregator.collect(\n",
    "        lr_dir,\n",
    "        hr_dir,\n",
    "        glcm_multi_angle=glcm_multi_angle,\n",
    "        glcm_levels=glcm_levels,\n",
    "        interp_map=interp_map,\n",
    "    )\n",
    "    df = StatsReporter.dataframe(rows)\n",
    "\n",
    "    # Global data visualizations\n",
    "    ImageDataVisualization.create_global_advanced_visualizations(\n",
    "        global_data,\n",
    "        os.path.join(output_dir, \"advanced_global_panel.png\"),\n",
    "    )\n",
    "    ImageDataVisualization.basic_distributions(df, output_dir)\n",
    "    ImageDataVisualization.artifact_color_histograms(df, output_dir)\n",
    "    ImageDataVisualization.artifact_boxplots(df, output_dir)\n",
    "    ImageDataVisualization.channel_shape_bars(df, output_dir)\n",
    "    ImageDataVisualization.correlation_matrix(df, output_dir)\n",
    "    ImageDataVisualization.scatter_relations(df, output_dir)\n",
    "    df_sorted = df.sort_values(\"lpips\")\n",
    "    selections = [\n",
    "        (df_sorted.head(top_k_examples), best_dir, \"best\"),\n",
    "        (df_sorted.tail(top_k_examples), worst_dir, \"worst\"),\n",
    "    ]\n",
    "    \n",
    "    for subset, scenario_dir, label in selections:\n",
    "        for rank, rel_path in enumerate(subset[\"filename\"].tolist(), 1):\n",
    "            lr_full = os.path.join(lr_dir, rel_path)\n",
    "            hr_full = os.path.join(hr_dir, rel_path)\n",
    "            \n",
    "            lr_img, hr_img = ImagePairLoader.load_and_align(\n",
    "                lr_full,\n",
    "                hr_full,\n",
    "                interp_map=interp_map\n",
    "            )\n",
    "            \n",
    "            lp_val = subset.loc[subset[\"filename\"] == rel_path, \"lpips\"].values[0]\n",
    "\n",
    "            # Normalize relative path and split\n",
    "            rel_norm = rel_path.replace(\"\\\\\", \"/\")\n",
    "            rel_no_ext = os.path.splitext(rel_norm)[0]\n",
    "            parent = os.path.dirname(rel_no_ext)\n",
    "            stem = os.path.basename(rel_no_ext)\n",
    "\n",
    "            # Create output directory preserving the parent structure\n",
    "            save_dir = os.path.join(scenario_dir, parent) if parent else scenario_dir\n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "            # Build output filenames without duplicating extensions\n",
    "            out_basic = os.path.join(save_dir, f\"{label}_{rank}_{stem}.png\")\n",
    "            ImageDataVisualization.save_visual_example(\n",
    "                lr_img, hr_img, out_basic, lp_val\n",
    "            )\n",
    "\n",
    "            out_adv = os.path.join(save_dir, f\"{label}_{rank}_advanced_{stem}.png\")\n",
    "            ImageDataVisualization.create_advanced_visualizations(\n",
    "                lr_img, hr_img, out_adv\n",
    "            )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82e449c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing metrics:   0%|          | 0/313 [00:00<?, ?img/s]c:\\Users\\bgmanuel\\anaconda3\\envs\\py310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\bgmanuel\\anaconda3\\envs\\py310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: c:\\Users\\bgmanuel\\anaconda3\\envs\\py310\\lib\\site-packages\\lpips\\weights\\v0.1\\alex.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing metrics: 100%|██████████| 313/313 [06:12<00:00,  1.19s/img]\n",
      "C:\\Users\\bgmanuel\\AppData\\Local\\Temp\\ipykernel_24896\\3790270673.py:296: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  box = plt.boxplot(data, labels=labels, patch_artist=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>lpips</th>\n",
       "      <th>psnr</th>\n",
       "      <th>ssim</th>\n",
       "      <th>glcm_contrast</th>\n",
       "      <th>glcm_homogeneity</th>\n",
       "      <th>glcm_correlation</th>\n",
       "      <th>rms_noise_lr</th>\n",
       "      <th>rms_noise_hr</th>\n",
       "      <th>lap_var_lr</th>\n",
       "      <th>...</th>\n",
       "      <th>ch1_skew_lr</th>\n",
       "      <th>ch1_skew_hr</th>\n",
       "      <th>ch2_skew_lr</th>\n",
       "      <th>ch2_skew_hr</th>\n",
       "      <th>ch0_kurt_lr</th>\n",
       "      <th>ch0_kurt_hr</th>\n",
       "      <th>ch1_kurt_lr</th>\n",
       "      <th>ch1_kurt_hr</th>\n",
       "      <th>ch2_kurt_lr</th>\n",
       "      <th>ch2_kurt_hr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>high_z_offset/high_z_offset0.png</td>\n",
       "      <td>0.364281</td>\n",
       "      <td>25.366058</td>\n",
       "      <td>0.803856</td>\n",
       "      <td>137.410715</td>\n",
       "      <td>0.149594</td>\n",
       "      <td>0.934708</td>\n",
       "      <td>2.499807</td>\n",
       "      <td>7.405629</td>\n",
       "      <td>108.620061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036239</td>\n",
       "      <td>-0.030008</td>\n",
       "      <td>-0.056324</td>\n",
       "      <td>-0.109049</td>\n",
       "      <td>-0.064233</td>\n",
       "      <td>-0.078027</td>\n",
       "      <td>-0.101885</td>\n",
       "      <td>-0.142501</td>\n",
       "      <td>-0.115562</td>\n",
       "      <td>-0.141359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>high_z_offset/high_z_offset1.png</td>\n",
       "      <td>0.251316</td>\n",
       "      <td>27.754356</td>\n",
       "      <td>0.847467</td>\n",
       "      <td>135.974401</td>\n",
       "      <td>0.161373</td>\n",
       "      <td>0.941820</td>\n",
       "      <td>2.532183</td>\n",
       "      <td>5.740295</td>\n",
       "      <td>107.357917</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.242923</td>\n",
       "      <td>-0.255645</td>\n",
       "      <td>-0.419483</td>\n",
       "      <td>-0.414943</td>\n",
       "      <td>0.167955</td>\n",
       "      <td>0.057892</td>\n",
       "      <td>0.143544</td>\n",
       "      <td>-0.011911</td>\n",
       "      <td>0.158280</td>\n",
       "      <td>-0.028525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>high_z_offset/high_z_offset10.png</td>\n",
       "      <td>0.349757</td>\n",
       "      <td>24.708093</td>\n",
       "      <td>0.725036</td>\n",
       "      <td>225.869160</td>\n",
       "      <td>0.430218</td>\n",
       "      <td>0.887708</td>\n",
       "      <td>6.394023</td>\n",
       "      <td>6.363694</td>\n",
       "      <td>751.291854</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.324179</td>\n",
       "      <td>-0.352662</td>\n",
       "      <td>-0.423683</td>\n",
       "      <td>-0.460285</td>\n",
       "      <td>0.299866</td>\n",
       "      <td>0.121729</td>\n",
       "      <td>0.419595</td>\n",
       "      <td>0.147142</td>\n",
       "      <td>0.493415</td>\n",
       "      <td>0.164363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>high_z_offset/high_z_offset100.png</td>\n",
       "      <td>0.317964</td>\n",
       "      <td>26.041058</td>\n",
       "      <td>0.748882</td>\n",
       "      <td>82.977939</td>\n",
       "      <td>0.161440</td>\n",
       "      <td>0.944976</td>\n",
       "      <td>2.002901</td>\n",
       "      <td>6.041940</td>\n",
       "      <td>69.841931</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.079562</td>\n",
       "      <td>-0.209162</td>\n",
       "      <td>-0.347382</td>\n",
       "      <td>-0.432156</td>\n",
       "      <td>0.391550</td>\n",
       "      <td>0.152999</td>\n",
       "      <td>0.459532</td>\n",
       "      <td>0.143770</td>\n",
       "      <td>0.626193</td>\n",
       "      <td>0.207427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>high_z_offset/high_z_offset101.png</td>\n",
       "      <td>0.415194</td>\n",
       "      <td>26.146266</td>\n",
       "      <td>0.759185</td>\n",
       "      <td>89.467270</td>\n",
       "      <td>0.160775</td>\n",
       "      <td>0.956186</td>\n",
       "      <td>2.164097</td>\n",
       "      <td>6.394686</td>\n",
       "      <td>82.893296</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.129830</td>\n",
       "      <td>-0.109321</td>\n",
       "      <td>-0.380877</td>\n",
       "      <td>-0.322283</td>\n",
       "      <td>0.179148</td>\n",
       "      <td>0.221096</td>\n",
       "      <td>0.304085</td>\n",
       "      <td>0.258230</td>\n",
       "      <td>0.500662</td>\n",
       "      <td>0.378809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>low_z_offset/low_z_offset95.png</td>\n",
       "      <td>0.398480</td>\n",
       "      <td>27.146761</td>\n",
       "      <td>0.767963</td>\n",
       "      <td>130.535761</td>\n",
       "      <td>0.470106</td>\n",
       "      <td>0.883706</td>\n",
       "      <td>4.739694</td>\n",
       "      <td>4.937069</td>\n",
       "      <td>378.520439</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.708274</td>\n",
       "      <td>-0.753500</td>\n",
       "      <td>-0.787584</td>\n",
       "      <td>-0.841872</td>\n",
       "      <td>0.191959</td>\n",
       "      <td>0.171960</td>\n",
       "      <td>0.684935</td>\n",
       "      <td>0.758831</td>\n",
       "      <td>0.903825</td>\n",
       "      <td>1.084455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>low_z_offset/low_z_offset96.png</td>\n",
       "      <td>0.230179</td>\n",
       "      <td>31.569480</td>\n",
       "      <td>0.907952</td>\n",
       "      <td>49.799471</td>\n",
       "      <td>0.249285</td>\n",
       "      <td>0.957178</td>\n",
       "      <td>1.312079</td>\n",
       "      <td>4.030325</td>\n",
       "      <td>29.217389</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.760076</td>\n",
       "      <td>-0.784344</td>\n",
       "      <td>-0.937650</td>\n",
       "      <td>-0.946355</td>\n",
       "      <td>-0.350854</td>\n",
       "      <td>-0.279414</td>\n",
       "      <td>0.358212</td>\n",
       "      <td>0.445815</td>\n",
       "      <td>0.855934</td>\n",
       "      <td>0.951866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>low_z_offset/low_z_offset97.png</td>\n",
       "      <td>0.191707</td>\n",
       "      <td>35.451120</td>\n",
       "      <td>0.942800</td>\n",
       "      <td>50.536258</td>\n",
       "      <td>0.507053</td>\n",
       "      <td>0.962478</td>\n",
       "      <td>2.999149</td>\n",
       "      <td>1.779312</td>\n",
       "      <td>157.944040</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.401852</td>\n",
       "      <td>-0.401222</td>\n",
       "      <td>-0.527594</td>\n",
       "      <td>-0.529595</td>\n",
       "      <td>-0.490090</td>\n",
       "      <td>-0.487183</td>\n",
       "      <td>-0.579616</td>\n",
       "      <td>-0.561587</td>\n",
       "      <td>-0.440199</td>\n",
       "      <td>-0.405477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>low_z_offset/low_z_offset98.png</td>\n",
       "      <td>0.305755</td>\n",
       "      <td>29.097566</td>\n",
       "      <td>0.824472</td>\n",
       "      <td>85.593845</td>\n",
       "      <td>0.479782</td>\n",
       "      <td>0.905295</td>\n",
       "      <td>3.869637</td>\n",
       "      <td>3.417618</td>\n",
       "      <td>258.198508</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.663705</td>\n",
       "      <td>-0.816551</td>\n",
       "      <td>-0.740988</td>\n",
       "      <td>-0.953585</td>\n",
       "      <td>0.030360</td>\n",
       "      <td>0.056749</td>\n",
       "      <td>0.276913</td>\n",
       "      <td>0.613602</td>\n",
       "      <td>0.294812</td>\n",
       "      <td>0.875763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>low_z_offset/low_z_offset99.png</td>\n",
       "      <td>0.242808</td>\n",
       "      <td>30.120961</td>\n",
       "      <td>0.852479</td>\n",
       "      <td>72.889782</td>\n",
       "      <td>0.184252</td>\n",
       "      <td>0.939719</td>\n",
       "      <td>1.969563</td>\n",
       "      <td>4.005357</td>\n",
       "      <td>68.389498</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.250805</td>\n",
       "      <td>-0.353014</td>\n",
       "      <td>-0.421704</td>\n",
       "      <td>-0.535357</td>\n",
       "      <td>-0.420899</td>\n",
       "      <td>-0.278068</td>\n",
       "      <td>0.007488</td>\n",
       "      <td>0.225327</td>\n",
       "      <td>0.322355</td>\n",
       "      <td>0.578168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>313 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               filename     lpips       psnr      ssim  \\\n",
       "0      high_z_offset/high_z_offset0.png  0.364281  25.366058  0.803856   \n",
       "1      high_z_offset/high_z_offset1.png  0.251316  27.754356  0.847467   \n",
       "2     high_z_offset/high_z_offset10.png  0.349757  24.708093  0.725036   \n",
       "3    high_z_offset/high_z_offset100.png  0.317964  26.041058  0.748882   \n",
       "4    high_z_offset/high_z_offset101.png  0.415194  26.146266  0.759185   \n",
       "..                                  ...       ...        ...       ...   \n",
       "308     low_z_offset/low_z_offset95.png  0.398480  27.146761  0.767963   \n",
       "309     low_z_offset/low_z_offset96.png  0.230179  31.569480  0.907952   \n",
       "310     low_z_offset/low_z_offset97.png  0.191707  35.451120  0.942800   \n",
       "311     low_z_offset/low_z_offset98.png  0.305755  29.097566  0.824472   \n",
       "312     low_z_offset/low_z_offset99.png  0.242808  30.120961  0.852479   \n",
       "\n",
       "     glcm_contrast  glcm_homogeneity  glcm_correlation  rms_noise_lr  \\\n",
       "0       137.410715          0.149594          0.934708      2.499807   \n",
       "1       135.974401          0.161373          0.941820      2.532183   \n",
       "2       225.869160          0.430218          0.887708      6.394023   \n",
       "3        82.977939          0.161440          0.944976      2.002901   \n",
       "4        89.467270          0.160775          0.956186      2.164097   \n",
       "..             ...               ...               ...           ...   \n",
       "308     130.535761          0.470106          0.883706      4.739694   \n",
       "309      49.799471          0.249285          0.957178      1.312079   \n",
       "310      50.536258          0.507053          0.962478      2.999149   \n",
       "311      85.593845          0.479782          0.905295      3.869637   \n",
       "312      72.889782          0.184252          0.939719      1.969563   \n",
       "\n",
       "     rms_noise_hr  lap_var_lr  ...  ch1_skew_lr  ch1_skew_hr  ch2_skew_lr  \\\n",
       "0        7.405629  108.620061  ...     0.036239    -0.030008    -0.056324   \n",
       "1        5.740295  107.357917  ...    -0.242923    -0.255645    -0.419483   \n",
       "2        6.363694  751.291854  ...    -0.324179    -0.352662    -0.423683   \n",
       "3        6.041940   69.841931  ...    -0.079562    -0.209162    -0.347382   \n",
       "4        6.394686   82.893296  ...    -0.129830    -0.109321    -0.380877   \n",
       "..            ...         ...  ...          ...          ...          ...   \n",
       "308      4.937069  378.520439  ...    -0.708274    -0.753500    -0.787584   \n",
       "309      4.030325   29.217389  ...    -0.760076    -0.784344    -0.937650   \n",
       "310      1.779312  157.944040  ...    -0.401852    -0.401222    -0.527594   \n",
       "311      3.417618  258.198508  ...    -0.663705    -0.816551    -0.740988   \n",
       "312      4.005357   68.389498  ...    -0.250805    -0.353014    -0.421704   \n",
       "\n",
       "     ch2_skew_hr  ch0_kurt_lr  ch0_kurt_hr  ch1_kurt_lr  ch1_kurt_hr  \\\n",
       "0      -0.109049    -0.064233    -0.078027    -0.101885    -0.142501   \n",
       "1      -0.414943     0.167955     0.057892     0.143544    -0.011911   \n",
       "2      -0.460285     0.299866     0.121729     0.419595     0.147142   \n",
       "3      -0.432156     0.391550     0.152999     0.459532     0.143770   \n",
       "4      -0.322283     0.179148     0.221096     0.304085     0.258230   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "308    -0.841872     0.191959     0.171960     0.684935     0.758831   \n",
       "309    -0.946355    -0.350854    -0.279414     0.358212     0.445815   \n",
       "310    -0.529595    -0.490090    -0.487183    -0.579616    -0.561587   \n",
       "311    -0.953585     0.030360     0.056749     0.276913     0.613602   \n",
       "312    -0.535357    -0.420899    -0.278068     0.007488     0.225327   \n",
       "\n",
       "     ch2_kurt_lr  ch2_kurt_hr  \n",
       "0      -0.115562    -0.141359  \n",
       "1       0.158280    -0.028525  \n",
       "2       0.493415     0.164363  \n",
       "3       0.626193     0.207427  \n",
       "4       0.500662     0.378809  \n",
       "..           ...          ...  \n",
       "308     0.903825     1.084455  \n",
       "309     0.855934     0.951866  \n",
       "310    -0.440199    -0.405477  \n",
       "311     0.294812     0.875763  \n",
       "312     0.322355     0.578168  \n",
       "\n",
       "[313 rows x 34 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_dir = \"images/LR\"\n",
    "hr_dir = \"images/HR\"\n",
    "output_dir = \"eda_results\"\n",
    "interp_map_path = \"images/interpolation_map.pkl\"\n",
    "\n",
    "run_eda_pipeline(lr_dir, hr_dir, output_dir, glcm_multi_angle=True, glcm_levels=256, interp_map_path=interp_map_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
