{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92856d4d",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ac93309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import cv2\n",
    "import lpips\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import torch\n",
    "from skimage import filters\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from skimage.metrics import (\n",
    "    peak_signal_noise_ratio as psnr,\n",
    "    structural_similarity as ssim,\n",
    " )\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe885f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagePairLoader:\n",
    "    \"\"\"Separated I/O utilities for iterating and aligning LR/HR pairs.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def iter_pairs(lr_dir, hr_dir):\n",
    "        \"\"\"Yield (lr_filename, hr_filename) pairs in lexicographic order.\"\"\"\n",
    "        \n",
    "        lr_images = sorted([\n",
    "            f for f in os.listdir(lr_dir)\n",
    "            if f.lower().endswith((\"png\", \"jpg\", \"jpeg\"))\n",
    "        ])\n",
    "        \n",
    "        hr_images = sorted([\n",
    "            f for f in os.listdir(hr_dir)\n",
    "            if f.lower().endswith((\"png\", \"jpg\", \"jpeg\"))\n",
    "        ])\n",
    "\n",
    "        assert len(lr_images) == len(hr_images), \\\n",
    "            \"Mismatch in LR/HR image counts\"\n",
    "\n",
    "        for lf, hf in zip(lr_images, hr_images):\n",
    "            yield lf, hf\n",
    "\n",
    "    @staticmethod\n",
    "    def load_and_align(lr_path, hr_path, interp_map=None):\n",
    "        \"\"\"Load two images and resize LR to HR size if required.\n",
    "\n",
    "        If interp_map provided, it should map LR filename to the\n",
    "        interpolation method string used originally (e.g., 'INTER_CUBIC').\n",
    "        That method is used for upscaling to match EDA fairness.\n",
    "        \"\"\"\n",
    "        \n",
    "        lr = cv2.imread(lr_path)\n",
    "        hr = cv2.imread(hr_path)\n",
    "\n",
    "        if lr is None or hr is None:\n",
    "            raise ValueError(f\"Failed reading {lr_path} or {hr_path}\")\n",
    "\n",
    "        if lr.shape[:2] != hr.shape[:2]:\n",
    "            interp_code = cv2.INTER_LINEAR\n",
    "            if interp_map is not None:\n",
    "                fname = os.path.basename(lr_path)\n",
    "                name = interp_map.get(fname)\n",
    "                name_to_code = {\n",
    "                    'INTER_LINEAR': cv2.INTER_LINEAR,\n",
    "                    'INTER_CUBIC': cv2.INTER_CUBIC,\n",
    "                    'INTER_AREA': cv2.INTER_AREA,\n",
    "                    'INTER_LANCZOS4': cv2.INTER_LANCZOS4,\n",
    "                }\n",
    "                if name in name_to_code:\n",
    "                    interp_code = name_to_code[name]\n",
    "            lr = cv2.resize(\n",
    "                lr,\n",
    "                (hr.shape[1], hr.shape[0]),\n",
    "                interpolation=interp_code\n",
    "            )\n",
    "\n",
    "        return lr, hr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6c8345",
   "metadata": {},
   "source": [
    "## Methods for exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87582ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDatasetAnalyzer:\n",
    "    \"\"\"Utility collection to analyze LR/HR image pairs.\n",
    "\n",
    "    All methods are static so they can be called without\n",
    "    instantiation.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def loss_fn():\n",
    "        \"\"\"Return (singleton) the loaded LPIPS model.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        lpips.LPIPS\n",
    "            Initialized LPIPS model instance.\n",
    "        \"\"\"\n",
    "        \n",
    "        if not hasattr(ImageDatasetAnalyzer, '_loss_fn'):\n",
    "            ImageDatasetAnalyzer._loss_fn = lpips.LPIPS(net=\"alex\")\n",
    "\n",
    "        return ImageDatasetAnalyzer._loss_fn\n",
    "\n",
    "    @staticmethod\n",
    "    def lpips_score(lr_img, hr_img):\n",
    "        \"\"\"Compute LPIPS between two aligned BGR images.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        lr_img : np.ndarray\n",
    "            Aligned LR image (BGR).\n",
    "        hr_img : np.ndarray\n",
    "            HR image (BGR).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            LPIPS value.\n",
    "        \"\"\"\n",
    "        \n",
    "        def to_tensor(img):\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) / 255.0\n",
    "            img = 2 * img - 1\n",
    "            img = np.transpose(img, (2, 0, 1))\n",
    "            return torch.from_numpy(img).unsqueeze(0).float()\n",
    "        \n",
    "        return ImageDatasetAnalyzer.loss_fn()(\n",
    "            to_tensor(lr_img),\n",
    "            to_tensor(hr_img)\n",
    "        ).item()\n",
    "\n",
    "    @staticmethod\n",
    "    def rms_noise(gray):\n",
    "        \"\"\"Estimate RMS noise using difference from a Gaussian blur.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        img : np.ndarray\n",
    "            Input BGR image.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            RMS noise estimate.\n",
    "        \"\"\"\n",
    "        \n",
    "        blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "        diff = gray.astype(np.float32) - blurred.astype(np.float32)\n",
    "\n",
    "        return float(np.sqrt(np.mean(diff ** 2)))\n",
    "\n",
    "    @staticmethod\n",
    "    def laplacian_variance(gray):\n",
    "        \"\"\"Variance of Laplacian (sharpness proxy).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        img : np.ndarray\n",
    "            BGR image.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            Variance value.\n",
    "        \"\"\"\n",
    "        \n",
    "        return float(cv2.Laplacian(gray, cv2.CV_64F).var())\n",
    "\n",
    "    @staticmethod\n",
    "    def psnr_metric(lr_img, hr_img):\n",
    "        \"\"\"Compute PSNR between HR and LR images.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        lr_img : np.ndarray\n",
    "            Aligned LR image.\n",
    "        hr_img : np.ndarray\n",
    "            HR image.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            PSNR value.\n",
    "        \"\"\"\n",
    "        \n",
    "        return psnr(hr_img, lr_img, data_range=255)\n",
    "\n",
    "    @staticmethod\n",
    "    def ssim_metric(lr_img, hr_img):\n",
    "        \"\"\"Compute SSIM between HR and LR images.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        lr_img : np.ndarray\n",
    "            Aligned LR image.\n",
    "        hr_img : np.ndarray\n",
    "            HR image.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            SSIM value.\n",
    "        \"\"\"\n",
    "        \n",
    "        return ssim(hr_img, lr_img, channel_axis=2, data_range=255)\n",
    "\n",
    "    @staticmethod\n",
    "    def glcm_features(gray, angles=None, levels=64, multi_angle=False):\n",
    "        \"\"\"Extract GLCM contrast, homogeneity, correlation.\n",
    "\n",
    "        Defaults trimmed to 64 levels and one angle (0 rad) to\n",
    "        reduce memory and time. Set multi_angle=True to use\n",
    "        the 4 standard angles (0, 45, 90, 135 deg) or pass a\n",
    "        custom iterable via angles.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        gray : np.ndarray\n",
    "            Grayscale image.\n",
    "        angles : iterable | None\n",
    "            Angles in radians. If None uses [0] unless\n",
    "            multi_angle True (then 4 angles).\n",
    "        levels : int\n",
    "            Quantization levels (default 64).\n",
    "        multi_angle : bool\n",
    "            Average metrics across four angles when True.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            glcm_contrast, glcm_homogeneity, glcm_correlation.\n",
    "        \"\"\"\n",
    "        \n",
    "        if angles is None:\n",
    "            if multi_angle:\n",
    "                angles = (0, np.pi / 4, np.pi / 2, 3 * np.pi / 4)\n",
    "            else:\n",
    "                angles = (0,)\n",
    "        # Quantize to requested levels\n",
    "        if gray.max() == 0:\n",
    "            norm = np.zeros_like(gray, dtype=np.uint8)\n",
    "        else:\n",
    "            norm = (\n",
    "                (gray.astype(np.float32) / 255.0) * (levels - 1)\n",
    "            ).astype(np.uint8)\n",
    "        glcm = graycomatrix(\n",
    "            norm,\n",
    "            [1],\n",
    "            list(angles),\n",
    "            levels,\n",
    "            symmetric=True,\n",
    "            normed=True\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"glcm_contrast\": float(\n",
    "                graycoprops(glcm, \"contrast\").mean()\n",
    "            ),\n",
    "            \"glcm_homogeneity\": float(\n",
    "                graycoprops(glcm, \"homogeneity\").mean()\n",
    "            ),\n",
    "            \"glcm_correlation\": float(\n",
    "                graycoprops(glcm, \"correlation\").mean()\n",
    "            )\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def feature_distribution(img, hsv):\n",
    "        \"\"\"Basic stats per BGR channel plus HSV saturation/brightness.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        img : np.ndarray\n",
    "            BGR image.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            Channel stats plus saturation_mean, brightness_mean.\n",
    "        \"\"\"\n",
    "        \n",
    "        results = {}\n",
    "\n",
    "        for idx, channel in enumerate(cv2.split(img)):\n",
    "            flat = channel.ravel()\n",
    "            results[f\"ch{idx}_mean\"] = float(np.mean(flat))\n",
    "            results[f\"ch{idx}_std\"] = float(np.std(flat))\n",
    "            results[f\"ch{idx}_skew\"] = float(scipy.stats.skew(flat))\n",
    "            results[f\"ch{idx}_kurt\"] = float(scipy.stats.kurtosis(flat))\n",
    "        \n",
    "        results[\"saturation_mean\"] = float(np.mean(hsv[:, :, 1]))\n",
    "        results[\"brightness_mean\"] = float(np.mean(hsv[:, :, 2]))\n",
    "\n",
    "        return results\n",
    "\n",
    "    @staticmethod\n",
    "    def detect_artifacts(img, gray):\n",
    "        \"\"\"Detect artifacts: blocking, color noise, ringing.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        img : np.ndarray\n",
    "            BGR image.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            blocking_score, color_noise, ringing_artifact.\n",
    "        \"\"\"\n",
    "        \n",
    "        dct = cv2.dct(np.float32(gray))\n",
    "        horizontal_blocking = np.mean(np.abs(dct[7::8, :]))\n",
    "        vertical_blocking = np.mean(np.abs(dct[:, 7::8]))\n",
    "        blocking_score = float(\n",
    "            (horizontal_blocking + vertical_blocking) / 2\n",
    "        )\n",
    "        blur = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "        color_noise = float(\n",
    "            np.mean(np.abs(img.astype(float) - blur.astype(float)))\n",
    "        )\n",
    "        edges = cv2.Canny(gray, 100, 200)\n",
    "        kernel = np.ones((5, 5), np.uint8)\n",
    "        dilated = cv2.dilate(edges, kernel)\n",
    "        edge_region = dilated & ~edges\n",
    "        \n",
    "        if np.any(edge_region):\n",
    "            ringing = float(np.std(gray[edge_region]))\n",
    "        else:\n",
    "            ringing = 0.0\n",
    "\n",
    "        return {\n",
    "            \"blocking_score\": blocking_score,\n",
    "            \"color_noise\": color_noise,\n",
    "            \"ringing_artifact\": ringing\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb5cc926",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagePairMetrics:\n",
    "    \"\"\"Container of metrics computed for an LR/HR pair.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        filename,\n",
    "        lpips,\n",
    "        psnr,\n",
    "        ssim,\n",
    "        glcm_contrast,\n",
    "        glcm_homogeneity,\n",
    "        glcm_correlation,\n",
    "        rms_noise_lr,\n",
    "        rms_noise_hr,\n",
    "        lap_var_lr,\n",
    "        lap_var_hr,\n",
    "        blocking_lr,\n",
    "        blocking_hr,\n",
    "        color_noise_lr,\n",
    "        color_noise_hr,\n",
    "        ringing_lr,\n",
    "        ringing_hr,\n",
    "        saturation_mean_lr,\n",
    "        saturation_mean_hr,\n",
    "        brightness_mean_lr,\n",
    "        brightness_mean_hr,\n",
    "        edge_diff,\n",
    "        ch0_skew_lr=None, \n",
    "        ch0_skew_hr=None,\n",
    "        ch1_skew_lr=None, \n",
    "        ch1_skew_hr=None,\n",
    "        ch2_skew_lr=None, \n",
    "        ch2_skew_hr=None,\n",
    "        ch0_kurt_lr=None, \n",
    "        ch0_kurt_hr=None,\n",
    "        ch1_kurt_lr=None, \n",
    "        ch1_kurt_hr=None,\n",
    "        ch2_kurt_lr=None, \n",
    "        ch2_kurt_hr=None,\n",
    "    ):\n",
    "        self.filename = filename\n",
    "        self.lpips = lpips\n",
    "        self.psnr = psnr\n",
    "        self.ssim = ssim\n",
    "        self.glcm_contrast = glcm_contrast\n",
    "        self.glcm_homogeneity = glcm_homogeneity\n",
    "        self.glcm_correlation = glcm_correlation\n",
    "        self.rms_noise_lr = rms_noise_lr\n",
    "        self.rms_noise_hr = rms_noise_hr\n",
    "        self.lap_var_lr = lap_var_lr\n",
    "        self.lap_var_hr = lap_var_hr\n",
    "        self.blocking_lr = blocking_lr\n",
    "        self.blocking_hr = blocking_hr\n",
    "        self.color_noise_lr = color_noise_lr\n",
    "        self.color_noise_hr = color_noise_hr\n",
    "        self.ringing_lr = ringing_lr\n",
    "        self.ringing_hr = ringing_hr\n",
    "        self.saturation_mean_lr = saturation_mean_lr\n",
    "        self.saturation_mean_hr = saturation_mean_hr\n",
    "        self.brightness_mean_lr = brightness_mean_lr\n",
    "        self.brightness_mean_hr = brightness_mean_hr\n",
    "        self.edge_diff = edge_diff\n",
    "        self.ch0_skew_lr = ch0_skew_lr\n",
    "        self.ch0_skew_hr = ch0_skew_hr\n",
    "        self.ch1_skew_lr = ch1_skew_lr\n",
    "        self.ch1_skew_hr = ch1_skew_hr\n",
    "        self.ch2_skew_lr = ch2_skew_lr\n",
    "        self.ch2_skew_hr = ch2_skew_hr\n",
    "        self.ch0_kurt_lr = ch0_kurt_lr\n",
    "        self.ch0_kurt_hr = ch0_kurt_hr\n",
    "        self.ch1_kurt_lr = ch1_kurt_lr\n",
    "        self.ch1_kurt_hr = ch1_kurt_hr\n",
    "        self.ch2_kurt_lr = ch2_kurt_lr\n",
    "        self.ch2_kurt_hr = ch2_kurt_hr\n",
    "\n",
    "    def as_dict(self):\n",
    "        \"\"\"Return metrics as a dict for DataFrame conversion.\"\"\"\n",
    "        return self.__dict__.copy()\n",
    "\n",
    "class MetricsAggregator:\n",
    "    \"\"\"Orchestrates metric extraction for all image pairs.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def collect(\n",
    "        lr_dir,\n",
    "        hr_dir,\n",
    "        glcm_multi_angle=False,\n",
    "        glcm_levels=64,\n",
    "        interp_map=None,\n",
    "    ):\n",
    "        \"\"\"Compute metrics for each pair and accumulate global visual data.\n",
    "        Always returns a tuple (rows, global_data) where global_data contains\n",
    "        the accumulators required to build the global advanced visualization panel.\n",
    "        Now uses tqdm for progress display. Added complementary skew/kurt capture.\n",
    "        \"\"\"\n",
    "        \n",
    "        rows = []\n",
    "        sat_bins = np.linspace(0, 256, 51)  # 50 bins 0-255\n",
    "        global_data = {\n",
    "            'count': 0,\n",
    "            'lr_fft_sum': None,\n",
    "            'hr_fft_sum': None,\n",
    "            'grad_hr_sum': None,\n",
    "            'glcm_sum': None,  # shape (256, 256, 1, 1)\n",
    "            'sat_lr_counts': np.zeros(len(sat_bins) - 1, dtype=np.float64),\n",
    "            'sat_hr_counts': np.zeros(len(sat_bins) - 1, dtype=np.float64),\n",
    "            'sat_bins': sat_bins,\n",
    "            'noise_means_lr': [],\n",
    "        }\n",
    "        \n",
    "        pairs = list(ImagePairLoader.iter_pairs(lr_dir, hr_dir))\n",
    "        for lf, hf in tqdm(pairs, desc=\"Computing metrics\", unit=\"img\"):\n",
    "            lr_img, hr_img = ImagePairLoader.load_and_align(\n",
    "                os.path.join(lr_dir, lf),\n",
    "                os.path.join(hr_dir, hf),\n",
    "                interp_map=interp_map\n",
    "            )\n",
    "            \n",
    "            gray_lr = cv2.cvtColor(lr_img, cv2.COLOR_BGR2GRAY)\n",
    "            gray_hr = cv2.cvtColor(hr_img, cv2.COLOR_BGR2GRAY)\n",
    "            hsv_lr = cv2.cvtColor(lr_img, cv2.COLOR_BGR2HSV)\n",
    "            hsv_hr = cv2.cvtColor(hr_img, cv2.COLOR_BGR2HSV)\n",
    "            lpips_val = ImageDatasetAnalyzer.lpips_score(lr_img, hr_img)\n",
    "            psnr_val = ImageDatasetAnalyzer.psnr_metric(lr_img, hr_img)\n",
    "            ssim_val = ImageDatasetAnalyzer.ssim_metric(lr_img, hr_img)\n",
    "            glcm = ImageDatasetAnalyzer.glcm_features(\n",
    "                gray_lr,\n",
    "                levels=glcm_levels,\n",
    "                multi_angle=glcm_multi_angle\n",
    "            )\n",
    "            fd_lr = ImageDatasetAnalyzer.feature_distribution(lr_img, hsv_lr)\n",
    "            fd_hr = ImageDatasetAnalyzer.feature_distribution(hr_img, hsv_hr)\n",
    "            art_lr = ImageDatasetAnalyzer.detect_artifacts(lr_img, gray_lr)\n",
    "            art_hr = ImageDatasetAnalyzer.detect_artifacts(hr_img, gray_hr)\n",
    "            rms_lr = ImageDatasetAnalyzer.rms_noise(gray_lr)\n",
    "            rms_hr = ImageDatasetAnalyzer.rms_noise(gray_hr)\n",
    "            lap_var_lr = ImageDatasetAnalyzer.laplacian_variance(gray_lr)\n",
    "            lap_var_hr = ImageDatasetAnalyzer.laplacian_variance(gray_hr)\n",
    "            lr_edges = filters.sobel(gray_lr)\n",
    "            hr_edges = filters.sobel(gray_hr)\n",
    "            edge_diff = float(np.mean(hr_edges) - np.mean(lr_edges))\n",
    "            ch0_skew_lr = fd_lr.get('ch0_skew')\n",
    "            ch0_skew_hr = fd_hr.get('ch0_skew')\n",
    "            ch1_skew_lr = fd_lr.get('ch1_skew')\n",
    "            ch1_skew_hr = fd_hr.get('ch1_skew')\n",
    "            ch2_skew_lr = fd_lr.get('ch2_skew')\n",
    "            ch2_skew_hr = fd_hr.get('ch2_skew')\n",
    "            ch0_kurt_lr = fd_lr.get('ch0_kurt')\n",
    "            ch0_kurt_hr = fd_hr.get('ch0_kurt')\n",
    "            ch1_kurt_lr = fd_lr.get('ch1_kurt')\n",
    "            ch1_kurt_hr = fd_hr.get('ch1_kurt')\n",
    "            ch2_kurt_lr = fd_lr.get('ch2_kurt')\n",
    "            ch2_kurt_hr = fd_hr.get('ch2_kurt')\n",
    "\n",
    "            rows.append(\n",
    "                ImagePairMetrics(\n",
    "                    filename=lf,\n",
    "                    lpips=lpips_val,\n",
    "                    psnr=psnr_val,\n",
    "                    ssim=ssim_val,\n",
    "                    glcm_contrast=glcm['glcm_contrast'],\n",
    "                    glcm_homogeneity=glcm['glcm_homogeneity'],\n",
    "                    glcm_correlation=glcm['glcm_correlation'],\n",
    "                    rms_noise_lr=rms_lr,\n",
    "                    rms_noise_hr=rms_hr,\n",
    "                    lap_var_lr=lap_var_lr,\n",
    "                    lap_var_hr=lap_var_hr,\n",
    "                    blocking_lr=art_lr['blocking_score'],\n",
    "                    blocking_hr=art_hr['blocking_score'],\n",
    "                    color_noise_lr=art_lr['color_noise'],\n",
    "                    color_noise_hr=art_hr['color_noise'],\n",
    "                    ringing_lr=art_lr['ringing_artifact'],\n",
    "                    ringing_hr=art_hr['ringing_artifact'],\n",
    "                    saturation_mean_lr=fd_lr['saturation_mean'],\n",
    "                    saturation_mean_hr=fd_hr['saturation_mean'],\n",
    "                    brightness_mean_lr=fd_lr['brightness_mean'],\n",
    "                    brightness_mean_hr=fd_hr['brightness_mean'],\n",
    "                    edge_diff=edge_diff,\n",
    "                    ch0_skew_lr=ch0_skew_lr, \n",
    "                    ch0_skew_hr=ch0_skew_hr,\n",
    "                    ch1_skew_lr=ch1_skew_lr, \n",
    "                    ch1_skew_hr=ch1_skew_hr,\n",
    "                    ch2_skew_lr=ch2_skew_lr, \n",
    "                    ch2_skew_hr=ch2_skew_hr,\n",
    "                    ch0_kurt_lr=ch0_kurt_lr, \n",
    "                    ch0_kurt_hr=ch0_kurt_hr,\n",
    "                    ch1_kurt_lr=ch1_kurt_lr, \n",
    "                    ch1_kurt_hr=ch1_kurt_hr,\n",
    "                    ch2_kurt_lr=ch2_kurt_lr, \n",
    "                    ch2_kurt_hr=ch2_kurt_hr,\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            if global_data['lr_fft_sum'] is None:\n",
    "                lr_fft_mag = np.abs(np.fft.fftshift(np.fft.fft2(gray_lr)))\n",
    "                hr_fft_mag = np.abs(np.fft.fftshift(np.fft.fft2(gray_hr)))\n",
    "                global_data['lr_fft_sum'] = lr_fft_mag.astype(np.float64)\n",
    "                global_data['hr_fft_sum'] = hr_fft_mag.astype(np.float64)\n",
    "                \n",
    "                sobelx = cv2.Sobel(gray_hr, cv2.CV_64F, 1, 0, ksize=5)\n",
    "                sobely = cv2.Sobel(gray_hr, cv2.CV_64F, 0, 1, ksize=5)\n",
    "                grad_mag = np.sqrt(sobelx ** 2 + sobely ** 2)\n",
    "                global_data['grad_hr_sum'] = grad_mag\n",
    "                \n",
    "                lr_glcm_full = graycomatrix(\n",
    "                    gray_lr,\n",
    "                    [1],\n",
    "                    [0],\n",
    "                    256,\n",
    "                    symmetric=True,\n",
    "                    normed=True\n",
    "                )\n",
    "                \n",
    "                global_data['glcm_sum'] = lr_glcm_full.astype(np.float64)\n",
    "            else:\n",
    "                global_data['lr_fft_sum'] += np.abs(\n",
    "                    np.fft.fftshift(np.fft.fft2(gray_lr))\n",
    "                )\n",
    "                \n",
    "                global_data['hr_fft_sum'] += np.abs(\n",
    "                    np.fft.fftshift(np.fft.fft2(gray_hr))\n",
    "                )\n",
    "                \n",
    "                sobelx = cv2.Sobel(gray_hr, cv2.CV_64F, 1, 0, ksize=5)\n",
    "                sobely = cv2.Sobel(gray_hr, cv2.CV_64F, 0, 1, ksize=5)\n",
    "                grad_mag = np.sqrt(sobelx ** 2 + sobely ** 2)\n",
    "                global_data['grad_hr_sum'] += grad_mag\n",
    "                \n",
    "                lr_glcm_full = graycomatrix(\n",
    "                    gray_lr,\n",
    "                    [1],\n",
    "                    [0],\n",
    "                    256,\n",
    "                    symmetric=True,\n",
    "                    normed=True\n",
    "                )\n",
    "                \n",
    "                global_data['glcm_sum'] += lr_glcm_full\n",
    "            \n",
    "            sat_lr = hsv_lr[:, :, 1]\n",
    "            sat_hr = hsv_hr[:, :, 1]\n",
    "            lr_counts, _ = np.histogram(sat_lr, bins=global_data['sat_bins'])\n",
    "            hr_counts, _ = np.histogram(sat_hr, bins=global_data['sat_bins'])\n",
    "            global_data['sat_lr_counts'] += lr_counts\n",
    "            global_data['sat_hr_counts'] += hr_counts\n",
    "            global_data['noise_means_lr'].append(art_lr['color_noise'])\n",
    "            global_data['count'] += 1\n",
    "            \n",
    "        return rows, global_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1763473",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StatsReporter:\n",
    "    \"\"\"Utilities to convert and summarize metrics to a DataFrame.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def dataframe(rows):\n",
    "        \"\"\"Convert list of ImagePairMetrics into a DataFrame.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        rows : list[ImagePairMetrics]\n",
    "            List of metric objects.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pandas.DataFrame\n",
    "            One row per image pair.\n",
    "        \"\"\"\n",
    "        \n",
    "        return pd.DataFrame([r.as_dict() for r in rows])\n",
    "\n",
    "    @staticmethod\n",
    "    def summary(df):\n",
    "        \"\"\"Return basic descriptive statistics.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pandas.DataFrame\n",
    "            Metrics data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pandas.DataFrame\n",
    "            mean, std and quartiles.\n",
    "        \"\"\"\n",
    "        \n",
    "        return df.describe().T[['mean', 'std', '25%', '50%', '75%']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d57ae2",
   "metadata": {},
   "source": [
    "## Visualization methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "769cc582",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataVisualization:\n",
    "    \"\"\"Visualization utilities for exploratory analysis.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def save_visual_example(lr_img, hr_img, output_path, lpips_val):\n",
    "        \"\"\"Save comparison figure and a difference heatmap.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        lr_img : np.ndarray\n",
    "            LR image.\n",
    "        hr_img : np.ndarray\n",
    "            HR image.\n",
    "        output_path : str\n",
    "            Output PNG path.\n",
    "        lpips_val : float\n",
    "            LPIPS value for title.\n",
    "        \"\"\"\n",
    "        \n",
    "        lr_resized = cv2.resize(\n",
    "            lr_img,\n",
    "            (hr_img.shape[1], hr_img.shape[0]),\n",
    "            interpolation=cv2.INTER_CUBIC\n",
    "        )\n",
    "\n",
    "        diff_map = cv2.absdiff(lr_resized, hr_img)\n",
    "        diff_map_color = cv2.applyColorMap(\n",
    "            cv2.convertScaleAbs(cv2.cvtColor(diff_map, cv2.COLOR_BGR2GRAY)),\n",
    "            cv2.COLORMAP_JET\n",
    "        )\n",
    "\n",
    "        _, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "        axes[0].imshow(cv2.cvtColor(lr_resized, cv2.COLOR_BGR2RGB))\n",
    "        axes[0].set_title(\"Rescaled LR\")\n",
    "        axes[0].axis(\"off\")\n",
    "\n",
    "        axes[1].imshow(cv2.cvtColor(hr_img, cv2.COLOR_BGR2RGB))\n",
    "        axes[1].set_title(\"HR\")\n",
    "        axes[1].axis(\"off\")\n",
    "\n",
    "        axes[2].imshow(diff_map_color)\n",
    "        axes[2].set_title(f\"Difference map\\nLPIPS: {lpips_val:.4f}\")\n",
    "        axes[2].axis(\"off\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()\n",
    "\n",
    "    @staticmethod\n",
    "    def create_advanced_visualizations(lr_img, hr_img, output_path):\n",
    "        \"\"\"Create per-pair advanced panel: spectra, gradients, GLCM, noise\n",
    "        map, saturation distribution.\"\"\"\n",
    "        plt.figure(figsize=(20, 10))\n",
    "\n",
    "        # 1. LR Spectrum\n",
    "        plt.subplot(231)\n",
    "        lr_fft = np.fft.fft2(cv2.cvtColor(lr_img, cv2.COLOR_BGR2GRAY))\n",
    "        plt.imshow(np.log(np.abs(np.fft.fftshift(lr_fft)) + 1e-8),\n",
    "                   cmap=\"viridis\")\n",
    "        plt.title(\"LR Frequency Spectrum\")\n",
    "        plt.colorbar()\n",
    "\n",
    "        # 2. HR Spectrum\n",
    "        plt.subplot(232)\n",
    "        hr_fft = np.fft.fft2(cv2.cvtColor(hr_img, cv2.COLOR_BGR2GRAY))\n",
    "        plt.imshow(np.log(np.abs(np.fft.fftshift(hr_fft)) + 1e-8),\n",
    "                   cmap=\"viridis\")\n",
    "        plt.title(\"HR Frequency Spectrum\")\n",
    "        plt.colorbar()\n",
    "\n",
    "        # 3. HR Gradient Magnitude\n",
    "        plt.subplot(233)\n",
    "        gray_hr = cv2.cvtColor(hr_img, cv2.COLOR_BGR2GRAY)\n",
    "        sobelx = cv2.Sobel(gray_hr, cv2.CV_64F, 1, 0, ksize=5)\n",
    "        sobely = cv2.Sobel(gray_hr, cv2.CV_64F, 0, 1, ksize=5)\n",
    "        gradient_magnitude = np.sqrt(sobelx ** 2 + sobely ** 2)\n",
    "        plt.imshow(gradient_magnitude, cmap=\"magma\")\n",
    "        plt.title(\"Gradient Magnitude\")\n",
    "        plt.colorbar()\n",
    "        \n",
    "        # 4. LR GLCM\n",
    "        plt.subplot(234)\n",
    "        lr_gray = cv2.cvtColor(lr_img, cv2.COLOR_BGR2GRAY)\n",
    "        lr_glcm = graycomatrix(\n",
    "            lr_gray, [1], [0], 256, symmetric=True, normed=True\n",
    "        )\n",
    "        lr_contrast = graycoprops(lr_glcm, \"contrast\")[0, 0]\n",
    "        plt.imshow(lr_glcm[:, :, 0, 0], cmap=\"plasma\")\n",
    "        plt.title(f\"LR GLCM (Contrast: {lr_contrast:.2f})\")\n",
    "        plt.colorbar()\n",
    "\n",
    "        # 5. LR Color Noise Map\n",
    "        plt.subplot(235)\n",
    "        blur = cv2.GaussianBlur(lr_img, (5, 5), 0)\n",
    "        noise_map = np.mean(\n",
    "            np.abs(lr_img.astype(float) - blur.astype(float)), axis=2\n",
    "        )\n",
    "        color_noise_mean = float(\n",
    "            np.mean(np.abs(lr_img.astype(float) - blur.astype(float)))\n",
    "        )\n",
    "        plt.imshow(noise_map, cmap=\"hot\")\n",
    "        plt.title(f\"Noise Map (Mean: {color_noise_mean:.2f})\")\n",
    "        plt.colorbar()\n",
    "\n",
    "        # 6. Saturation Distribution LR vs HR\n",
    "        plt.subplot(236)\n",
    "        lr_hsv = cv2.cvtColor(lr_img, cv2.COLOR_BGR2HSV)[:, :, 1]\n",
    "        hr_hsv = cv2.cvtColor(hr_img, cv2.COLOR_BGR2HSV)[:, :, 1]\n",
    "        plt.hist(lr_hsv.ravel(), bins=50, alpha=0.5, density=True,\n",
    "                 label=\"LR\", color=\"steelblue\")\n",
    "        plt.hist(hr_hsv.ravel(), bins=50, alpha=0.5, density=True,\n",
    "                 label=\"HR\", color=\"orange\")\n",
    "        plt.title(\"Saturation Distribution\")\n",
    "        plt.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        plt.savefig(output_path, dpi=300, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "    @staticmethod\n",
    "    def create_global_advanced_visualizations(global_data, output_path):\n",
    "        \"\"\"Create a global panel with averaged spectra, gradient, averaged\n",
    "        GLCM, noise mean distribution, saturation densities.\"\"\"\n",
    "        \n",
    "        if global_data is None or global_data.get('count', 0) == 0:\n",
    "            print(\"No global data available to create advanced visualization.\")\n",
    "            return\n",
    "\n",
    "        n = global_data['count']\n",
    "        eps = 1e-8\n",
    "        # Average spectra (compute log after averaging magnitudes)\n",
    "        lr_fft_avg = global_data['lr_fft_sum'] / n\n",
    "        hr_fft_avg = global_data['hr_fft_sum'] / n\n",
    "        # Average gradient magnitude\n",
    "        grad_hr_avg = global_data['grad_hr_sum'] / n\n",
    "        # Average (unnormalized-sum) GLCM then renormalize\n",
    "        glcm_sum = global_data['glcm_sum']\n",
    "        glcm_avg = glcm_sum / glcm_sum.sum()\n",
    "        glcm_contrast = graycoprops(glcm_avg, \"contrast\")[0, 0]\n",
    "\n",
    "        # Saturation histograms (normalize to density)\n",
    "        sat_bins = global_data['sat_bins']\n",
    "        bin_width = sat_bins[1] - sat_bins[0]\n",
    "        sat_lr_density = (\n",
    "            global_data['sat_lr_counts'] /\n",
    "            (global_data['sat_lr_counts'].sum() * bin_width + eps)\n",
    "        )\n",
    "        sat_hr_density = (\n",
    "            global_data['sat_hr_counts'] /\n",
    "            (global_data['sat_hr_counts'].sum() * bin_width + eps)\n",
    "        )\n",
    "        sat_centers = 0.5 * (sat_bins[:-1] + sat_bins[1:])\n",
    "\n",
    "        noise_means = np.array(global_data['noise_means_lr'], dtype=np.float64)\n",
    "\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        \n",
    "        # 1 LR Spectrum\n",
    "        plt.subplot(231)\n",
    "        plt.imshow(np.log(lr_fft_avg + eps), cmap=\"viridis\")\n",
    "        plt.title(\"LR Avg Frequency Spectrum\")\n",
    "        plt.colorbar()\n",
    "        \n",
    "        # 2 HR Spectrum\n",
    "        plt.subplot(232)\n",
    "        plt.imshow(np.log(hr_fft_avg + eps), cmap=\"viridis\")\n",
    "        plt.title(\"HR Avg Frequency Spectrum\")\n",
    "        plt.colorbar()\n",
    "        \n",
    "        # 3 Gradient Magnitude\n",
    "        plt.subplot(233)\n",
    "        plt.imshow(grad_hr_avg, cmap=\"magma\")\n",
    "        plt.title(\"HR Avg Gradient Magnitude\")\n",
    "        plt.colorbar()\n",
    "        \n",
    "        # 4 GLCM\n",
    "        plt.subplot(234)\n",
    "        plt.imshow(glcm_avg[:, :, 0, 0], cmap=\"plasma\")\n",
    "        plt.title(f\"LR Avg GLCM (Contrast: {glcm_contrast:.2f})\")\n",
    "        plt.colorbar()\n",
    "        \n",
    "        # 5 Noise mean distribution\n",
    "        plt.subplot(235)\n",
    "        plt.hist(\n",
    "            noise_means, bins=30, color='tomato', edgecolor='black', alpha=0.8\n",
    "        )\n",
    "        plt.title(\n",
    "            f\"LR Color Noise Mean Dist\\nMean={noise_means.mean():.2f} \"\n",
    "            f\"Std={noise_means.std():.2f}\"\n",
    "        )\n",
    "        plt.xlabel(\"Per-image color noise mean\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        \n",
    "        # 6 Saturation density\n",
    "        plt.subplot(236)\n",
    "        plt.plot(sat_centers, sat_lr_density, label='LR', color='steelblue')\n",
    "        plt.plot(sat_centers, sat_hr_density, label='HR', color='orange')\n",
    "        plt.title(\"Global Saturation Density\")\n",
    "        plt.xlabel(\"Saturation value\")\n",
    "        plt.ylabel(\"Density\")\n",
    "        \n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        plt.savefig(output_path, dpi=300, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "    @staticmethod\n",
    "    def basic_distributions(df, output_dir):\n",
    "        \"\"\"\n",
    "            Save distributions.png: \n",
    "                original basic histograms + integrated GLCM histograms.\n",
    "            Metrics: \n",
    "                lpips, psnr, ssim, lap_var_hr, rms_noise_hr, blocking_hr, \n",
    "                glcm_contrast, glcm_homogeneity, glcm_correlation.\n",
    "        \"\"\"\n",
    "        \n",
    "        metrics = [\n",
    "            'lpips', 'psnr', 'ssim', 'lap_var_hr', 'rms_noise_hr', \n",
    "            'blocking_hr', 'glcm_contrast', 'glcm_homogeneity', \n",
    "            'glcm_correlation'\n",
    "        ]\n",
    "        colors = [\n",
    "            \"#1f77b4\",\"#ff7f0e\",\"#2ca02c\",\"#d62728\",\"#9467bd\",\n",
    "            \"#8c564b\",\"#6baed6\",\"#9edae5\",\"#17becf\"\n",
    "        ]\n",
    "        plt.figure(figsize=(18, 14))\n",
    "        rows = 3; cols = 3\n",
    "        for i, (m, c) in enumerate(zip(metrics, colors), 1):\n",
    "            plt.subplot(rows, cols, i)\n",
    "            plt.hist(df[m], bins=30, color=c, edgecolor='black', alpha=0.85)\n",
    "            plt.title(m)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\n",
    "            os.path.join(output_dir, 'distributions.png'),\n",
    "            dpi=300, bbox_inches='tight'\n",
    "        )\n",
    "        plt.close()\n",
    "\n",
    "    @staticmethod\n",
    "    def artifact_color_histograms(df, output_dir):\n",
    "        \"\"\"Overlay LR vs HR histograms + edge diff.\"\"\"\n",
    "        overlay_pairs = [\n",
    "            ('blocking_lr', 'blocking_hr', 'Blocking Score'),\n",
    "            ('ringing_lr', 'ringing_hr', 'Ringing Artifact'),\n",
    "            ('saturation_mean_lr', 'saturation_mean_hr', 'Saturation Mean'),\n",
    "            ('brightness_mean_lr', 'brightness_mean_hr', 'Brightness Mean'),\n",
    "            ('color_noise_lr', 'color_noise_hr', 'Color Noise'),\n",
    "        ]\n",
    "        rows = 3; cols = 3\n",
    "        plt.figure(figsize=(16, 12))\n",
    "        for i, (lr_col, hr_col, title) in enumerate(overlay_pairs, 1):\n",
    "            plt.subplot(rows, cols, i)\n",
    "            plt.hist(\n",
    "                df[lr_col], bins=30, alpha=0.55, label='LR', color='#1f77b4',\n",
    "                edgecolor='black', linewidth=0.4\n",
    "            )\n",
    "            plt.hist(\n",
    "                df[hr_col], bins=30, alpha=0.55, label='HR', color='#ff7f0e',\n",
    "                edgecolor='black', linewidth=0.4\n",
    "            )\n",
    "            plt.title(title)\n",
    "            plt.legend(fontsize=8)\n",
    "        # edge_diff\n",
    "        plt.subplot(rows, cols, 7)\n",
    "        plt.hist(df['edge_diff'], bins=30, color='#2ca02c', alpha=0.8, edgecolor='black')\n",
    "        plt.title('Edge Mean Diff (HR-LR)')\n",
    "        plt.subplot(rows, cols, 8)\n",
    "        sns.kdeplot(df['edge_diff'], fill=True, color='#2ca02c')\n",
    "        plt.title('Edge Diff Density')\n",
    "        plt.subplot(rows, cols, 9)\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, 'artifact_color_histograms.png'), dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    @staticmethod\n",
    "    def artifact_boxplots(df, output_dir):\n",
    "        \"\"\"Save artifact_boxplots.png with LR vs HR boxplots.\"\"\"\n",
    "        \n",
    "        plt.figure(figsize=(11, 6))\n",
    "        groups = [\n",
    "            ('blocking_lr', 'blocking_hr', 'Blocking'),\n",
    "            ('ringing_lr', 'ringing_hr', 'Ringing'),\n",
    "            ('saturation_mean_lr', 'saturation_mean_hr', 'Saturation'),\n",
    "            ('brightness_mean_lr', 'brightness_mean_hr', 'Brightness'),\n",
    "            ('color_noise_lr', 'color_noise_hr', 'ColorNoise'),\n",
    "        ]\n",
    "        data = []\n",
    "        labels = []\n",
    "        for lr_col, hr_col, name in groups:\n",
    "            data.append(df[lr_col]); labels.append(f'{name} LR')\n",
    "            data.append(df[hr_col]); labels.append(f'{name} HR')\n",
    "        box = plt.boxplot(data, labels=labels, patch_artist=True)\n",
    "        palette = ['#1f77b4', '#ff7f0e'] * len(groups)\n",
    "        for patch, col in zip(box['boxes'], palette):\n",
    "            patch.set_facecolor(col); patch.set_alpha(0.55)\n",
    "        plt.xticks(rotation=25, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, 'artifact_boxplots.png'), dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    @staticmethod\n",
    "    def channel_shape_bars(df, output_dir):\n",
    "        \"\"\"Complementary: multi-bar chart of per-channel skew & kurt (LR vs HR).\"\"\"\n",
    "        \n",
    "        required = [\n",
    "            'ch0_skew_lr','ch0_skew_hr','ch1_skew_lr','ch1_skew_hr','ch2_skew_lr','ch2_skew_hr',\n",
    "            'ch0_kurt_lr','ch0_kurt_hr','ch1_kurt_lr','ch1_kurt_hr','ch2_kurt_lr','ch2_kurt_hr'\n",
    "        ]\n",
    "        if not all(r in df.columns for r in required):\n",
    "            print('Channel shape stats missing; skipping channel_shape_bars.')\n",
    "            return\n",
    "        \n",
    "        skew_means_lr = [df['ch0_skew_lr'].mean(), df['ch1_skew_lr'].mean(), df['ch2_skew_lr'].mean()]\n",
    "        skew_means_hr = [df['ch0_skew_hr'].mean(), df['ch1_skew_hr'].mean(), df['ch2_skew_hr'].mean()]\n",
    "        kurt_means_lr = [df['ch0_kurt_lr'].mean(), df['ch1_kurt_lr'].mean(), df['ch2_kurt_lr'].mean()]\n",
    "        kurt_means_hr = [df['ch0_kurt_hr'].mean(), df['ch1_kurt_hr'].mean(), df['ch2_kurt_hr'].mean()]\n",
    "        channels = ['B','G','R']; x = np.arange(len(channels)); width = 0.18\n",
    "        \n",
    "        plt.figure(figsize=(12,6))\n",
    "        plt.bar(x - 1.5*width, skew_means_lr, width, label='Skew LR', color='#3182bd')\n",
    "        plt.bar(x - 0.5*width, skew_means_hr, width, label='Skew HR', color='#6baed6')\n",
    "        plt.bar(x + 0.5*width, kurt_means_lr, width, label='Kurt LR', color='#fd8d3c')\n",
    "        plt.bar(x + 1.5*width, kurt_means_hr, width, label='Kurt HR', color='#fdd0a2')\n",
    "        plt.axhline(0, color='black', linewidth=0.8)\n",
    "        plt.xticks(x, channels)\n",
    "        plt.ylabel('Value (mean)')\n",
    "        plt.title('Per-Channel Skew & Kurtosis (LR vs HR)')\n",
    "        plt.legend(ncol=2)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, 'channel_shape_bars.png'), dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    @staticmethod\n",
    "    def correlation_matrix(df, output_dir):\n",
    "        \"\"\"Generate a correlation heatmap.\n",
    "        Saves: correlation_matrix.png. Includes extended metrics if present.\"\"\"\n",
    "        \n",
    "        metrics = [\n",
    "            'lpips', 'psnr', 'ssim', 'lap_var_hr', 'rms_noise_hr', \n",
    "            'blocking_hr','ringing_hr', 'saturation_mean_hr', \n",
    "            'brightness_mean_hr', 'edge_diff'\n",
    "        ]\n",
    "        \n",
    "        available = [m for m in metrics if m in df.columns]\n",
    "        if len(available) < 3:\n",
    "            print('Not enough columns for correlation matrix.')\n",
    "            return\n",
    "        \n",
    "        corr = df[available].corr()\n",
    "        plt.figure(figsize=(1.2 * len(available), 0.9 * len(available)))\n",
    "        sns.heatmap(\n",
    "            corr, cmap='flare', annot=True, fmt='.2f', center=0, square=True,\n",
    "            cbar_kws={'shrink': 0.75}\n",
    "        )\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\n",
    "            os.path.join(output_dir, 'correlation_matrix.png'),\n",
    "            dpi=300, bbox_inches='tight'\n",
    "        )\n",
    "        plt.close()\n",
    "\n",
    "    @staticmethod\n",
    "    def scatter_relations(df, output_dir):\n",
    "        \"\"\"Scatter plots for metrics relations.\n",
    "        Saves: scatter_relations.png\n",
    "        Pairs:\n",
    "          (lpips, psnr), (lpips, ssim), (lap_var_hr, psnr),\n",
    "          (rms_noise_hr, psnr), (blocking_hr, ringing_hr),\n",
    "          (saturation_mean_hr, brightness_mean_hr),\n",
    "          (edge_diff, psnr), (edge_diff, ssim)\n",
    "        \"\"\"\n",
    "        \n",
    "        pairs = [\n",
    "            ('lpips', 'psnr', 'LPIPS vs PSNR', '#1f77b4'),\n",
    "            ('lpips', 'ssim', 'LPIPS vs SSIM', '#ff7f0e'),\n",
    "            ('lap_var_hr', 'psnr', 'LaplacianVar HR vs PSNR', '#2ca02c'),\n",
    "            ('rms_noise_hr', 'psnr', 'Noise HR vs PSNR', '#d62728'),\n",
    "            ('blocking_hr', 'ringing_hr', 'Blocking vs Ringing', '#9467bd'),\n",
    "            ('saturation_mean_hr', 'brightness_mean_hr',\n",
    "             'Saturation vs Brightness', '#8c564b'),\n",
    "            ('edge_diff', 'psnr', 'Edge Diff vs PSNR', '#e377c2'),\n",
    "            ('edge_diff', 'ssim', 'Edge Diff vs SSIM', '#7f7f7f')\n",
    "        ]\n",
    "        rows, cols = 4, 2\n",
    "        plt.figure(figsize=(cols * 5, rows * 3.2))\n",
    "        for i, (x, y, title, color) in enumerate(pairs, 1):\n",
    "            if x not in df.columns or y not in df.columns:\n",
    "                continue\n",
    "            plt.subplot(rows, cols, i)\n",
    "            plt.scatter(\n",
    "                df[x], df[y], s=14, alpha=0.75, color=color,\n",
    "                edgecolors='white', linewidths=0.4\n",
    "            )\n",
    "            plt.xlabel(x)\n",
    "            plt.ylabel(y)\n",
    "            plt.title(title, fontsize=9)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\n",
    "            os.path.join(output_dir, 'scatter_relations.png'),\n",
    "            dpi=300, bbox_inches='tight'\n",
    "        )\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16c7f06",
   "metadata": {},
   "source": [
    "## Dataset processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24e9b686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_eda_pipeline(\n",
    "    lr_dir,\n",
    "    hr_dir,\n",
    "    output_dir=\"eda_results\",\n",
    "    top_k_examples=1,\n",
    "    glcm_multi_angle=False,\n",
    "    glcm_levels=64,\n",
    "    interp_map_path=\"\",\n",
    "):\n",
    "    \"\"\"Execute full EDA pipeline and return metrics DataFrame.\n",
    "\n",
    "    Generates:\n",
    "      - advanced_global_panel.png\n",
    "      - distributions.png\n",
    "      - artifact_color_histograms.png\n",
    "      - artifact_boxplots.png\n",
    "      - channel_shape_bars.png\n",
    "      - correlation_matrix.png\n",
    "      - scatter_relations.png\n",
    "      - LPIPS_Scenarios\n",
    "    \"\"\"\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Load interpolation mapping\n",
    "    interp_map = None\n",
    "    if interp_map_path and os.path.exists(interp_map_path):\n",
    "        try:\n",
    "            with open(interp_map_path, 'rb') as f:\n",
    "                interp_map = pickle.load(f)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: could not load interpolation map: {e}\")\n",
    "    else:\n",
    "        print(\"Interpolation map not found; default interpolation will be used.\")\n",
    "    \n",
    "    examples_dir = os.path.join(output_dir, \"LPIPS_Scenarios\")\n",
    "    best_dir = os.path.join(examples_dir, \"best_scenarios\")\n",
    "    worst_dir = os.path.join(examples_dir, \"worst_scenarios\")\n",
    "\n",
    "    for d in (best_dir, worst_dir):\n",
    "        os.makedirs(d, exist_ok=True)\n",
    "    \n",
    "    # Collect metrics + global visualization data\n",
    "    rows, global_data = MetricsAggregator.collect(\n",
    "        lr_dir,\n",
    "        hr_dir,\n",
    "        glcm_multi_angle=glcm_multi_angle,\n",
    "        glcm_levels=glcm_levels,\n",
    "        interp_map=interp_map,\n",
    "    )\n",
    "    df = StatsReporter.dataframe(rows)\n",
    "\n",
    "    # Global data visualizations\n",
    "    ImageDataVisualization.create_global_advanced_visualizations(\n",
    "        global_data,\n",
    "        os.path.join(output_dir, \"advanced_global_panel.png\"),\n",
    "    )\n",
    "    ImageDataVisualization.basic_distributions(df, output_dir)\n",
    "    ImageDataVisualization.artifact_color_histograms(df, output_dir)\n",
    "    ImageDataVisualization.artifact_boxplots(df, output_dir)\n",
    "    ImageDataVisualization.channel_shape_bars(df, output_dir)\n",
    "    ImageDataVisualization.correlation_matrix(df, output_dir)\n",
    "    ImageDataVisualization.scatter_relations(df, output_dir)\n",
    "    df_sorted = df.sort_values(\"lpips\")\n",
    "    selections = [\n",
    "        (df_sorted.head(top_k_examples), best_dir, \"best\"),\n",
    "        (df_sorted.tail(top_k_examples), worst_dir, \"worst\"),\n",
    "    ]\n",
    "\n",
    "    for subset, subdir, label in selections:\n",
    "        for rank, name in enumerate(subset[\"filename\"].tolist(), 1):\n",
    "            lr_img, hr_img = ImagePairLoader.load_and_align(\n",
    "                os.path.join(lr_dir, name),\n",
    "                os.path.join(hr_dir, name),\n",
    "                interp_map=interp_map\n",
    "            )\n",
    "            lp_val = subset.loc[subset[\"filename\"] == name, \"lpips\"].values[0]\n",
    "\n",
    "            out_basic = os.path.join(\n",
    "                subdir,\n",
    "                f\"{label}_{rank}_{name}.png\"\n",
    "            )\n",
    "            ImageDataVisualization.save_visual_example(\n",
    "                lr_img, hr_img, out_basic, lp_val\n",
    "            )\n",
    "\n",
    "            out_adv = os.path.join(\n",
    "                subdir,\n",
    "                f\"{label}_{rank}_advanced_{name}.png\"\n",
    "            )\n",
    "            ImageDataVisualization.create_advanced_visualizations(\n",
    "                lr_img, hr_img, out_adv\n",
    "            )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82e449c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing metrics:   0%|          | 0/343 [00:00<?, ?img/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bgmanuel\\anaconda3\\envs\\py310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\bgmanuel\\anaconda3\\envs\\py310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: c:\\Users\\bgmanuel\\anaconda3\\envs\\py310\\lib\\site-packages\\lpips\\weights\\v0.1\\alex.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing metrics: 100%|| 343/343 [06:48<00:00,  1.19s/img]\n",
      "C:\\Users\\bgmanuel\\AppData\\Local\\Temp\\ipykernel_13608\\3790270673.py:296: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  box = plt.boxplot(data, labels=labels, patch_artist=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>lpips</th>\n",
       "      <th>psnr</th>\n",
       "      <th>ssim</th>\n",
       "      <th>glcm_contrast</th>\n",
       "      <th>glcm_homogeneity</th>\n",
       "      <th>glcm_correlation</th>\n",
       "      <th>rms_noise_lr</th>\n",
       "      <th>rms_noise_hr</th>\n",
       "      <th>lap_var_lr</th>\n",
       "      <th>...</th>\n",
       "      <th>ch1_skew_lr</th>\n",
       "      <th>ch1_skew_hr</th>\n",
       "      <th>ch2_skew_lr</th>\n",
       "      <th>ch2_skew_hr</th>\n",
       "      <th>ch0_kurt_lr</th>\n",
       "      <th>ch0_kurt_hr</th>\n",
       "      <th>ch1_kurt_lr</th>\n",
       "      <th>ch1_kurt_hr</th>\n",
       "      <th>ch2_kurt_lr</th>\n",
       "      <th>ch2_kurt_hr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>low_z_offset0.png</td>\n",
       "      <td>0.327826</td>\n",
       "      <td>30.109390</td>\n",
       "      <td>0.808420</td>\n",
       "      <td>14.432869</td>\n",
       "      <td>0.384390</td>\n",
       "      <td>0.980362</td>\n",
       "      <td>0.832386</td>\n",
       "      <td>4.060324</td>\n",
       "      <td>10.953554</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.242137</td>\n",
       "      <td>-0.591390</td>\n",
       "      <td>-0.287607</td>\n",
       "      <td>-0.707762</td>\n",
       "      <td>-0.297556</td>\n",
       "      <td>0.129260</td>\n",
       "      <td>-0.123669</td>\n",
       "      <td>0.537456</td>\n",
       "      <td>0.045144</td>\n",
       "      <td>0.925549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>low_z_offset1.png</td>\n",
       "      <td>0.529672</td>\n",
       "      <td>26.493820</td>\n",
       "      <td>0.607662</td>\n",
       "      <td>16.617853</td>\n",
       "      <td>0.337882</td>\n",
       "      <td>0.975979</td>\n",
       "      <td>0.862706</td>\n",
       "      <td>6.003793</td>\n",
       "      <td>11.863290</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074242</td>\n",
       "      <td>-0.497468</td>\n",
       "      <td>-0.153824</td>\n",
       "      <td>-0.647975</td>\n",
       "      <td>-0.289403</td>\n",
       "      <td>0.070751</td>\n",
       "      <td>-0.037936</td>\n",
       "      <td>0.452261</td>\n",
       "      <td>0.005073</td>\n",
       "      <td>0.802236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>low_z_offset10.png</td>\n",
       "      <td>0.306552</td>\n",
       "      <td>30.261418</td>\n",
       "      <td>0.810037</td>\n",
       "      <td>31.606168</td>\n",
       "      <td>0.269219</td>\n",
       "      <td>0.957130</td>\n",
       "      <td>1.311557</td>\n",
       "      <td>3.479813</td>\n",
       "      <td>29.479333</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.557486</td>\n",
       "      <td>-0.728197</td>\n",
       "      <td>-0.723243</td>\n",
       "      <td>-0.941078</td>\n",
       "      <td>0.018876</td>\n",
       "      <td>0.071032</td>\n",
       "      <td>0.292284</td>\n",
       "      <td>0.603479</td>\n",
       "      <td>0.635983</td>\n",
       "      <td>1.133528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>low_z_offset100.png</td>\n",
       "      <td>0.391417</td>\n",
       "      <td>30.240566</td>\n",
       "      <td>0.809254</td>\n",
       "      <td>110.620090</td>\n",
       "      <td>0.162323</td>\n",
       "      <td>0.861414</td>\n",
       "      <td>3.171527</td>\n",
       "      <td>3.922570</td>\n",
       "      <td>182.536126</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.025756</td>\n",
       "      <td>-1.210069</td>\n",
       "      <td>-1.203912</td>\n",
       "      <td>-1.450431</td>\n",
       "      <td>1.293942</td>\n",
       "      <td>1.487699</td>\n",
       "      <td>2.280737</td>\n",
       "      <td>2.697713</td>\n",
       "      <td>2.751919</td>\n",
       "      <td>3.457019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>low_z_offset101.png</td>\n",
       "      <td>0.416359</td>\n",
       "      <td>27.748634</td>\n",
       "      <td>0.789911</td>\n",
       "      <td>147.161750</td>\n",
       "      <td>0.469028</td>\n",
       "      <td>0.856525</td>\n",
       "      <td>5.111986</td>\n",
       "      <td>3.788779</td>\n",
       "      <td>464.812880</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.009000</td>\n",
       "      <td>-1.158847</td>\n",
       "      <td>-1.097316</td>\n",
       "      <td>-1.287071</td>\n",
       "      <td>1.248353</td>\n",
       "      <td>1.297797</td>\n",
       "      <td>2.096780</td>\n",
       "      <td>2.431108</td>\n",
       "      <td>2.211748</td>\n",
       "      <td>2.710430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>low_z_offset95.png</td>\n",
       "      <td>0.259394</td>\n",
       "      <td>29.385208</td>\n",
       "      <td>0.843681</td>\n",
       "      <td>46.650142</td>\n",
       "      <td>0.246699</td>\n",
       "      <td>0.984569</td>\n",
       "      <td>1.254234</td>\n",
       "      <td>2.028015</td>\n",
       "      <td>25.684411</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.792244</td>\n",
       "      <td>-0.804692</td>\n",
       "      <td>-0.741957</td>\n",
       "      <td>-0.776511</td>\n",
       "      <td>0.083306</td>\n",
       "      <td>-0.165739</td>\n",
       "      <td>-0.012851</td>\n",
       "      <td>-0.027361</td>\n",
       "      <td>-0.116006</td>\n",
       "      <td>-0.045628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>low_z_offset96.png</td>\n",
       "      <td>0.162832</td>\n",
       "      <td>29.575188</td>\n",
       "      <td>0.871340</td>\n",
       "      <td>140.259189</td>\n",
       "      <td>0.146594</td>\n",
       "      <td>0.943394</td>\n",
       "      <td>2.763581</td>\n",
       "      <td>3.611707</td>\n",
       "      <td>130.738173</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.632025</td>\n",
       "      <td>-0.641598</td>\n",
       "      <td>-0.677984</td>\n",
       "      <td>-0.701186</td>\n",
       "      <td>-0.478937</td>\n",
       "      <td>-0.602372</td>\n",
       "      <td>-0.132964</td>\n",
       "      <td>-0.196968</td>\n",
       "      <td>0.033565</td>\n",
       "      <td>0.009365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>low_z_offset97.png</td>\n",
       "      <td>0.423534</td>\n",
       "      <td>27.335886</td>\n",
       "      <td>0.793812</td>\n",
       "      <td>124.802953</td>\n",
       "      <td>0.474242</td>\n",
       "      <td>0.881772</td>\n",
       "      <td>4.677649</td>\n",
       "      <td>4.272199</td>\n",
       "      <td>380.353872</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.003449</td>\n",
       "      <td>-1.057208</td>\n",
       "      <td>-1.079240</td>\n",
       "      <td>-1.199442</td>\n",
       "      <td>0.557686</td>\n",
       "      <td>0.533245</td>\n",
       "      <td>1.291997</td>\n",
       "      <td>1.445661</td>\n",
       "      <td>1.457566</td>\n",
       "      <td>1.814850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>low_z_offset98.png</td>\n",
       "      <td>0.307503</td>\n",
       "      <td>28.812628</td>\n",
       "      <td>0.795854</td>\n",
       "      <td>49.452483</td>\n",
       "      <td>0.234245</td>\n",
       "      <td>0.952119</td>\n",
       "      <td>1.525515</td>\n",
       "      <td>3.904114</td>\n",
       "      <td>39.702325</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.521457</td>\n",
       "      <td>-0.614353</td>\n",
       "      <td>-0.573143</td>\n",
       "      <td>-0.754087</td>\n",
       "      <td>-0.059861</td>\n",
       "      <td>-0.146607</td>\n",
       "      <td>0.268751</td>\n",
       "      <td>0.362653</td>\n",
       "      <td>0.362214</td>\n",
       "      <td>0.641304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>low_z_offset99.png</td>\n",
       "      <td>0.646348</td>\n",
       "      <td>26.627349</td>\n",
       "      <td>0.646225</td>\n",
       "      <td>46.209336</td>\n",
       "      <td>0.180790</td>\n",
       "      <td>0.954195</td>\n",
       "      <td>1.966138</td>\n",
       "      <td>3.740131</td>\n",
       "      <td>74.003085</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.359166</td>\n",
       "      <td>-0.389486</td>\n",
       "      <td>-0.471660</td>\n",
       "      <td>-0.576371</td>\n",
       "      <td>0.017680</td>\n",
       "      <td>-0.108813</td>\n",
       "      <td>0.136715</td>\n",
       "      <td>-0.021711</td>\n",
       "      <td>0.304691</td>\n",
       "      <td>0.190482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>343 rows  34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                filename     lpips       psnr      ssim  glcm_contrast  \\\n",
       "0      low_z_offset0.png  0.327826  30.109390  0.808420      14.432869   \n",
       "1      low_z_offset1.png  0.529672  26.493820  0.607662      16.617853   \n",
       "2     low_z_offset10.png  0.306552  30.261418  0.810037      31.606168   \n",
       "3    low_z_offset100.png  0.391417  30.240566  0.809254     110.620090   \n",
       "4    low_z_offset101.png  0.416359  27.748634  0.789911     147.161750   \n",
       "..                   ...       ...        ...       ...            ...   \n",
       "338   low_z_offset95.png  0.259394  29.385208  0.843681      46.650142   \n",
       "339   low_z_offset96.png  0.162832  29.575188  0.871340     140.259189   \n",
       "340   low_z_offset97.png  0.423534  27.335886  0.793812     124.802953   \n",
       "341   low_z_offset98.png  0.307503  28.812628  0.795854      49.452483   \n",
       "342   low_z_offset99.png  0.646348  26.627349  0.646225      46.209336   \n",
       "\n",
       "     glcm_homogeneity  glcm_correlation  rms_noise_lr  rms_noise_hr  \\\n",
       "0            0.384390          0.980362      0.832386      4.060324   \n",
       "1            0.337882          0.975979      0.862706      6.003793   \n",
       "2            0.269219          0.957130      1.311557      3.479813   \n",
       "3            0.162323          0.861414      3.171527      3.922570   \n",
       "4            0.469028          0.856525      5.111986      3.788779   \n",
       "..                ...               ...           ...           ...   \n",
       "338          0.246699          0.984569      1.254234      2.028015   \n",
       "339          0.146594          0.943394      2.763581      3.611707   \n",
       "340          0.474242          0.881772      4.677649      4.272199   \n",
       "341          0.234245          0.952119      1.525515      3.904114   \n",
       "342          0.180790          0.954195      1.966138      3.740131   \n",
       "\n",
       "     lap_var_lr  ...  ch1_skew_lr  ch1_skew_hr  ch2_skew_lr  ch2_skew_hr  \\\n",
       "0     10.953554  ...    -0.242137    -0.591390    -0.287607    -0.707762   \n",
       "1     11.863290  ...    -0.074242    -0.497468    -0.153824    -0.647975   \n",
       "2     29.479333  ...    -0.557486    -0.728197    -0.723243    -0.941078   \n",
       "3    182.536126  ...    -1.025756    -1.210069    -1.203912    -1.450431   \n",
       "4    464.812880  ...    -1.009000    -1.158847    -1.097316    -1.287071   \n",
       "..          ...  ...          ...          ...          ...          ...   \n",
       "338   25.684411  ...    -0.792244    -0.804692    -0.741957    -0.776511   \n",
       "339  130.738173  ...    -0.632025    -0.641598    -0.677984    -0.701186   \n",
       "340  380.353872  ...    -1.003449    -1.057208    -1.079240    -1.199442   \n",
       "341   39.702325  ...    -0.521457    -0.614353    -0.573143    -0.754087   \n",
       "342   74.003085  ...    -0.359166    -0.389486    -0.471660    -0.576371   \n",
       "\n",
       "     ch0_kurt_lr  ch0_kurt_hr  ch1_kurt_lr  ch1_kurt_hr  ch2_kurt_lr  \\\n",
       "0      -0.297556     0.129260    -0.123669     0.537456     0.045144   \n",
       "1      -0.289403     0.070751    -0.037936     0.452261     0.005073   \n",
       "2       0.018876     0.071032     0.292284     0.603479     0.635983   \n",
       "3       1.293942     1.487699     2.280737     2.697713     2.751919   \n",
       "4       1.248353     1.297797     2.096780     2.431108     2.211748   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "338     0.083306    -0.165739    -0.012851    -0.027361    -0.116006   \n",
       "339    -0.478937    -0.602372    -0.132964    -0.196968     0.033565   \n",
       "340     0.557686     0.533245     1.291997     1.445661     1.457566   \n",
       "341    -0.059861    -0.146607     0.268751     0.362653     0.362214   \n",
       "342     0.017680    -0.108813     0.136715    -0.021711     0.304691   \n",
       "\n",
       "     ch2_kurt_hr  \n",
       "0       0.925549  \n",
       "1       0.802236  \n",
       "2       1.133528  \n",
       "3       3.457019  \n",
       "4       2.710430  \n",
       "..           ...  \n",
       "338    -0.045628  \n",
       "339     0.009365  \n",
       "340     1.814850  \n",
       "341     0.641304  \n",
       "342     0.190482  \n",
       "\n",
       "[343 rows x 34 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_dir = \"images/LR/low_z_offset\"\n",
    "hr_dir = \"images/HR/low_z_offset\"\n",
    "output_dir = \"eda_results\"\n",
    "interp_map_path = \"images/low_z_offset_interpolation_map.pkl\"\n",
    "\n",
    "run_eda_pipeline(lr_dir, hr_dir, output_dir, glcm_multi_angle=True, glcm_levels=256, interp_map_path=interp_map_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
